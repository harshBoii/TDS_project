import { z as z$1 } from 'zod';

var we=(e,t)=>(t=Symbol[e])?t:Symbol.for("Symbol."+e),kn=e=>{throw TypeError(e)};var En=function(e,t){this[0]=e,this[1]=t;};var Ot=e=>{var t=e[we("asyncIterator")],o=!1,s,i={};return t==null?(t=e[we("iterator")](),s=l=>i[l]=r=>t[l](r)):(t=t.call(e),s=l=>i[l]=r=>{if(o){if(o=!1,l==="throw")throw r;return r}return o=!0,{done:!1,value:new En(new Promise(d=>{var p=t[l](r);p instanceof Object||kn("Object expected"),d(p);}),1)}}),i[we("iterator")]=()=>i,s("next"),"throw"in t?s("throw"):i.throw=l=>{throw l},"return"in t&&s("return"),i};var f=z$1.object({apiKey:z$1.string().min(1),deploymentId:z$1.string().min(1),resourceName:z$1.string().min(1).optional(),baseUrl:z$1.string().optional()});var ee="system",te="user",A="assistant",oe="tool",Cn=[ee,te,A,oe],je=z$1.enum(Cn),wn=[A],In=z$1.enum(wn),K="image",Ge="base64",Rn=["png","jpeg","webp","gif"],jn=z$1.object({type:z$1.literal(Ge),base64:z$1.string(),mediaType:z$1.enum(Rn)}),Ae="url",Gn=z$1.object({type:z$1.literal(Ae),url:z$1.string()}),An=z$1.discriminatedUnion("type",[jn,Gn]),Ln=["low","medium","high","auto"],Nn=z$1.enum(Ln),Un=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(K),detail:Nn,value:An,metadata:e}),St="reasoning",kt="partial-reasoning",Et="thinking",Bn="redacted",Re=z$1.object({type:z$1.literal(Et),thinking:z$1.string(),signature:z$1.string()}),Ct=z$1.object({type:z$1.literal(Bn),data:z$1.string()}),$n=z$1.discriminatedUnion("type",[Re,Ct]),qn=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(St),value:$n,metadata:e}),zn=z$1.object({type:z$1.literal(Et),thinking:Re.shape.thinking.optional(),signature:Re.shape.signature.optional()}),Dn=z$1.discriminatedUnion("type",[zn,Ct]),Fn=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(kt),value:Dn,metadata:e}),k="text",wt=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(k),value:z$1.string(),metadata:e}),Le="partial-text",It=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(Le),value:z$1.string(),metadata:e}),j="tool-call",Rt=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(j),index:z$1.number().int().nonnegative(),id:z$1.string().min(1),name:z$1.string().min(1),arguments:z$1.string(),metadata:e}),Ne="partial-tool-call",jt=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(Ne),index:z$1.number().int().nonnegative(),id:z$1.string().optional(),name:z$1.string().optional(),arguments:z$1.string().optional(),metadata:e}),L="tool-response",Hn=(e=z$1.undefined())=>z$1.object({modality:z$1.literal(L),index:z$1.number().int().nonnegative(),id:z$1.string().min(1),name:z$1.string().min(1),data:z$1.string(),metadata:e}),Kn=[k,K,j,L,St],Gt=z$1.enum(Kn),Jn=(e=z$1.undefined(),t=z$1.undefined(),o=z$1.undefined(),s=z$1.undefined(),i=z$1.undefined())=>z$1.discriminatedUnion("modality",[wt(e),Un(t),Rt(o),Hn(s),qn(i)]),Vn=[Le,Ne,kt];z$1.enum(Vn);var Wn=(e=z$1.undefined(),t=z$1.undefined(),o=z$1.undefined())=>z$1.discriminatedUnion("modality",[It(e),jt(t),Fn(o)]);var Ue=(e=je,t=z$1.undefined(),o=z$1.undefined(),s=z$1.undefined(),i=z$1.undefined(),l=z$1.undefined(),r=z$1.undefined())=>z$1.object({role:e,content:z$1.array(Jn(t,o,s,i,r)),metadata:l}),Be=(e=In,t=z$1.undefined(),o=z$1.undefined(),s=z$1.undefined(),i=z$1.undefined())=>z$1.object({role:e,partialContent:Wn(t,o,s),metadata:i}),Yn=z$1.object({promptTokens:z$1.number().nonnegative(),completionTokens:z$1.number().nonnegative(),totalTokens:z$1.number().nonnegative()}),vt=z$1.object({token:z$1.string(),logProb:z$1.number(),bytes:z$1.array(z$1.number().int()).nullable()}),Zn=vt.extend({topLogProbs:z$1.array(vt)}),At=z$1.array(Zn);z$1.object({messages:z$1.array(Ue()),usage:Yn.optional(),logProbs:At.optional()});var Xn=z$1.object({promptTokens:z$1.number().nonnegative().optional(),completionTokens:z$1.number().nonnegative().optional(),totalTokens:z$1.number().nonnegative().optional()});z$1.object({partialMessages:z$1.array(Be()),usage:Xn.optional(),logProbs:At.optional()});var $e=(e=z$1.record(z$1.string(),z$1.any()).optional())=>e,Qn=["object","array","number","string","boolean","enum"],xt=z$1.enum(Qn),ea=z$1.object({anyOf:z$1.array(z$1.any()).optional(),type:z$1.union([xt,z$1.array(z$1.union([xt,z$1.literal("null")]))]).optional(),default:z$1.any().optional(),title:z$1.string().optional(),description:z$1.string().max(4096).optional(),properties:z$1.record(z$1.any()).optional(),required:z$1.array(z$1.string()).optional(),minItems:z$1.number().int().min(0).optional(),maxItems:z$1.number().int().optional(),items:z$1.record(z$1.any()).optional(),enum:z$1.array(z$1.union([z$1.string(),z$1.number(),z$1.boolean(),z$1.null()])).optional(),minimum:z$1.number().optional(),maximum:z$1.number().optional(),minLength:z$1.number().int().min(0).optional(),maxLength:z$1.number().int().optional(),$ref:z$1.string().optional()}),ta=z$1.object({type:z$1.enum(["object"]),required:z$1.array(z$1.string()),$defs:z$1.record(z$1.any()).optional(),properties:z$1.record(ea),additionalProperties:z$1.literal(!1)}),Lt=z$1.object({name:z$1.string().regex(/^[a-zA-Z0-9_]{1,64}$/).max(64),description:z$1.string().max(4096),strict:z$1.boolean().optional(),schema:ta}).optional(),J="text",W="token",oa=[J,W],Nt=z$1.enum(oa),na=z$1.array(z$1.string().min(1)),aa=z$1.array(z$1.array(z$1.number().int().nonnegative())),Ut=(e=z$1.undefined())=>z$1.discriminatedUnion("modality",[z$1.object({modality:z$1.literal(J),metadata:e,requests:na}),z$1.object({modality:z$1.literal(W),metadata:e,requests:aa})]),qe="float",sa=z$1.object({index:z$1.number().int().nonnegative(),embedding:z$1.array(z$1.number())}),ze="base64",ia=z$1.object({index:z$1.number().int().nonnegative(),embedding:z$1.string().base64()}),Mt=z$1.object({totalTokens:z$1.number().int().nonnegative()});z$1.discriminatedUnion("encodingFormat",[z$1.object({encodingFormat:z$1.literal(qe),embeddings:z$1.array(sa),usage:Mt.optional()}),z$1.object({encodingFormat:z$1.literal(ze),embeddings:z$1.array(ia),usage:Mt.optional()})]);var ra=e=>{let t=new WeakSet;return JSON.stringify(e,(o,s)=>{if(typeof s=="object"&&s!==null){if(t.has(s))return;t.add(s);}return s})},la=e=>e==null?"unknown error":typeof e=="string"?e:e instanceof Error?e.message:ra(e),Ie="GatewayBaseError",z=class Bt extends Error{constructor({info:t,cause:o},s){super(`[${s!=null?s:Ie}]: ${t}
Message: ${la(o)}`),this.name=Ie,this.info=t,this.cause=o,this.name=s!=null?s:Ie,Object.setPrototypeOf(this,new.target.prototype);}static isGatewayBaseError(t){return t instanceof Bt}toJSON(){return {name:this.name,info:this.info,cause:this.cause,message:this.message,stack:this.stack}}},ma=z$1.object({inputPricePerMillion:z$1.number().nonnegative().describe("Price per 1M input tokens"),outputPricePerMillion:z$1.number().nonnegative().describe("Price per 1M output tokens")}).describe("Input/output price pair (per 1M tokens) for a specific category within a ChatModel pricing tier."),da=z$1.object({base:ma.describe("Base (uncached, non\u2011reasoning) rates")}).describe("Holds the `ChatModelTokenPairPrice` for different categories (e.g., base) within a single pricing tier."),pa=z$1.object({minTokens:z$1.number().int().nonnegative().describe("Inclusive lower token bound for this tier."),maxTokens:z$1.number().int().nullable().optional().describe("Exclusive upper token bound; `null` means \u221E."),prices:da.describe("Price categories and rates for this specific token range.")}).refine(e=>e.maxTokens===null||typeof e.maxTokens=="number"&&e.maxTokens>e.minTokens,{message:"maxTokens must be > minTokens (or null for infinite).",path:["maxTokens"]}).describe("A single pricing tier defined by a token range and associated prices.");z$1.object({modelName:z$1.string().describe("Model name this schedule applies to."),currency:z$1.string().default("USD").describe("Currency code (e.g., USD)."),tokenRanges:z$1.array(pa).min(1).describe("Pricing tiers (`ChatModelTokenRangePrice`) schedule, sorted by minTokens.")}).superRefine((e,t)=>{let{tokenRanges:o}=e;o[0].minTokens!==0&&t.addIssue({code:z$1.ZodIssueCode.custom,path:["tokenRanges",0,"minTokens"],message:"The first tier must have minTokens = 0."});for(let i=1;i<o.length;i++){let l=o[i-1],r=o[i];if(l.maxTokens===null){t.addIssue({code:z$1.ZodIssueCode.custom,path:["tokenRanges",i-1,"maxTokens"],message:"Cannot define any tokenRanges after an infinite tier (maxTokens = null)."});break}r.minTokens!==l.maxTokens&&t.addIssue({code:z$1.ZodIssueCode.custom,path:["tokenRanges",i,"minTokens"],message:`Tier ${i} minTokens (${r.minTokens}) must equal previous tier's maxTokens (${l.maxTokens}) for contiguity.`}),r.minTokens<l.minTokens&&t.addIssue({code:z$1.ZodIssueCode.custom,path:["tokenRanges",i,"minTokens"],message:`tokenRanges must be sorted by ascending minTokens. Tier ${i} (${r.minTokens}) starts before Tier ${i-1} (${l.minTokens}).`});}let s=o[o.length-1];o.every(i=>i.maxTokens!==null||i===s)&&s.maxTokens!==null&&t.addIssue({code:z$1.ZodIssueCode.custom,path:["tokenRanges",o.length-1,"maxTokens"],message:"The final tier must have maxTokens = null (representing infinity)."});}).describe("Complete pricing schedule for a single chat model, including all its token-based tiers.");var ca="function";var ua=z$1.enum(["object","array","number","string","boolean","null"]),ga=z$1.object({anyOf:z$1.array(z$1.any()).optional(),type:ua.optional(),default:z$1.any().optional(),title:z$1.string().optional(),description:z$1.string().max(4096).optional(),properties:z$1.record(z$1.any()).optional(),required:z$1.array(z$1.string()).optional(),minItems:z$1.number().int().min(0).optional(),maxItems:z$1.number().int().optional(),items:z$1.record(z$1.any()).optional(),enum:z$1.array(z$1.union([z$1.string(),z$1.number(),z$1.boolean(),z$1.null()])).optional(),minimum:z$1.number().optional(),maximum:z$1.number().optional(),minLength:z$1.number().int().min(0).optional(),maxLength:z$1.number().int().optional()});z$1.object({type:z$1.enum(["object"]),title:z$1.string().optional(),$defs:z$1.record(z$1.any()).optional(),properties:z$1.record(ga).optional(),required:z$1.array(z$1.string()).optional()});var ha=z$1.object({name:z$1.string().regex(/^[a-zA-Z0-9_]{1,64}$/).max(64),description:z$1.string().max(4096),parameters:z$1.any(),strict:z$1.boolean().optional()});var fa=z$1.enum(["function"]),_a=z$1.object({type:fa,definition:z$1.object({schema:ha})}),ba=[ca];z$1.enum(ba);var $t=(e=z$1.undefined())=>z$1.discriminatedUnion("type",[_a.extend({metadata:e})]),De=e=>wt().parse({modality:k,value:e}),qt=(e,t,o,s)=>Rt().parse({modality:j,index:e,id:t,name:o,arguments:s});var Fe=(e,t)=>Be().parse({role:e,partialContent:It().parse({modality:Le,value:t})}),zt=(e,t,o,s,i)=>Be().parse({role:e,partialContent:jt().parse({modality:Ne,index:t,id:o,name:s,arguments:i})});var ya=Object.defineProperty,Dt=Object.getOwnPropertySymbols,Ta=Object.prototype.hasOwnProperty,Pa=Object.prototype.propertyIsEnumerable,Ft=(e,t,o)=>t in e?ya(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,ne=(e,t)=>{for(var o in t||(t={}))Ta.call(t,o)&&Ft(e,o,t[o]);if(Dt)for(var o of Dt(t))Pa.call(t,o)&&Ft(e,o,t[o]);return e},Ht="ProviderError",He=class Qt extends z{constructor({info:t,cause:o}){super({info:t,cause:o},Ht),this.name=Ht,this.info=t,this.cause=o;}static isProviderError(t){return t instanceof Qt}},Kt="ModelError",de=class eo extends z{constructor({info:t,cause:o}){super({info:t,cause:o},Kt),this.name=Kt,this.info=t,this.cause=o;}static isModelError(t){return t instanceof eo}},Jt="ModelResponseError",D=class to extends z{constructor({info:t,cause:o}){super({info:t,cause:o},Jt),this.name=Jt,this.cause=o,this.info=t;}static isModelResponseError(t){return t instanceof to}},Vt="InvalidModelRequestError",ae=class oo extends z{constructor({info:t,cause:o}){super({info:t,cause:o},Vt),this.name=Vt,this.cause=o,this.info=t,Object.setPrototypeOf(this,new.target.prototype);}static isInvalidModelRequestError(t){return t instanceof oo}},Wt="InvalidConfigError",F=class no extends z{constructor({info:t,cause:o}){super({info:t,cause:o},Wt),this.name=Wt,this.cause=o,this.info=t,Object.setPrototypeOf(this,new.target.prototype);}static isInvalidConfigError(t){return t instanceof no}},Yt="InvalidMessagesError",G=class ao extends z{constructor({info:t,cause:o}){super({info:t,cause:o},Yt),this.name=Yt,this.cause=o,this.info=t,Object.setPrototypeOf(this,new.target.prototype);}static isInvalidMessagesError(t){return t instanceof ao}},Zt="InvalidToolsError",Ke=class so extends z{constructor({info:t,cause:o}){super({info:t,cause:o},Zt),this.name=Zt,this.cause=o,this.info=t,Object.setPrototypeOf(this,new.target.prototype);}static isInvalidToolsError(t){return t instanceof so}},Xt="InvalidEmbeddingRequestsError",io=class ro extends z{constructor({info:t,cause:o}){super({info:t,cause:o},Xt),this.name=Xt,this.info=t,this.cause=o,Object.setPrototypeOf(this,new.target.prototype);}static isInvalidEmbeddingRequestsError(t){return t instanceof ro}},Je="multi-string",lo=z$1.object({type:z$1.literal(Je),param:z$1.string().min(1),title:z$1.string().min(1),description:z$1.string().min(1).max(500),max:z$1.number().int().positive()}),Oa=e=>z$1.array(z$1.string()).max(e).default([]).optional(),mo=e=>({def:lo.parse(ne({type:Je},e)),schema:Oa(e.max)}),Ve="object-schema",po=z$1.object({type:z$1.literal(Ve),param:z$1.string().min(1),title:z$1.string().min(1),description:z$1.string().min(1).max(500),objectSchema:z$1.any()}),va=e=>e.optional(),co=e=>({def:po.parse(ne({type:Ve},e)),schema:va(e.objectSchema)}),We="range",uo=z$1.object({type:z$1.literal(We),param:z$1.string().min(1),title:z$1.string().min(1),description:z$1.string().min(1).max(500),min:z$1.number().int(),max:z$1.number().int(),step:z$1.number().positive(),default:z$1.number()}),xa=(e,t,o,s)=>z$1.number().min(e).max(t).step(o).default(s).optional(),N=e=>({def:uo.parse(ne({type:We},e)),schema:xa(e.min,e.max,e.step,e.default)}),Ye="select-boolean",go=z$1.object({type:z$1.literal(Ye),param:z$1.string().min(1),title:z$1.string().min(1),description:z$1.string().min(1).max(500),default:z$1.boolean().nullable()}),Ma=e=>z$1.boolean().nullable().default(e).optional(),ho=e=>({def:go.parse(ne({type:Ye},e)),schema:Ma(e.default)}),Ze="select-string",fo=z$1.object({type:z$1.literal(Ze),param:z$1.string().min(1),title:z$1.string().min(1),description:z$1.string().min(1).max(500),default:z$1.string(),choices:z$1.array(z$1.string())}),Sa=(e,t)=>z$1.enum(t).nullable().default(e).optional(),Y=e=>({def:fo.parse(ne({type:Ze},e)),schema:Sa(e.default,e.choices)}),ka=[We,Je,Ze,Ve,Ye];z$1.enum(ka);var _o=z$1.discriminatedUnion("type",[uo,lo,fo,go,po]),y=(e=je,t=Gt)=>z$1.object({name:z$1.string().min(1),description:z$1.string().min(1),roles:z$1.record(e,z$1.string().min(1).optional()),modalities:z$1.array(t).nonempty(),maxInputTokens:z$1.number().int().positive().min(1),maxOutputTokens:z$1.number().int().positive().min(1),maxReasoningTokens:z$1.number().int().positive().min(1).optional(),config:z$1.object({def:z$1.record(z$1.string().min(1),_o),schema:z$1.instanceof(z$1.ZodObject)}).refine(o=>{var s,i;let l=Object.keys(o.def),r=Object.keys((i=(s=o.schema)==null?void 0:s.shape)!=null?i:{});return l.every(d=>r.includes(d))&&r.every(d=>l.includes(d))},{message:"Keys in 'config.def' must exactly match keys in 'config.schema'"}),price:z$1.custom()}),Z=(e=Nt)=>z$1.object({name:z$1.string().min(1),description:z$1.string().min(1),modalities:z$1.array(e).nonempty(),maxInputTokens:z$1.number().int().positive().min(1),maxOutputTokens:z$1.number().int().positive().min(1),config:z$1.object({def:z$1.record(z$1.string().min(1),_o),schema:z$1.instanceof(z$1.ZodObject)}).refine(t=>{var o,s;let i=Object.keys(t.def),l=Object.keys((s=(o=t.schema)==null?void 0:o.shape)!=null?s:{});return i.every(r=>l.includes(r))&&l.every(r=>i.includes(r))},{message:"Keys in 'config.def' must exactly match keys in 'config.schema'"})});z$1.record(z$1.string());z$1.record(z$1.union([z$1.boolean(),z$1.string(),z$1.number(),z$1.object({}),z$1.array(z$1.any()),z$1.null(),z$1.undefined()]));z$1.string().url();var Ea={type:"range",title:"Temperature",description:"Adjusts the model's creativity level. With a setting of 0, the model strictly picks the most probable next word.     For endeavors that benefit from a dash of inventiveness, consider dialing it up to 0.7 or higher, enabling the model to produce text     that's unexpectedly fresh."},Ca={type:"range",title:"Max tokens",description:"Specify the total tokens for generation, where one token approximates four English characters.     Setting this to 0 defaults to the model's maximum capacity."},wa={type:"range",title:"Max reasoning tokens",description:"Specify the total tokens for reasoning, where one token approximates four English characters."},Ia=e=>({type:"multi",title:"Stop sequence",description:`Enter up to ${e} sequences that will halt additional text output.       The generated text will exclude these sequences.`}),Ra={type:"range",title:"Top A",description:"Considers only the top tokens that have 'sufficiently high' probabilities relative to the most likely token,     functioning like a dynamic Top-P.     A lower Top-A value narrows down the token choices based on the highest probability token,     while a higher Top-A value refines the filtering without necessarily impacting the creativity of the output."},ja={type:"range",title:"Top P",description:"Selects a subset of likely tokens for generation, restricting choices to the top-P fraction of possibilities,     such as the top 10% when P=0.1.     This approach can limit the variety of the output. By default, it's set to 1, indicating no restriction.     It's advised to adjust this parameter or temperature to modulate output diversity, but not to modify both simultaneously."},Ga={type:"range",title:"Top K",description:"Select only from the highest K probabilities for each following word, effectively eliminating the less likely 'long tail' options."},Aa={type:"range",title:"Min P",description:"Specifies the minimum probability a token must have to be considered, in relation to the probability of the most likely token.     (This value varies based on the confidence level of the top token.)     For example, if Min-P is set to 0.1, only tokens with at least 1/10th the probability of the highest-ranked token will be considered."},La={type:"range",title:"Frequency penalty",description:"Minimize redundancy.    By assigning a penalty to frequently used tokens within the text, the likelihood of repeating identical phrases is reduced.     The default setting for this penalty is zero."},Na={type:"range",title:"Presence penalty",description:"Enhance the introduction of novel subjects by reducing the preference for tokens that have already appeared in the text,     thus boosting the chances of exploring fresh topics.     The standard setting for this is zero."},Ua={type:"range",title:"Seed",description:"When seed is fixed to a specific value, the model makes a best effort to provide the same response for repeated requests.     Deterministic output isn't guaranteed.     Also, changing the model or parameter settings, such as the temperature,     can cause variations in the response even when you use the same seed value.     By default, a random seed value is used."},Ba={type:"range",title:"Repetition penalty",description:"Reduces the likelihood of repeating tokens from the input.     Increasing this value makes the model less prone to repetition, but setting it too high may lead to less coherent output,     often resulting in run-on sentences missing smaller words.     The token penalty is scaled according to the original token's probability."},$a={type:"boolean",title:"Log probs",description:"Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned."},qa={type:"range",title:"Top log probs",description:"The number of most likely tokens to return at each token position, each with an associated log probability.     'logprobs' must be set to true if this parameter is used."},za={type:"boolean",title:"Echo",description:"If true, the response will contain the prompt."},Da={type:"select",title:"Response format",description:"Choose the response format of your model. For JSON, you must include the string 'JSON' in some form within your system / user prompt."},Fa={type:"select",title:"Response format",description:"Choose the response format of your model. 'json_object' colloquially known as JSON mode, instructs the model to respond with a valid   JSON (must include the term 'json' in prompt). 'json_schema' colloquially known as structured outputs, allows you to specify a strict   response schema that the model will adhere to."},Ha={type:"object",title:"Response schema",description:"When response format is set to 'json_schema', the model will return a JSON object of the specified schema."},b={TEMPERATURE:Ea,MAX_TOKENS:Ca,STOP:Ia,TOP_A:Ra,TOP_P:ja,TOP_K:Ga,MIN_P:Aa,FREQUENCY_PENALTY:La,PRESENCE_PENALTY:Na,REPETITION_PENALTY:Ba,SEED:Ua,LOG_PROBS:$a,TOP_LOG_PROBS:qa,ECHO:za,RESPONSE_FORMAT:Da,RESPONSE_FORMAT_WITH_SCHEMA:Fa,RESPONSE_SCHEMA:Ha,MAX_REASONING_TOKENS:wa};var Xe=e=>Object.fromEntries(Object.entries(e).filter(([t,o])=>o!=null));var bo=e=>e.split(";")[0].split("/")[1],X=e=>e==null?void 0:e.replace(/\/$/,"");var Ka=Object.defineProperty,Ja=Object.defineProperties,Va=Object.getOwnPropertyDescriptors,yo=Object.getOwnPropertySymbols,Wa=Object.prototype.hasOwnProperty,Ya=Object.prototype.propertyIsEnumerable,ce=(e,t)=>(t=Symbol[e])?t:Symbol.for("Symbol."+e),Za=e=>{throw TypeError(e)},To=(e,t,o)=>t in e?Ka(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,E=(e,t)=>{for(var o in t||(t={}))Wa.call(t,o)&&To(e,o,t[o]);if(yo)for(var o of yo(t))Ya.call(t,o)&&To(e,o,t[o]);return e},ue=(e,t)=>Ja(e,Va(t)),R=(e,t,o)=>new Promise((s,i)=>{var l=p=>{try{d(o.next(p));}catch(c){i(c);}},r=p=>{try{d(o.throw(p));}catch(c){i(c);}},d=p=>p.done?s(p.value):Promise.resolve(p.value).then(l,r);d((o=o.apply(e,t)).next());}),Oo=function(e,t){this[0]=e,this[1]=t;},Po=(e,t,o)=>{var s=(r,d,p,c)=>{try{var v=o[r](d),g=(d=v.value)instanceof Oo,M=v.done;Promise.resolve(g?d[0]:d).then(h=>g?s(r==="return"?r:"next",d[1]?{done:h.done,value:h.value}:h,p,c):p({value:h,done:M})).catch(h=>s("throw",h,p,c));}catch(h){c(h);}},i=r=>l[r]=d=>new Promise((p,c)=>s(r,d,p,c)),l={};return o=o.apply(e,t),l[ce("asyncIterator")]=()=>l,i("next"),i("throw"),i("return"),l},Xa=e=>{var t=e[ce("asyncIterator")],o=!1,s,i={};return t==null?(t=e[ce("iterator")](),s=l=>i[l]=r=>t[l](r)):(t=t.call(e),s=l=>i[l]=r=>{if(o){if(o=!1,l==="throw")throw r;return r}return o=!0,{done:!1,value:new Oo(new Promise(d=>{var p=t[l](r);p instanceof Object||Za("Object expected"),d(p);}),1)}}),i[ce("iterator")]=()=>i,s("next"),"throw"in t?s("throw"):i.throw=l=>{throw l},"return"in t&&s("return"),i},vo=N({param:"temperature",title:b.TEMPERATURE.title,description:b.TEMPERATURE.description,min:0,max:2,step:.01,default:1}),xo=e=>N({param:"max_completion_tokens",title:b.MAX_TOKENS.title,description:b.MAX_TOKENS.description,min:0,max:e,step:1,default:0}),Mo=e=>mo({param:"stop",title:b.STOP(e).title,description:b.STOP(e).description,max:e}),So=N({param:"top_p",title:b.TOP_P.title,description:b.TOP_P.description,min:0,max:1,step:.01,default:1}),ko=N({param:"frequency_penalty",title:b.FREQUENCY_PENALTY.title,description:b.FREQUENCY_PENALTY.description,min:-2,max:2,step:.01,default:0}),Eo=N({param:"presence_penalty",title:b.PRESENCE_PENALTY.title,description:b.PRESENCE_PENALTY.description,min:-2,max:2,step:.01,default:0}),Co=N({param:"seed",title:b.SEED.title,description:b.SEED.description,min:0,max:1e6,step:1,default:0}),wo=ho({param:"logprobs",title:b.LOG_PROBS.title,description:b.LOG_PROBS.description,default:!1}),Io=N({param:"top_logprobs",title:b.TOP_LOG_PROBS.title,description:b.TOP_LOG_PROBS.description,min:0,max:20,step:1,default:0}),Ro=Y({param:"tool_choice",title:"Tool choice",description:"Controls which (if any) tool is called by the model. 'none' means the model will not call a function. 'auto' means the model can pick between generating a message or calling a tool.",default:"auto",choices:["auto","required","none"]}),ft=(e,t)=>z$1.object({temperature:vo.schema,maxTokens:xo(e).schema,stop:Mo(t).schema,topP:So.schema,frequencyPenalty:ko.schema,presencePenalty:Eo.schema,seed:Co.schema.transform(o=>o===0?void 0:o),logProbs:wo.schema,topLogProbs:Io.schema,toolChoice:Ro.schema}),_t=(e,t)=>({temperature:vo.def,maxTokens:xo(e).def,stop:Mo(t).def,topP:So.def,frequencyPenalty:ko.def,presencePenalty:Eo.def,seed:Co.def,logProbs:wo.def,topLogProbs:Io.def,toolChoice:Ro.def}),jo=co({param:"response_schema",title:b.RESPONSE_SCHEMA.title,description:b.RESPONSE_SCHEMA.description,objectSchema:Lt}),Go=Y({param:"response_format",title:b.RESPONSE_FORMAT_WITH_SCHEMA.title,description:b.RESPONSE_FORMAT_WITH_SCHEMA.description,default:"text",choices:["text","json_object","json_schema"]}),Ao=(e,t)=>ue(E({},_t(e,t)),{responseFormat:Go.def,responseSchema:jo.def}),Lo=(e,t)=>ft(e,t).extend({responseFormat:Go.schema,responseSchema:jo.schema}),No=N({param:"temperature",title:b.TEMPERATURE.title,description:b.TEMPERATURE.description,min:1,max:1,step:.01,default:1}),Uo=Y({param:"reasoning_effort",title:"Reasoning Effort",description:"Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.",default:"medium",choices:["low","medium","high"]}),Qa=(e,t)=>ue(E({},Ao(e,t)),{temperature:No.def,reasoningEffort:Uo.def}),es=(e,t)=>Lo(e,t).extend({temperature:No.schema,reasoningEffort:Uo.schema}),Bo=Y({param:"response_format",title:b.RESPONSE_FORMAT.title,description:b.RESPONSE_FORMAT.description,default:"text",choices:["text","json_object"]}),ts=(e,t)=>ue(E({},_t(e,t)),{responseFormat:Bo.def}),os=(e,t)=>ft(e,t).extend({responseFormat:Bo.schema}),$o=Y({param:"encoding_format",title:"Encoding format",description:"Select the encoding format for the word embedding.",default:"float",choices:["float","base64"]}),qo=e=>N({param:"dimensions",title:"Dimensions",description:"Select the number of dimensions for the word embedding.",min:1,max:e,step:1,default:e}),zo=()=>z$1.object({encodingFormat:$o.schema}),Do=()=>({encodingFormat:$o.def}),ns=e=>zo().extend({dimensions:qo(e).schema}),as=e=>ue(E({},Do()),{dimensions:qo(e).def}),u={base:(e,t)=>({def:_t(e,t),schema:ft(e,t)}),responseFormat:(e,t)=>({def:ts(e,t),schema:os(e,t)}),responseSchema:(e,t)=>({def:Ao(e,t),schema:Lo(e,t)}),oSeries:(e,t)=>({def:Qa(e,t),schema:es(e,t)})},H={base:()=>({def:Do(),schema:zo()}),dimensions:e=>({def:as(e),schema:ns(e)})},S={"gpt-3.5-turbo-0125":{modelName:"gpt-3.5-turbo-0125",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.5,outputPricePerMillion:1.5}}}]},"gpt-3.5-turbo-1106":{modelName:"gpt-3.5-turbo-1106",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.5,outputPricePerMillion:1.5}}}]},"gpt-3.5-turbo":{modelName:"gpt-3.5-turbo",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.5,outputPricePerMillion:1.5}}}]},"gpt-4-0125-preview":{modelName:"gpt-4-0125-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4-0613":{modelName:"gpt-4-0613",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4-1106-preview":{modelName:"gpt-4-1106-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4-turbo-2024-04-09":{modelName:"gpt-4-turbo-2024-04-09",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:30}}}]},"gpt-4-turbo-preview":{modelName:"gpt-4-turbo-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:30}}}]},"gpt-4-turbo":{modelName:"gpt-4-turbo",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:30}}}]},"gpt-4":{modelName:"gpt-4",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4o-2024-05-13":{modelName:"gpt-4o-2024-05-13",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:5,outputPricePerMillion:20}}}]},"gpt-4o-2024-08-06":{modelName:"gpt-4o-2024-08-06",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:2.5,outputPricePerMillion:10}}}]},"gpt-4o-mini-2024-07-18":{modelName:"gpt-4o-mini-2024-07-18",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.6,outputPricePerMillion:2.4}}}]},"gpt-4o-mini":{modelName:"gpt-4o-mini",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.6,outputPricePerMillion:2.4}}}]},"gpt-4o":{modelName:"gpt-4o",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:5,outputPricePerMillion:20}}}]},"o1-2024-12-17":{modelName:"o1-2024-12-17",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:15,outputPricePerMillion:60}}}]},o1:{modelName:"o1",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:15,outputPricePerMillion:60}}}]},"o3-mini-2025-01-31":{modelName:"o3-mini-2025-01-31",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]},"o3-mini":{modelName:"o3-mini",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]},"o3-2025-04-16":{modelName:"o3-2025-04-16",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:40}}}]},o3:{modelName:"o3",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:40}}}]},"o4-mini-2025-04-16":{modelName:"o4-mini-2025-04-16",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]},"o4-mini":{modelName:"o4-mini",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]}},ss="openai",bt=class{constructor(){this.version="v1",this.name=ss,this.chatModelFactories={[tt]:{model:ws,modelOptions:Cs,modelSchema:fe},[Qe]:{model:xs,modelOptions:vs,modelSchema:ge},[et]:{model:ks,modelOptions:Ss,modelSchema:he},[ot]:{model:js,modelOptions:Rs,modelSchema:Ho},[nt]:{model:Ls,modelOptions:As,modelSchema:_e},[at]:{model:Bs,modelOptions:Us,modelSchema:be},[st]:{model:zs,modelOptions:qs,modelSchema:ye},[it]:{model:Hs,modelOptions:Fs,modelSchema:Ko},[rt]:{model:Vs,modelOptions:Js,modelSchema:Jo},[lt]:{model:Zs,modelOptions:Ys,modelSchema:Te},[dt]:{model:ni,modelOptions:oi,modelSchema:Oe},[ct]:{model:mi,modelOptions:li,modelSchema:xe},[ut]:{model:ci,modelOptions:pi,modelSchema:Me},[pt]:{model:ii,modelOptions:si,modelSchema:ve},[mt]:{model:ei,modelOptions:Qs,modelSchema:Pe},[ht]:{model:bi,modelOptions:_i,modelSchema:Wo},[gt]:{model:hi,modelOptions:gi,modelSchema:Vo},[on]:{model:wi,modelOptions:Ci,modelSchema:nn},[en]:{model:ki,modelOptions:Si,modelSchema:tn},[Yo]:{model:Pi,modelOptions:Ti,modelSchema:Zo},[Xo]:{model:xi,modelOptions:vi,modelSchema:Qo},[an]:{model:ji,modelOptions:Ri,modelSchema:sn},[rn]:{model:Li,modelOptions:Ai,modelSchema:ln}},this.embeddingModelFactories={[mn]:{model:zi,modelOptions:qi,modelSchema:ke},[dn]:{model:Hi,modelOptions:Fi,modelSchema:Ee},[pn]:{model:Vi,modelOptions:Ji,modelSchema:Ce}};}chatModelLiterals(){return Object.keys(this.chatModelFactories)}chatModelSchemas(){return Object.keys(this.chatModelFactories).reduce((e,t)=>(e[t]=this.chatModelFactories[t].modelSchema,e),{})}chatModel(e){let t=e.modelName;if(!(t in this.chatModelFactories))throw new He({info:`OpenAI chat model: ${t} not found`,cause:new Error(`OpenAI chat model: ${t} not found, available chat models: 
          [${this.chatModelLiterals().join(", ")}]`)});let o=this.chatModelFactories[t].model,s=this.chatModelFactories[t].modelOptions.parse(e);return new o(s)}embeddingModelLiterals(){return Object.keys(this.embeddingModelFactories)}embeddingModelSchemas(){return Object.keys(this.embeddingModelFactories).reduce((e,t)=>(e[t]=this.embeddingModelFactories[t].modelSchema,e),{})}embeddingModel(e){let t=e.modelName;if(!(t in this.embeddingModelFactories))throw new He({info:`OpenAI embedding model: ${t} not found`,cause:new Error(`OpenAI embedding model: ${t} not found, available embedding models: 
          [${this.embeddingModelLiterals().join(", ")}]`)});let o=this.embeddingModelFactories[t].model,s=this.embeddingModelFactories[t].modelOptions.parse(e);return new o(s)}};bt.baseUrl="https://api.openai.com/v1";var T=z$1.enum([ee,te,A,oe]),P={system:ee,user:te,assistant:A,tool:oe},w=[k,K,j,L],I=z$1.enum([k,K,j,L]);z$1.enum([k]);var U=[k,j,L],B=z$1.enum([k,j,L]),pe=z$1.object({token:z$1.string(),logprob:z$1.number(),bytes:z$1.array(z$1.number()).nullable()}),Fo=z$1.object({content:z$1.array(pe.extend({top_logprobs:z$1.array(pe)})).nullable().optional(),refusal:z$1.array(pe.extend({top_logprobs:z$1.array(pe)})).nullable().optional()}).nullable(),is=z$1.array(z$1.object({id:z$1.string().min(1),type:z$1.enum(["function"]),function:z$1.object({name:z$1.string(),arguments:z$1.string()})})),rs=z$1.object({id:z$1.string(),object:z$1.literal("chat.completion"),created:z$1.number(),model:z$1.string(),system_fingerprint:z$1.string().nullable(),choices:z$1.array(z$1.object({index:z$1.number(),message:z$1.object({role:z$1.string(),content:z$1.string().nullable().optional(),tool_calls:is.optional(),refusal:z$1.string().nullable().optional()}),logprobs:Fo.optional(),finish_reason:z$1.string()})),usage:z$1.object({prompt_tokens:z$1.number(),completion_tokens:z$1.number(),total_tokens:z$1.number()})}),ls=z$1.array(z$1.object({index:z$1.number().int(),id:z$1.string().min(1).optional(),type:z$1.enum(["function"]).optional(),function:z$1.object({name:z$1.string().min(1).optional(),arguments:z$1.string().optional()}).optional()})),ms=z$1.object({id:z$1.string(),object:z$1.string(),created:z$1.number(),model:z$1.string(),system_fingerprint:z$1.string().nullable().optional(),choices:z$1.array(z$1.object({index:z$1.number(),delta:z$1.object({content:z$1.string().nullable().optional(),tool_calls:ls.optional(),refusal:z$1.string().nullable().optional()}).or(z$1.object({})),logprobs:Fo.optional(),finish_reason:z$1.string().nullable()})),usage:z$1.object({prompt_tokens:z$1.number(),completion_tokens:z$1.number(),total_tokens:z$1.number()}).nullable().optional()}),ds=z$1.object({type:z$1.literal("function"),function:z$1.object({name:z$1.string().min(1),description:z$1.string().min(1).optional(),strict:z$1.boolean().optional(),parameters:z$1.any()})}),ps=z$1.enum(["none","auto","required"]),cs=z$1.object({type:z$1.literal("function"),function:z$1.object({name:z$1.string().min(1)})}),us=z$1.object({type:z$1.enum(["text","json_object"])}).or(z$1.object({type:z$1.literal("json_schema"),json_schema:z$1.object({name:z$1.string().min(1),description:z$1.string().min(1).optional(),strict:z$1.boolean().optional(),schema:z$1.any()})})),yt=z$1.object({text:z$1.string().min(1),type:z$1.literal("text")}),gs=z$1.object({type:z$1.literal("image_url"),image_url:z$1.object({url:z$1.string().url().min(1),detail:z$1.enum(["low","high","auto"]).optional()})}),hs=z$1.object({id:z$1.string().min(1),type:z$1.literal("function"),function:z$1.object({name:z$1.string().min(1),arguments:z$1.string().min(1)})}),fs=z$1.object({role:z$1.literal("system"),content:z$1.string().min(1).or(z$1.array(yt).min(1))}),_s=z$1.object({role:z$1.literal("user"),content:z$1.string().min(1).or(z$1.array(z$1.union([yt,gs])).min(1))}),bs=z$1.object({role:z$1.literal("assistant"),content:z$1.string().min(1).or(z$1.array(yt).min(1)).optional(),tool_calls:z$1.array(hs).min(1).optional()}),ys=z$1.object({role:z$1.literal("tool"),tool_call_id:z$1.string().min(1),content:z$1.string().min(1)}),Ts=z$1.union([fs,_s,bs,ys]),Ps=z$1.object({model:z$1.string().min(1).optional(),messages:z$1.array(Ts).min(1),frequency_penalty:z$1.number().min(-2).max(2).nullable().optional(),logprobs:z$1.boolean().nullable().optional(),top_logprobs:z$1.number().min(0).max(20).nullable().optional(),max_completion_tokens:z$1.number().min(0).nullable().optional(),presence_penalty:z$1.number().min(-2).max(2).nullable().optional(),response_format:us.optional(),seed:z$1.number().nullable().optional(),stop:z$1.string().or(z$1.array(z$1.string()).max(4)).nullable().optional(),temperature:z$1.number().min(0).max(2).nullable().optional(),top_p:z$1.number().min(0).max(1).nullable().optional(),tools:z$1.array(ds).optional(),tool_choice:ps.or(cs).optional()}),x=z$1.object({modelName:z$1.string(),apiKey:z$1.string(),baseUrl:z$1.string().url().optional(),completeChatUrl:z$1.string().url().optional(),streamChatUrl:z$1.string().url().optional(),organization:z$1.string().optional()}),O=class{constructor(e,t){this.version="v1";let o=x.parse(t);this.modelSchema=e,this.modelName=o.modelName,this.apiKey=o.apiKey,this.baseUrl=X(o.baseUrl||bt.baseUrl),this.streamChatUrl=X(o.streamChatUrl||`${this.baseUrl}/chat/completions`),this.completeChatUrl=X(o.completeChatUrl||`${this.baseUrl}/chat/completions`),this.organization=o.organization;}getDefaultBaseUrl(){return this.baseUrl}getDefaultHeaders(){return E({Authorization:`Bearer ${this.apiKey}`,"Content-Type":"application/json"},this.organization?{"OpenAI-Organization":this.organization}:{})}getDefaultParams(){return {model:this.modelName}}getRetryDelay(e){let t=r=>{let d=/(\d+)(h|m|s|ms)/g,p={h:36e5,m:6e4,s:1e3,ms:1},c,v=0;for(;(c=d.exec(r))!==null;){let g=parseInt(c[1]),M=c[2];v+=g*p[M];}return v},o=0,s=0,i=!0;e["x-ratelimit-reset-requests"]&&(o=t(e["x-ratelimit-reset-requests"])),e["x-ratelimit-reset-tokens"]&&(s=t(e["x-ratelimit-reset-tokens"]));let l=Math.max(o,s);return {shouldRetry:i,delayMs:l}}getTokenCount(e){return e.reduce((t,o)=>t+o.content.map(s=>s.modality==="text"?s.value:"").join(" ").length,0)}transformModelRequest(e){let t=Ps.safeParse(e);if(!t.success)throw new ae({info:"Invalid model request",cause:t.error});let o=t.data,s=o.model;if(o.tool_choice&&(!o.tools||o.tools.length===0))throw new ae({info:`Invalid model request for model : '${this.modelName}'`,cause:new Error("'tools' are required when 'tool_choice' is specified")});let i={};o.response_format&&(i.responseFormat=o.response_format.type,o.response_format.type==="json_schema"&&(i.responseSchema={name:o.response_format.json_schema.name,description:o.response_format.json_schema.description||"",strict:o.response_format.json_schema.strict,schema:o.response_format.json_schema.schema})),o.tool_choice&&(typeof o.tool_choice=="string"?i.toolChoice=o.tool_choice:i.toolChoice=o.tool_choice.function.name),i.seed=o.seed,i.maxTokens=o.max_completion_tokens,i.temperature=o.temperature,i.topP=o.top_p,i.presencePenalty=o.presence_penalty,i.frequencyPenalty=o.frequency_penalty,i.stop=o.stop,i.logProbs=o.logprobs,i.topLogProbs=o.top_logprobs;let l=$e().parse(Xe(i)),r=[],d={};o.messages.forEach(c=>{let v=c.role;switch(v){case"system":{let g=c.content;if(typeof g=="string")r.push({role:v,content:[{modality:k,value:g}]});else {let M=g.map(h=>({modality:k,value:h.text}));r.push({role:v,content:M});}}break;case"user":{let g=c.content;if(typeof g=="string")r.push({role:v,content:[{modality:k,value:g}]});else {let M=g.map(h=>h.type==="text"?{modality:k,value:h.text}:h.image_url.url.startsWith("data:")?{modality:K,detail:h.image_url.detail||"auto",value:{type:Ge,base64:h.image_url.url,mediaType:bo(h.image_url.url)}}:{modality:K,detail:h.image_url.detail||"auto",value:{type:Ae,url:h.image_url.url}});r.push({role:v,content:M});}}break;case"assistant":{let g=[];if(!c.content&&!c.tool_calls)throw new ae({info:`Invalid model request for model : '${this.modelName}'`,cause:new Error("one of'content' or 'tool_calls' must be provided")});if(c.content){let M=c.content;typeof M=="string"?g.push({modality:k,value:M}):M.forEach(h=>{g.push({modality:k,value:h.text});});}c.tool_calls&&c.tool_calls.forEach((M,h)=>{let C={modality:j,id:M.id,index:h,name:M.function.name,arguments:M.function.arguments};g.push(C),d[C.id]=C;}),r.push({role:v,content:g});}break;case"tool":{let g=c;r.push({role:v,content:[{modality:L,id:g.tool_call_id,index:d[g.tool_call_id].index,name:d[g.tool_call_id].name,data:g.content}]});}break}});let p=[];return o.tools&&o.tools.forEach(c=>{p.push({type:"function",definition:{schema:{name:c.function.name,description:c.function.description||"",strict:c.function.strict,parameters:c.function.parameters}}});}),{modelName:s,config:l,messages:r,tools:p.length>0?p:void 0}}transformConfig(e,t,o){let s=e.toolChoice;delete e.toolChoice;let i=this.modelSchema.config.schema.safeParse(e);if(!i.success)throw new F({info:`Invalid config for model : '${this.modelName}'`,cause:i.error});let l=i.data;s!==void 0&&(l.toolChoice=s),Object.keys(l).forEach(d=>{if(!(d in this.modelSchema.config.def))throw new F({info:`Invalid config for model : '${this.modelName}'`,cause:new Error(`Invalid config key : '${d}', 
            available keys : [${Object.keys(this.modelSchema.config.def).join(", ")}]`)})});let r=Object.keys(l).reduce((d,p)=>{let c=this.modelSchema.config.def[p],v=c.param,g=l[p];return v==="max_completion_tokens"&&c.type==="range"&&g===0?d[v]=c.max:d[v]=g,d},{});if(r.top_logprobs&&!r.logprobs)throw new F({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'logprobs' must be 'true' when 'top_logprobs' is specified")});if("tool_choice"in r&&r.tool_choice!==void 0){let d=r.tool_choice;if(!o||o&&o.length===0)throw new F({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'tools' are required when 'toolChoice' is specified")});if(o&&o.length>0){let p=this.modelSchema.config.def.toolChoice;if(!p.choices.includes(d))if(o.map(c=>c.definition.schema.name).includes(d))r.tool_choice={type:"function",function:{name:d}};else throw new F({info:`Invalid config for model : '${this.modelName}'`,cause:new Error(`toolChoice : '${d}' is not part of provided 'tools' names or 
                one of [${p.choices.join(", ")}]`)})}}if("response_format"in r&&r.response_format!==void 0){let d=r.response_format;if(d==="json_schema")if("response_schema"in r)r.response_format={type:"json_schema",json_schema:r.response_schema},delete r.response_schema;else throw new F({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'responseSchema' is required in config when 'responseFormat' is 'json_schema'")});else r.response_format={type:d};}return r}transformMessages(e){if(!e||e&&e.length===0)return {messages:[]};let t=e.map(o=>{let s=Ue().safeParse(o);if(!s.success)throw new G({info:"Invalid messages",cause:s.error});return s.data});return t.forEach(o=>{o.content.forEach(s=>{if(!this.modelSchema.modalities.includes(s.modality))throw new G({info:`Invalid message content for model : '${this.modelName}'`,cause:new Error(`model : '${this.modelName}' does not support modality : '${s.modality}', 
              available modalities : [${this.modelSchema.modalities.join(", ")}]`)})});}),t.forEach(o=>{if(!Object.keys(this.modelSchema.roles).includes(o.role))throw new G({info:`Invalid message content for model : '${this.modelName}'`,cause:new Error(`model : '${this.modelName}' does not support role : '${o.role}', 
            available roles : [${Object.keys(this.modelSchema.roles).join(", ")}]`)})}),{messages:t.map(o=>{switch(o.role){case ee:{let s=[];return o.content.forEach(i=>{if(i.modality===k)s.push({type:"text",text:i.value});else throw new G({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${o.role}' cannot have content with modality : '${i.modality}'`)})}),{role:this.modelSchema.roles[o.role],content:s}}case A:{let s=[],i=[];return o.content.forEach(l=>{if(l.modality===k)s.push({type:"text",text:l.value});else if(l.modality===j)i.push({id:l.id,type:"function",function:{name:l.name,arguments:l.arguments}});else throw new G({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${o.role}' cannot have content with modality : '${l.modality}'`)})}),E({role:this.modelSchema.roles[o.role],content:s},i.length>0?{tool_calls:i}:{})}case te:{let s=[],i=[];o.content.forEach(r=>{if(r.modality===k)s.push({type:"text",text:r.value});else if(r.modality===K)i.push({type:"image_url",image_url:{url:r.value.type==="url"?r.value.url:r.value.base64,detail:r.detail}});else throw new G({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${o.role}' cannot have content with modality : '${r.modality}'`)})});let l=[...s,...i];return {role:this.modelSchema.roles[o.role],content:l}}case oe:{if(o.content.length!==1)throw new G({info:`Invalid message for role : '${o.role}'`,cause:new Error(`role : '${o.role}' must have exactly one content item`)});if(o.content[0].modality!==L)throw new G({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${o.role}' must have content with modality : '${L}'`)});let s=o.content[0];return {role:this.modelSchema.roles[o.role],tool_call_id:s.id,content:s.data}}default:throw new G({info:`Invalid message 'role' for model : ${this.modelName}`,cause:new Error(`role : '${o.role}' is not supported, 
              available roles : [${Object.keys(this.modelSchema.roles).join(", ")}]`)})}})}}transformTools(e){if(!this.modelSchema.modalities.includes(j))throw new Ke({info:`Invalid tool 'modality' for model : ${this.modelName}`,cause:new Error(`model : '${this.modelName}' does not support tool modality : '${j}'`)});return !e||e&&e.length===0?{tools:[]}:{tools:e.map(t=>{let o=$t().safeParse(t);if(!o.success)throw new Ke({info:"Invalid tools",cause:o.error});return o.data}).map(t=>({type:"function",function:t.definition.schema}))}}getCompleteChatUrl(e,t,o){return R(this,null,function*(){return new Promise(s=>{s(this.completeChatUrl);})})}getCompleteChatHeaders(e,t,o){return R(this,null,function*(){return new Promise(s=>{s(this.getDefaultHeaders());})})}getCompleteChatData(e,t,o){return R(this,null,function*(){let s=this.transformConfig(e,t,o),i=this.transformMessages(t);if(i.messages&&i.messages.length===0)throw new G({info:"Messages are required",cause:new Error("Messages are required")});let l=o?this.transformTools(o):{};return new Promise(r=>{r(E(E(E(E({},this.getDefaultParams()),s),i),l));})})}transformCompleteChatResponse(e){let t=rs.safeParse(e);if(t.success){if(t.data.choices.length===0)throw new D({info:"Invalid response from model",cause:new Error(`No choices in response : ${JSON.stringify(t.data)}`)});let o=t.data,s=[{role:A,content:[]}],i=o.choices[0].message;i.content&&s[0].content.push(De(i.content)),i.refusal&&s[0].content.push(De(i.refusal)),i.tool_calls&&i.tool_calls.forEach((p,c)=>{s[0].content.push(qt(c,p.id,p.function.name,p.function.arguments));});let l={promptTokens:o.usage.prompt_tokens,completionTokens:o.usage.completion_tokens,totalTokens:o.usage.total_tokens},r=[],d=o.choices[0].logprobs;return d&&(d.content&&r.push(...d.content.map(p=>({token:p.token,logProb:p.logprob,bytes:p.bytes,topLogProbs:p.top_logprobs.map(c=>({token:c.token,logProb:c.logprob,bytes:c.bytes}))}))),d.refusal&&r.push(...d.refusal.map(p=>({token:p.token,logProb:p.logprob,bytes:p.bytes,topLogProbs:p.top_logprobs.map(c=>({token:c.token,logProb:c.logprob,bytes:c.bytes}))})))),{messages:s,usage:l,logProbs:r}}throw new D({info:"Invalid response from model",cause:t.error})}getStreamChatUrl(e,t,o){return R(this,null,function*(){return new Promise(s=>{s(this.streamChatUrl);})})}getStreamChatHeaders(e,t,o){return R(this,null,function*(){return new Promise(s=>{s(this.getDefaultHeaders());})})}getStreamChatData(e,t,o){return R(this,null,function*(){let s=this.transformConfig(e,t,o),i=this.transformMessages(t);if(i.messages&&i.messages.length===0)throw new G({info:"Messages are required",cause:new Error("Messages are required")});let l=o?this.transformTools(o):{};return new Promise(r=>{r(E(E(E(E({stream:!0,stream_options:{include_usage:!0}},this.getDefaultParams()),s),i),l));})})}transformStreamChatResponseChunk(e,t){return Po(this,null,function*(){var o,s;let i=t+e,l=[],r="",d=0;for(;d<i.length;){let p=i.indexOf(`
`,d);if(p===-1){r=i.substring(d);break}else {let c=i.substring(d,p).trim();c&&l.push(c),d=p+1;}}for(let p of l){if(p==="data: [DONE]")return;if(p.startsWith("data: ")){let c=p.substring(6);try{let v=JSON.parse(c),g=ms.safeParse(v);if(g.success){let M={partialMessages:[]},h=g.data;if(h.choices.length>0){let C=h.choices[0].delta;if(C!==void 0&&Object.keys(C).length!==0){if("content"in C&&C.content!==null)M.partialMessages.push(Fe(A,C.content));else if("refusal"in C&&C.refusal!==null)M.partialMessages.push(Fe(A,C.refusal));else if("tool_calls"in C&&C.tool_calls!==void 0){let me=C.tool_calls.at(0);M.partialMessages.push(zt(A,me.index,me.id,(o=me.function)==null?void 0:o.name,(s=me.function)==null?void 0:s.arguments));}}}h.usage&&(M.usage={promptTokens:h.usage.prompt_tokens,completionTokens:h.usage.completion_tokens,totalTokens:h.usage.total_tokens}),yield {partialResponse:M,buffer:r};}else throw new D({info:"Invalid response from model",cause:g.error})}catch(v){throw new D({info:`Malformed JSON received in stream: ${c}`,cause:v})}}}yield {partialResponse:{partialMessages:[]},buffer:r};})}transformProxyStreamChatResponseChunk(e,t,o,s,i){return Po(this,null,function*(){yield*Ot(Xa(this.transformStreamChatResponseChunk(e,t)));})}getProxyStreamChatUrl(e,t,o){return R(this,null,function*(){return new Promise(s=>{s(this.streamChatUrl);})})}getProxyCompleteChatUrl(e,t,o){return R(this,null,function*(){return new Promise(s=>{s(this.completeChatUrl);})})}getProxyCompleteChatHeaders(e,t,o){return R(this,null,function*(){if(!t)return {};let s=E({},t);return delete s.host,delete s["content-length"],s})}getProxyStreamChatHeaders(e,t,o){return R(this,null,function*(){return yield this.getProxyCompleteChatHeaders(e,t,o)})}getModelPricing(){if(!(this.modelName in S))throw new D({info:`Invalid model pricing for model : '${this.modelName}'`,cause:new Error(`No pricing configuration found for model "${this.modelName}"`)});return S[this.modelName]}},Qe="gpt-3.5-turbo-0125",Os="The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a   text encoding issue for non-English language function calls. Training data up to Sept 2021.",ge=y(T,B).parse({name:Qe,description:Os,maxInputTokens:4092,maxOutputTokens:4092,roles:P,modalities:U,config:{def:u.responseFormat(4092,4).def,schema:u.responseFormat(4092,4).schema},price:S[Qe]}),vs=x,xs=class extends O{constructor(e){super(ge,e);}},et="gpt-3.5-turbo-1106",Ms="The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.   Returns a maximum of 4,096 output tokens. Training data up to Sept 2021.",he=y(T,B).parse({name:et,description:Ms,maxInputTokens:4092,maxOutputTokens:16385,roles:P,modalities:U,config:{def:u.responseFormat(16385,4).def,schema:u.responseFormat(16385,4).schema},price:S[et]}),Ss=x,ks=class extends O{constructor(e){super(he,e);}},tt="gpt-3.5-turbo",Es="Currently points to gpt-3.5-turbo-0125. Training data up to Sept 2021.",fe=y(T,B).parse({name:tt,description:Es,maxInputTokens:4092,maxOutputTokens:4092,roles:P,modalities:U,config:{def:u.responseFormat(4092,4).def,schema:u.responseFormat(4092,4).schema},price:S[tt]}),Cs=x,ws=class extends O{constructor(e){super(fe,e);}},ot="gpt-4-0125-preview",Is="The latest GPT-4 model intended to reduce cases of \u201Claziness\u201D where the model doesn\u2019t complete a task. Training data up to Apr 2023.",Ho=y(T,B).parse({name:ot,description:Is,maxInputTokens:128e3,maxOutputTokens:4092,roles:P,modalities:U,config:{def:u.base(4092,4).def,schema:u.base(4092,4).schema},price:S[ot]}),Rs=x,js=class extends O{constructor(e){super(Ho,e);}},nt="gpt-4-0613",Gs="Snapshot of gpt-4 from June 13th 2023 with improved function calling support. Training data up to Sept 2021.",_e=y(T,B).parse({name:nt,description:Gs,maxInputTokens:8192,maxOutputTokens:4092,roles:P,modalities:U,config:{def:u.base(4092,4).def,schema:u.base(4092,4).schema},price:S[nt]}),As=x,Ls=class extends O{constructor(e){super(_e,e);}},at="gpt-4-1106-preview",Ns="GPT-4 Turbo model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.   Returns a maximum of 4,096 output tokens. This preview model is not yet suited for production traffic. Training data up to Apr 2023.",be=y(T,B).parse({name:at,description:Ns,maxInputTokens:128e3,maxOutputTokens:4092,roles:P,modalities:U,config:{def:u.base(4092,4).def,schema:u.base(4092,4).schema},price:S[at]}),Us=x,Bs=class extends O{constructor(e){super(be,e);}},st="gpt-4-turbo-2024-04-09",$s="GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. gpt-4-turbo currently points to this version.   Training data up to Dec 2023.",ye=y(T,I).parse({name:st,description:$s,maxInputTokens:128e3,maxOutputTokens:4096,roles:P,modalities:w,config:{def:u.responseFormat(4096,4).def,schema:u.responseFormat(4096,4).schema},price:S[st]}),qs=x,zs=class extends O{constructor(e){super(ye,e);}},it="gpt-4-turbo-preview",Ds="Currently points to gpt-4-0125-preview. Training data up to Apr 2023.",Ko=y(T,B).parse({name:it,description:Ds,maxInputTokens:128e3,maxOutputTokens:4092,roles:P,modalities:U,config:{def:u.responseFormat(4092,4).def,schema:u.responseFormat(4092,4).schema},price:S[it]}),Fs=x,Hs=class extends O{constructor(e){super(Ko,e);}},rt="gpt-4-turbo",Ks="The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.   Currently points to gpt-4-turbo-2024-04-09. Training data up to Dec 2023.",Jo=y(T,I).parse({name:rt,description:Ks,maxInputTokens:128e3,maxOutputTokens:4092,roles:P,modalities:w,config:{def:u.responseFormat(4092,4).def,schema:u.responseFormat(4092,4).schema},price:S[rt]}),Js=x,Vs=class extends O{constructor(e){super(Jo,e);}},lt="gpt-4",Ws="Currently points to gpt-4-0613. Training data up to Sept 2021.",Te=y(T,B).parse({name:lt,description:Ws,maxInputTokens:8192,maxOutputTokens:4092,roles:P,modalities:U,config:{def:u.base(4092,4).def,schema:u.base(4092,4).schema},price:S[lt]}),Ys=x,Zs=class extends O{constructor(e){super(Te,e);}},mt="gpt-4o-2024-05-13",Xs="Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.",Pe=y(T,I).parse({name:mt,description:Xs,maxInputTokens:128e3,maxOutputTokens:4092,roles:P,modalities:w,config:{def:u.responseSchema(4092,4).def,schema:u.responseSchema(4092,4).schema},price:S[mt]}),Qs=x,ei=class extends O{constructor(e){super(Pe,e);}},dt="gpt-4o-2024-08-06",ti="Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.",Oe=y(T,I).parse({name:dt,description:ti,maxInputTokens:128e3,maxOutputTokens:4092,roles:P,modalities:w,config:{def:u.responseSchema(4092,4).def,schema:u.responseSchema(4092,4).schema},price:S[dt]}),oi=x,ni=class extends O{constructor(e){super(Oe,e);}},pt="gpt-4o-mini-2024-07-18",ai="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",ve=y(T,I).parse({name:pt,description:ai,maxInputTokens:128e3,maxOutputTokens:4092,roles:P,modalities:w,config:{def:u.responseSchema(4092,4).def,schema:u.responseSchema(4092,4).schema},price:S[pt]}),si=x,ii=class extends O{constructor(e){super(ve,e);}},ct="gpt-4o-mini",ri="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",xe=y(T,I).parse({name:ct,description:ri,maxInputTokens:128e3,maxOutputTokens:4092,roles:P,modalities:w,config:{def:u.responseSchema(4092,4).def,schema:u.responseSchema(4092,4).schema},price:S[ct]}),li=x,mi=class extends O{constructor(e){super(xe,e);}},ut="gpt-4o",di="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",Me=y(T,I).parse({name:ut,description:di,maxInputTokens:128e3,maxOutputTokens:4092,roles:P,modalities:w,config:{def:u.responseSchema(4092,4).def,schema:u.responseSchema(4092,4).schema},price:S[ut]}),pi=x,ci=class extends O{constructor(e){super(Me,e);}},gt="o1-2024-12-17",ui="A stable release model for production use, offering robust performance and advanced features. Training data up to December 2024.",Vo=y(T,I).parse({name:gt,description:ui,maxInputTokens:2e5,maxOutputTokens:1e5,roles:P,modalities:w,config:{def:u.oSeries(1e5,4).def,schema:u.oSeries(1e5,4).schema},price:S[gt]}),gi=x,hi=class extends O{constructor(e){super(Vo,e);}},ht="o1",fi="Highly capable general-purpose reasoning model with advanced capabilities in language, coding, and reasoning. Training data up to Oct 2023.",Wo=y(T,I).parse({name:ht,description:fi,maxInputTokens:2e5,maxOutputTokens:1e5,roles:P,modalities:w,config:{def:u.oSeries(1e5,4).def,schema:u.oSeries(1e5,4).schema},price:S[ht]}),_i=x,bi=class extends O{constructor(e){super(Wo,e);}},Yo="o3-2025-04-16",yi="A new standard for math, science, coding, and visual reasoning tasks. Training data up to Jun 2024.",Zo=y(T,I).parse({name:Yo,description:yi,maxInputTokens:2e5,maxOutputTokens:1e5,roles:P,modalities:w,config:{def:u.oSeries(1e5,4).def,schema:u.oSeries(1e5,4).schema}}),Ti=x,Pi=class extends O{constructor(e){super(Zo,e);}},Xo="o3",Oi="A new standard for math, science, coding, and visual reasoning tasks. Training data up to Jun 2024.",Qo=y(T,I).parse({name:Xo,description:Oi,maxInputTokens:2e5,maxOutputTokens:1e5,roles:P,modalities:w,config:{def:u.oSeries(1e5,4).def,schema:u.oSeries(1e5,4).schema}}),vi=x,xi=class extends O{constructor(e){super(Qo,e);}},en="o3-mini",Mi="o3-mini is the newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. Training data up to Sep 2023.",tn=y(T,B).parse({name:en,description:Mi,maxInputTokens:2e5,maxOutputTokens:1e5,roles:P,modalities:U,config:{def:u.oSeries(1e5,4).def,schema:u.oSeries(1e5,4).schema}}),Si=x,ki=class extends O{constructor(e){super(tn,e);}},on="o3-mini-2025-01-31",Ei="o3-mini is the newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. Training data up to Sep 2023.",nn=y(T,B).parse({name:on,description:Ei,maxInputTokens:2e5,maxOutputTokens:1e5,roles:P,modalities:U,config:{def:u.oSeries(1e5,4).def,schema:u.oSeries(1e5,4).schema}}),Ci=x,wi=class extends O{constructor(e){super(nn,e);}},an="o4-mini-2025-04-16",Ii="Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. Training data up to Jun 2024.",sn=y(T,I).parse({name:an,description:Ii,maxInputTokens:2e5,maxOutputTokens:1e5,roles:P,modalities:w,config:{def:u.oSeries(1e5,4).def,schema:u.oSeries(1e5,4).schema}}),Ri=x,ji=class extends O{constructor(e){super(sn,e);}},rn="o4-mini",Gi="Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. Training data up to Jun 2024.",ln=y(T,I).parse({name:rn,description:Gi,maxInputTokens:2e5,maxOutputTokens:1e5,roles:P,modalities:w,config:{def:u.oSeries(1e5,4).def,schema:u.oSeries(1e5,4).schema}}),Ai=x,Li=class extends O{constructor(e){super(ln,e);}},se=[J,W],ie=z$1.enum([J,W]),Ni=z$1.object({object:z$1.literal("list"),model:z$1.string(),data:z$1.array(z$1.object({index:z$1.number(),object:z$1.literal("embedding"),embedding:z$1.array(z$1.number()).or(z$1.string().base64())})),usage:z$1.object({prompt_tokens:z$1.number().nonnegative(),total_tokens:z$1.number().nonnegative()})}),Ui=z$1.string().min(1).or(z$1.array(z$1.string().min(1)).min(1)).or(z$1.array(z$1.number().int().nonnegative()).min(1)).or(z$1.array(z$1.array(z$1.number().int().nonnegative()).min(1)).min(1)),Bi=z$1.object({model:z$1.string().min(1).optional(),input:Ui,encoding_format:z$1.enum(["float","base64"]).optional(),dimensions:z$1.number().int().min(1).optional()}),Se=z$1.object({modelName:z$1.string(),apiKey:z$1.string(),baseUrl:z$1.string().url().optional(),getEmbeddingsUrl:z$1.string().url().optional()}),re=class{constructor(e,t){this.version="v1";let o=Se.parse(t);this.modelSchema=e,this.modelName=o.modelName,this.apiKey=o.apiKey,this.baseUrl=X(o.baseUrl||bt.baseUrl),this.getEmbeddingsUrl=X(o.getEmbeddingsUrl||`${this.baseUrl}/embeddings`);}getDefaultBaseUrl(){return this.baseUrl}getDefaultHeaders(){return {Authorization:`Bearer ${this.apiKey}`,"Content-Type":"application/json"}}getDefaultParams(){return {model:this.modelSchema.name}}getRetryDelay(e){let t=r=>{let d=/(\d+)(h|m|s|ms)/g,p={h:36e5,m:6e4,s:1e3,ms:1},c,v=0;for(;(c=d.exec(r))!==null;){let g=parseInt(c[1]),M=c[2];v+=g*p[M];}return v},o=0,s=0,i=!0;e["x-ratelimit-reset-requests"]&&(o=t(e["x-ratelimit-reset-requests"])),e["x-ratelimit-reset-tokens"]&&(s=t(e["x-ratelimit-reset-tokens"]));let l=Math.max(o,s);return {shouldRetry:i,delayMs:l}}getTokenCount(e){return e.requests.reduce((t,o)=>t+o.length,0)}transformModelRequest(e){let t=Bi.safeParse(e);if(!t.success)throw new ae({info:"Invalid model request",cause:t.error});let o=t.data,s=o.model,i={encodingFormat:o.encoding_format,dimensions:o.dimensions},l=$e().parse(Xe(i)),r,d;return typeof o.input=="string"?d=J:typeof o.input[0]=="string"?d=J:d=W,d===J?typeof o.input=="string"?r={modality:d,requests:[o.input]}:r={modality:d,requests:o.input}:typeof o.input[0]=="number"?r={modality:d,requests:[o.input]}:r={modality:d,requests:o.input},{modelName:s,config:l,embeddingRequests:r}}transformConfig(e,t){let o=this.modelSchema.config.schema.safeParse(e);if(!o.success)throw new F({info:`Invalid config for model : '${this.modelSchema.name}'`,cause:o.error});let s=o.data;return Object.keys(s).forEach(i=>{if(!this.modelSchema.config.def[i])throw new F({info:`Invalid config for model : '${this.modelSchema.name}'`,cause:new Error(`Invalid config key : '${i}', 
            available keys : [${Object.keys(this.modelSchema.config.def).join(", ")}]`)})}),Object.keys(s).reduce((i,l)=>{let r=this.modelSchema.config.def[l].param,d=s[l];return i[r]=d,i},{})}transformEmbeddingRequests(e){let t=Ut().safeParse(e);if(!t.success)throw new io({info:"Invalid embedding requests",cause:t.error});return {input:t.data.requests}}getGetEmbeddingsUrl(e,t){return R(this,null,function*(){return new Promise(o=>{o(this.getEmbeddingsUrl);})})}getGetEmbeddingsHeaders(e,t){return R(this,null,function*(){return new Promise(o=>{o(this.getDefaultHeaders());})})}getGetEmbeddingsData(e,t){return R(this,null,function*(){return new Promise(o=>{o(E(E(E({},this.getDefaultParams()),this.transformConfig(e,t)),this.transformEmbeddingRequests(t)));})})}transformGetEmbeddingsResponse(e){let t,o=Ni.safeParse(e);if(o.success){let s=o.data;t=typeof s.data[0].embedding=="string"?ze:qe;let i=s.data.map(l=>typeof l.embedding=="string"?{index:l.index,embedding:l.embedding}:{index:l.index,embedding:l.embedding});return {encodingFormat:t,embeddings:i,usage:{totalTokens:s.usage.total_tokens}}}throw new D({info:"Invalid response from model",cause:o.error})}},mn="text-embedding-ada-002",$i="Most capable 2nd generation embedding model, replacing 16 first generation models",ke=Z(ie).parse({name:mn,description:$i,modalities:se,maxInputTokens:8192,maxOutputTokens:1536,config:{def:H.base().def,schema:H.base().schema}}),qi=Se,zi=class extends re{constructor(e){super(ke,e);}},dn="text-embedding-3-small",Di="Increased performance over 2nd generation ada embedding model",Ee=Z(ie).parse({name:dn,description:Di,modalities:se,maxInputTokens:8192,maxOutputTokens:1536,config:{def:H.dimensions(1536).def,schema:H.dimensions(1536).schema}}),Fi=Se,Hi=class extends re{constructor(e){super(Ee,e);}},pn="text-embedding-3-large",Ki="Most capable embedding model for both english and non-english tasks",Ce=Z(ie).parse({name:pn,description:Ki,modalities:se,maxInputTokens:8192,maxOutputTokens:3072,config:{def:H.dimensions(3072).def,schema:H.dimensions(3072).schema}}),Ji=Se,Vi=class extends re{constructor(e){super(Ce,e);}};var Tt=y(T,I).parse({name:"__base__",description:"Base chat model for Azure OpenAI",maxInputTokens:128e3,maxOutputTokens:128e3,roles:P,modalities:w,config:{def:u.base(128e3,4).def,schema:u.base(128e3,4).schema}});var _=class extends O{constructor(o,s){let i=f.parse(s),l;if(i.baseUrl)l=i.baseUrl;else if(i.resourceName)l=V.azureUrl(i.resourceName,"openai");else throw new de({info:"Either 'baseUrl' or 'resourceName' must be provided",cause:new Error("Either 'baseUrl' or 'resourceName' must be provided")});let r="2024-06-01",d=`${l}/openai/deployments/${i.deploymentId}`;super(o,{modelName:i.deploymentId,apiKey:i.apiKey,baseUrl:d,completeChatUrl:`${d}/chat/completions?api-version=${r}`,streamChatUrl:`${d}/chat/completions?api-version=${r}`});this.version="v1";this.modelSchema=o,this.deploymentId=i.deploymentId,this.azureApiKey=i.apiKey,this.azureApiVersion=r;}getDefaultHeaders(){return {"Content-Type":"application/json","api-key":this.azureApiKey,source:"adaline"}}getModelPricing(){throw new D({info:`Invalid model pricing for model : '${this.modelName}'`,cause:new Error("Pricing configuration not supported azure provider.")})}};var Ml="gpt-4o",Wi=Me,Sl=f,cn=class extends _{constructor(t){super(Wi,t);}};var Il="gpt-4o-mini",Yi=xe,Rl=f,un=class extends _{constructor(t){super(Yi,t);}};var Nl="gpt-4o-mini-2024-07-18",Zi=ve,Ul=f,gn=class extends _{constructor(t){super(Zi,t);}};var Dl="gpt-4o-2024-08-06",Xi=Oe,Fl=f,hn=class extends _{constructor(t){super(Xi,t);}};var Wl="gpt-4o-2024-05-13",Qi=Pe,Yl=f,fn=class extends _{constructor(t){super(Qi,t);}};var tm="gpt-4",er=Te,om=f,_n=class extends _{constructor(t){super(er,t);}};var rm="gpt-4-turbo-2024-04-09",tr=ye,lm=f,bn=class extends _{constructor(t){super(tr,t);}};var um="gpt-4-1106-preview",or=be,gm=f,yn=class extends _{constructor(t){super(or,t);}};var ym="gpt-4-0613",nr=_e,Tm=f,Tn=class extends _{constructor(t){super(nr,t);}};var Mm="gpt-3-5-turbo",ar=fe,Sm=f,Pn=class extends _{constructor(t){super(ar,t);}};var Im="gpt-3-5-turbo-1106",sr=he,Rm=f,On=class extends _{constructor(t){super(sr,t);}};var Nm="gpt-3-5-turbo-0125",ir=ge,Um=f,vn=class extends _{constructor(t){super(ir,t);}};var $=z$1.object({apiKey:z$1.string().min(1),deploymentId:z$1.string().min(1),resourceName:z$1.string().min(1).optional(),baseUrl:z$1.string().optional()});var Pt=Z(ie).parse({name:"__base__",description:"Base embedding model for Azure OpenAI",maxInputTokens:8192,maxOutputTokens:3072,modalities:se,config:{def:H.dimensions(3072).def,schema:H.dimensions(3072).schema}});var q=class extends re{constructor(o,s){let i=$.parse(s),l;if(i.baseUrl)l=i.baseUrl;else if(i.resourceName)l=V.azureUrl(i.resourceName,"openai");else throw new de({info:"Either 'baseUrl' or 'resourceName' must be provided",cause:new Error("Either 'baseUrl' or 'resourceName' must be provided")});let r="2024-06-01",d=`${l}/openai/deployments/${i.deploymentId}`;super(o,{modelName:i.deploymentId,apiKey:i.apiKey,baseUrl:d,getEmbeddingsUrl:`${d}/embeddings?api-version=${r}`});this.version="v1";this.modelSchema=o,this.deploymentId=i.deploymentId,this.azureApiKey=i.apiKey,this.azureApiVersion=r;}getDefaultHeaders(){return {"Content-Type":"application/json","api-key":this.azureApiKey,source:"adaline"}}};var od="text-embedding-3-large",rr=Ce,nd=$,xn=class extends q{constructor(t){super(rr,t);}};var ld="text-embedding-ada-002",lr=ke,md=$,Mn=class extends q{constructor(t){super(lr,t);}};var gd="text-embedding-3-small",mr=Ee,hd=$,Sn=class extends q{constructor(t){super(mr,t);}};var dr="azure",V=class{constructor(){this.version="v1";this.name=dr;}chatModelLiterals(){return ["__base__"]}chatModelSchemas(){return {__base__:Tt}}chatModel(t){let o=_,s=f.parse(t);return new o(Tt,s)}embeddingModelLiterals(){return ["__base__"]}embeddingModelSchemas(){return {__base__:Pt}}embeddingModel(t){let o=q,s=$.parse(t);return new o(Pt,s)}};V.azureUrl=(t,o)=>`https://${t}.${o}.azure.com`;

export { V as Azure, _ as BaseChatModelOpenAI, f as BaseChatModelOptions, Tt as BaseChatModelSchema, q as BaseEmbeddingModelOpenAI, $ as BaseEmbeddingModelOptions, Pt as BaseEmbeddingModelSchema, Pn as GPT_3_5_Turbo, Mm as GPT_3_5_TurboLiteral, Sm as GPT_3_5_TurboOptions, ar as GPT_3_5_TurboSchema, vn as GPT_3_5_Turbo_0125, Nm as GPT_3_5_Turbo_0125Literal, Um as GPT_3_5_Turbo_0125Options, ir as GPT_3_5_Turbo_0125Schema, On as GPT_3_5_Turbo_1106, Im as GPT_3_5_Turbo_1106Literal, Rm as GPT_3_5_Turbo_1106Options, sr as GPT_3_5_Turbo_1106Schema, _n as GPT_4, tm as GPT_4Literal, om as GPT_4Options, er as GPT_4Schema, Tn as GPT_4_0613, ym as GPT_4_0613Literal, Tm as GPT_4_0613Options, nr as GPT_4_0613Schema, yn as GPT_4_1106_Preview, um as GPT_4_1106_PreviewLiteral, gm as GPT_4_1106_PreviewOptions, or as GPT_4_1106_PreviewSchema, bn as GPT_4_Turbo_2024_04_09, rm as GPT_4_Turbo_2024_04_09Literal, lm as GPT_4_Turbo_2024_04_09Options, tr as GPT_4_Turbo_2024_04_09Schema, cn as GPT_4o, Ml as GPT_4oLiteral, Sl as GPT_4oOptions, Wi as GPT_4oSchema, fn as GPT_4o_2024_05_13, Wl as GPT_4o_2024_05_13Literal, Yl as GPT_4o_2024_05_13Options, Qi as GPT_4o_2024_05_13Schema, hn as GPT_4o_2024_08_06, Dl as GPT_4o_2024_08_06Literal, Fl as GPT_4o_2024_08_06Options, Xi as GPT_4o_2024_08_06Schema, un as GPT_4o_Mini, Il as GPT_4o_MiniLiteral, Rl as GPT_4o_MiniOptions, Yi as GPT_4o_MiniSchema, gn as GPT_4o_Mini_2024_07_18, Nl as GPT_4o_Mini_2024_07_18Literal, Ul as GPT_4o_Mini_2024_07_18Options, Zi as GPT_4o_Mini_2024_07_18Schema, xn as Text_Embedding_3_Large, od as Text_Embedding_3_LargeLiteral, nd as Text_Embedding_3_LargeOptions, rr as Text_Embedding_3_LargeSchema, Sn as Text_Embedding_3_Small, gd as Text_Embedding_3_SmallLiteral, hd as Text_Embedding_3_SmallOptions, mr as Text_Embedding_3_SmallSchema, Mn as Text_Embedding_Ada_002, ld as Text_Embedding_Ada_002Literal, md as Text_Embedding_Ada_002Options, lr as Text_Embedding_Ada_002Schema };
//# sourceMappingURL=index.mjs.map
//# sourceMappingURL=index.mjs.map