import { RangeConfigItem, CHAT_CONFIG, MultiStringConfigItem, SelectStringConfigItem, ChatModelSchema, InvalidMessagesError, ModelResponseError, ProviderError } from '@adaline/provider';
import { z as z$1 } from 'zod';
import { OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum, OpenAIChatModelRolesMap, OpenAIChatModelTextToolModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelModalities, BaseChatModel } from '@adaline/openai';

var a={"gemma2-9b-it":{modelName:"gemma2-9b-it",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.2,outputPricePerMillion:.2}}}]},"llama-3.1-8b-instant":{modelName:"llama-3.1-8b-instant",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.05,outputPricePerMillion:.08}}}]},"llama-3.2-11b-vision-preview":{modelName:"llama-3.2-11b-vision-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.18,outputPricePerMillion:.18}}}]},"llama-3.2-1b-preview":{modelName:"llama-3.2-1b-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.04,outputPricePerMillion:.04}}}]},"llama-3.2-3b-preview":{modelName:"llama-3.2-3b-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.06,outputPricePerMillion:.06}}}]},"llama-3.2-90b-vision-preview":{modelName:"llama-3.2-90b-vision-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.7,outputPricePerMillion:.8}}}]},"llama3-70b-8192":{modelName:"llama3-70b-8192",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.59,outputPricePerMillion:.79}}}]},"llama3-8b-8192":{modelName:"llama3-8b-8192",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.05,outputPricePerMillion:.08}}}]},"llama-guard-3-8b":{modelName:"llama-guard-3-8b",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.2,outputPricePerMillion:.2}}}]}};var n=z$1.object({modelName:z$1.string().min(1),apiKey:z$1.string().min(1)}),t=class extends BaseChatModel{constructor(i,c){let r=n.parse(c),p=h.baseUrl;super(i,{modelName:r.modelName,apiKey:r.apiKey,baseUrl:p,completeChatUrl:`${p}/chat/completions`,streamChatUrl:`${p}/chat/completions`});this.version="v1";this.modelSchema=i,this.modelName=r.modelName,this.groqApiKey=r.apiKey;}transformMessages(i){let c=i.some(l=>l.role==="system"),r=i.some(l=>l.content.some(_=>_.modality==="image"));if(c&&r)throw new InvalidMessagesError({info:`Invalid message content for model : '${this.modelName}'`,cause:new Error("Prompting with images is incompatible with system messages`)")});let p=super.transformMessages(i);return p.messages.forEach(l=>{l.role==="system"?typeof l.content!="string"&&(l.content=l.content.map(_=>_.text).join(`
`)):l.role==="assistant"&&l.content&&typeof l.content!="string"&&(l.content=l.content.map(_=>_.text).join(`
`));}),p}getModelPricing(){if(!(this.modelName in a))throw new ModelResponseError({info:`Invalid model pricing for model : '${this.modelName}'`,cause:new Error(`No pricing configuration found for model "${this.modelName}"`)});return a[this.modelName]}};var v=RangeConfigItem({param:"temperature",title:CHAT_CONFIG.TEMPERATURE.title,description:CHAT_CONFIG.TEMPERATURE.description,min:0,max:2,step:.01,default:1}),N=s=>RangeConfigItem({param:"max_tokens",title:CHAT_CONFIG.MAX_TOKENS.title,description:CHAT_CONFIG.MAX_TOKENS.description,min:0,max:s,step:1,default:0}),q=MultiStringConfigItem({param:"stop",title:CHAT_CONFIG.STOP(4).title,description:CHAT_CONFIG.STOP(4).description,max:4}),w=RangeConfigItem({param:"top_p",title:CHAT_CONFIG.TOP_P.title,description:CHAT_CONFIG.TOP_P.description,min:0,max:1,step:.01,default:1}),z=RangeConfigItem({param:"frequency_penalty",title:CHAT_CONFIG.FREQUENCY_PENALTY.title,description:CHAT_CONFIG.FREQUENCY_PENALTY.description,min:-2,max:2,step:.01,default:0}),B=RangeConfigItem({param:"presence_penalty",title:CHAT_CONFIG.PRESENCE_PENALTY.title,description:CHAT_CONFIG.PRESENCE_PENALTY.description,min:-2,max:2,step:.01,default:0}),D=RangeConfigItem({param:"seed",title:CHAT_CONFIG.SEED.title,description:CHAT_CONFIG.SEED.description,min:0,max:1e6,step:1,default:0}),V=SelectStringConfigItem({param:"response_format",title:CHAT_CONFIG.RESPONSE_FORMAT.title,description:CHAT_CONFIG.RESPONSE_FORMAT.description,default:"text",choices:["text","json_object"]}),F=SelectStringConfigItem({param:"tool_choice",title:"Tool choice",description:"Controls which (if any) tool is called by the model.     'none' means the model will not call a function.     'auto' means the model can pick between generating a message or calling a tool.",default:"auto",choices:["auto","required","none"]});var W=s=>z$1.object({temperature:v.schema,maxTokens:N(s).schema,stop:q.schema,topP:w.schema,frequencyPenalty:z.schema,presencePenalty:B.schema,seed:D.schema.transform(e=>e===0?void 0:e),responseFormat:V.schema,toolChoice:F.schema}),ee=s=>({temperature:v.def,maxTokens:N(s).def,stop:q.def,topP:w.def,frequencyPenalty:z.def,presencePenalty:B.def,seed:D.def,responseFormat:V.def,toolChoice:F.def});var o={base:s=>({def:ee(s),schema:W(s)})};var u="gemma2-9b-it",ge="Gemma is a family of lightweight, state-of-the-art open models from Google,   built from the same research and technology used to create the Gemini models.",U=ChatModelSchema(OpenAIChatModelRoles,OpenAIChatModelTextToolModalitiesEnum).parse({name:u,description:ge,maxInputTokens:8192,maxOutputTokens:4096,roles:OpenAIChatModelRolesMap,modalities:OpenAIChatModelTextToolModalities,config:{def:o.base(4096).def,schema:o.base(4096).schema},price:a[u]}),oe=n,M=class extends t{constructor(e){super(U,e);}};var f="llama-3.1-8b-instant",Ie="The Llama 3.1 instruction tuned text only models (8B, 70B, 405B) are optimized for multilingual dialogue use cases and   outperform many of the available open source and closed chat models on common industry benchmarks.",j=ChatModelSchema(OpenAIChatModelRoles,OpenAIChatModelTextToolModalitiesEnum).parse({name:f,description:Ie,maxInputTokens:128e3,maxOutputTokens:8192,roles:OpenAIChatModelRolesMap,modalities:OpenAIChatModelTextToolModalities,config:{def:o.base(8192).def,schema:o.base(8192).schema},price:a[f]}),ae=n,b=class extends t{constructor(e){super(j,e);}};var y="llama-3.2-11b-vision-preview",ve="The Llama 3.2-Vision instruction-tuned models are optimized for visual recognition, image reasoning, captioning,   and answering general questions about an image.   The models outperform many of the available open source and closed multimodal models on common industry benchmarks.",K=ChatModelSchema(OpenAIChatModelRoles,OpenAIChatModelModalitiesEnum).parse({name:y,description:ve,maxInputTokens:128e3,maxOutputTokens:8192,roles:OpenAIChatModelRolesMap,modalities:OpenAIChatModelModalities,config:{def:o.base(8192).def,schema:o.base(8192).schema},price:a[y]}),te=n,T=class extends t{constructor(e){super(K,e);}};var O="llama-3.2-1b-preview",De="The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and   summarization tasks. They outperform many of the available open source and closed chat models on common industry benchmarks.",$=ChatModelSchema(OpenAIChatModelRoles,OpenAIChatModelTextToolModalitiesEnum).parse({name:O,description:De,maxInputTokens:128e3,maxOutputTokens:8192,roles:OpenAIChatModelRolesMap,modalities:OpenAIChatModelTextToolModalities,config:{def:o.base(8192).def,schema:o.base(8192).schema},price:a[O]}),se=n,g=class extends t{constructor(e){super($,e);}};var C="llama-3.2-3b-preview",$e="The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and   summarization tasks. They outperform many of the available open source and closed chat models on common industry benchmarks.",Y=ChatModelSchema(OpenAIChatModelRoles,OpenAIChatModelTextToolModalitiesEnum).parse({name:C,description:$e,maxInputTokens:128e3,maxOutputTokens:8192,roles:OpenAIChatModelRolesMap,modalities:OpenAIChatModelTextToolModalities,config:{def:o.base(8192).def,schema:o.base(8192).schema},price:a[C]}),ie=n,L=class extends t{constructor(e){super(Y,e);}};var x="llama-3.2-90b-vision-preview",Je="The Llama 3.2-90B Vision instruction-tuned models are optimized for advanced visual recognition,   complex image reasoning, detailed captioning, and answering intricate questions about images.   These models achieve state-of-the-art results on multiple industry benchmarks for multimodal tasks.",Q=ChatModelSchema(OpenAIChatModelRoles,OpenAIChatModelModalitiesEnum).parse({name:x,description:Je,maxInputTokens:131072,maxOutputTokens:8192,roles:OpenAIChatModelRolesMap,modalities:OpenAIChatModelModalities,config:{def:o.base(8192).def,schema:o.base(8192).schema},price:a[x]}),ne=n,S=class extends t{constructor(e){super(Q,e);}};var P="llama3-70b-8192",so="The Llama 3 instruction tuned models are optimized for dialogue use cases and outperform many of   the available open source chat models on common industry benchmarks.",X=ChatModelSchema(OpenAIChatModelRoles,OpenAIChatModelTextToolModalitiesEnum).parse({name:P,description:so,maxInputTokens:8192,maxOutputTokens:4096,roles:OpenAIChatModelRolesMap,modalities:OpenAIChatModelTextToolModalities,config:{def:o.base(4096).def,schema:o.base(4096).schema},price:a[P]}),me=n,I=class extends t{constructor(e){super(X,e);}};var k="llama3-8b-8192",po="The Llama 3 instruction tuned models are optimized for dialogue use cases and outperform many of   the available open source chat models on common industry benchmarks.",Z=ChatModelSchema(OpenAIChatModelRoles,OpenAIChatModelTextToolModalitiesEnum).parse({name:k,description:po,maxInputTokens:8192,maxOutputTokens:4096,roles:OpenAIChatModelRolesMap,modalities:OpenAIChatModelTextToolModalities,config:{def:o.base(4096).def,schema:o.base(4096).schema},price:a[k]}),le=n,E=class extends t{constructor(e){super(Z,e);}};var R="llama-guard-3-8b",fo="Llama Guard 3 is a Llama-3.1-8B pretrained model, fine-tuned for content safety classification.",H=ChatModelSchema(OpenAIChatModelRoles,OpenAIChatModelTextToolModalitiesEnum).parse({name:R,description:fo,maxInputTokens:8192,maxOutputTokens:4096,roles:OpenAIChatModelRolesMap,modalities:OpenAIChatModelTextToolModalities,config:{def:o.base(4096).def,schema:o.base(4096).schema},price:a[R]}),re=n,A=class extends t{constructor(e){super(H,e);}};var bo="groq",h=class{constructor(){this.version="v1";this.name=bo;this.chatModelFactories={[u]:{model:M,modelOptions:oe,modelSchema:U},[R]:{model:A,modelOptions:re,modelSchema:H},[k]:{model:E,modelOptions:le,modelSchema:Z},[P]:{model:I,modelOptions:me,modelSchema:X},[f]:{model:b,modelOptions:ae,modelSchema:j},[y]:{model:T,modelOptions:te,modelSchema:K},[x]:{model:S,modelOptions:ne,modelSchema:Q},[C]:{model:L,modelOptions:ie,modelSchema:Y},[O]:{model:g,modelOptions:se,modelSchema:$}};this.embeddingModelFactories={};}chatModelLiterals(){return Object.keys(this.chatModelFactories)}chatModelSchemas(){return Object.keys(this.chatModelFactories).reduce((e,i)=>(e[i]=this.chatModelFactories[i].modelSchema,e),{})}chatModel(e){let i=e.modelName;if(!(i in this.chatModelFactories))throw new ProviderError({info:`Groq chat model: ${i} not found`,cause:new Error(`Groq chat model: ${i} not found, available chat models: 
          ${this.chatModelLiterals().join(", ")}`)});let c=this.chatModelFactories[i].model,r=this.chatModelFactories[i].modelOptions.parse(e);return new c(r)}embeddingModelLiterals(){return Object.keys(this.embeddingModelFactories)}embeddingModelSchemas(){return Object.keys(this.embeddingModelFactories).reduce((e,i)=>(e[i]=this.embeddingModelFactories[i].modelSchema,e),{})}embeddingModel(e){throw new ProviderError({info:"Groq does not support embedding models yet",cause:new Error("Groq does not support embedding models yet")})}};h.baseUrl="https://api.groq.com/openai/v1";

export { t as BaseChatModelGroq, n as BaseChatModelOptions, M as Gemma2_9b_IT, u as Gemma2_9b_ITLiteral, oe as Gemma2_9b_ITOptions, U as Gemma2_9b_ITSchema, h as Groq, A as LlamaGuard_3_8b, R as LlamaGuard_3_8bLiteral, re as LlamaGuard_3_8bOptions, H as LlamaGuard_3_8bSchema, b as Llama_3_1_8b, f as Llama_3_1_8bLiteral, j as Llama_3_1_8bSchema, ae as Llama_3_1_8b_Options, T as Llama_3_2_11b_Vision, y as Llama_3_2_11b_VisionLiteral, te as Llama_3_2_11b_VisionOptions, K as Llama_3_2_11b_VisionSchema, g as Llama_3_2_1b, O as Llama_3_2_1bLiteral, $ as Llama_3_2_1bSchema, se as Llama_3_2_1b_Options, L as Llama_3_2_3b, C as Llama_3_2_3bLiteral, Y as Llama_3_2_3bSchema, ie as Llama_3_2_3b_Options, S as Llama_3_2_90b_Vision, x as Llama_3_2_90b_VisionLiteral, ne as Llama_3_2_90b_VisionOptions, Q as Llama_3_2_90b_VisionSchema, I as Llama_3_70b, P as Llama_3_70bLiteral, me as Llama_3_70bOptions, X as Llama_3_70bSchema, E as Llama_3_8b, k as Llama_3_8bLiteral, le as Llama_3_8bOptions, Z as Llama_3_8bSchema };
//# sourceMappingURL=index.mjs.map
//# sourceMappingURL=index.mjs.map