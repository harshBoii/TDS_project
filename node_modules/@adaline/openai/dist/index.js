'use strict';

var zod = require('zod');
var provider = require('@adaline/provider');
var types = require('@adaline/types');

var ln=Object.defineProperty,pn=Object.defineProperties;var mn=Object.getOwnPropertyDescriptors;var Zo=Object.getOwnPropertySymbols;var dn=Object.prototype.hasOwnProperty,cn=Object.prototype.propertyIsEnumerable;var X=(s,e)=>(e=Symbol[s])?e:Symbol.for("Symbol."+s),un=s=>{throw TypeError(s)};var et=(s,e,t)=>e in s?ln(s,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):s[e]=t,P=(s,e)=>{for(var t in e||(e={}))dn.call(e,t)&&et(s,t,e[t]);if(Zo)for(var t of Zo(e))cn.call(e,t)&&et(s,t,e[t]);return s},L=(s,e)=>pn(s,mn(e));var A=(s,e,t)=>new Promise((o,n)=>{var i=p=>{try{a(t.next(p));}catch(h){n(h);}},m=p=>{try{a(t.throw(p));}catch(h){n(h);}},a=p=>p.done?o(p.value):Promise.resolve(p.value).then(i,m);a((t=t.apply(s,e)).next());}),ot=function(s,e){this[0]=s,this[1]=e;},Qe=(s,e,t)=>{var o=(m,a,p,h)=>{try{var c=t[m](a),b=(a=c.value)instanceof ot,y=c.done;Promise.resolve(b?a[0]:a).then(M=>b?o(m==="return"?m:"next",a[1]?{done:M.done,value:M.value}:M,p,h):p({value:M,done:y})).catch(M=>o("throw",M,p,h));}catch(M){h(M);}},n=m=>i[m]=a=>new Promise((p,h)=>o(m,a,p,h)),i={};return t=t.apply(s,e),i[X("asyncIterator")]=()=>i,n("next"),n("throw"),n("return"),i},tt=s=>{var e=s[X("asyncIterator")],t=!1,o,n={};return e==null?(e=s[X("iterator")](),o=i=>n[i]=m=>e[i](m)):(e=e.call(s),o=i=>n[i]=m=>{if(t){if(t=!1,i==="throw")throw m;return m}return t=!0,{done:!1,value:new ot(new Promise(a=>{var p=e[i](m);p instanceof Object||un("Object expected"),a(p);}),1)}}),n[X("iterator")]=()=>n,o("next"),"throw"in e?o("throw"):n.throw=i=>{throw i},"return"in e&&o("return"),n};var Xe=provider.RangeConfigItem({param:"temperature",title:provider.CHAT_CONFIG.TEMPERATURE.title,description:provider.CHAT_CONFIG.TEMPERATURE.description,min:0,max:2,step:.01,default:1}),Ze=s=>provider.RangeConfigItem({param:"max_completion_tokens",title:provider.CHAT_CONFIG.MAX_TOKENS.title,description:provider.CHAT_CONFIG.MAX_TOKENS.description,min:0,max:s,step:1,default:0}),eo=s=>provider.MultiStringConfigItem({param:"stop",title:provider.CHAT_CONFIG.STOP(s).title,description:provider.CHAT_CONFIG.STOP(s).description,max:s}),oo=provider.RangeConfigItem({param:"top_p",title:provider.CHAT_CONFIG.TOP_P.title,description:provider.CHAT_CONFIG.TOP_P.description,min:0,max:1,step:.01,default:1}),to=provider.RangeConfigItem({param:"frequency_penalty",title:provider.CHAT_CONFIG.FREQUENCY_PENALTY.title,description:provider.CHAT_CONFIG.FREQUENCY_PENALTY.description,min:-2,max:2,step:.01,default:0}),no=provider.RangeConfigItem({param:"presence_penalty",title:provider.CHAT_CONFIG.PRESENCE_PENALTY.title,description:provider.CHAT_CONFIG.PRESENCE_PENALTY.description,min:-2,max:2,step:.01,default:0}),so=provider.RangeConfigItem({param:"seed",title:provider.CHAT_CONFIG.SEED.title,description:provider.CHAT_CONFIG.SEED.description,min:0,max:1e6,step:1,default:0}),io=provider.SelectBooleanConfigItem({param:"logprobs",title:provider.CHAT_CONFIG.LOG_PROBS.title,description:provider.CHAT_CONFIG.LOG_PROBS.description,default:!1}),ao=provider.RangeConfigItem({param:"top_logprobs",title:provider.CHAT_CONFIG.TOP_LOG_PROBS.title,description:provider.CHAT_CONFIG.TOP_LOG_PROBS.description,min:0,max:20,step:1,default:0}),ro=provider.SelectStringConfigItem({param:"tool_choice",title:"Tool choice",description:"Controls which (if any) tool is called by the model. 'none' means the model will not call a function. 'auto' means the model can pick between generating a message or calling a tool.",default:"auto",choices:["auto","required","none"]});var F=(s,e)=>zod.z.object({temperature:Xe.schema,maxTokens:Ze(s).schema,stop:eo(e).schema,topP:oo.schema,frequencyPenalty:to.schema,presencePenalty:no.schema,seed:so.schema.transform(t=>t===0?void 0:t),logProbs:io.schema,topLogProbs:ao.schema,toolChoice:ro.schema}),$=(s,e)=>({temperature:Xe.def,maxTokens:Ze(s).def,stop:eo(e).def,topP:oo.def,frequencyPenalty:to.def,presencePenalty:no.def,seed:so.def,logProbs:io.def,topLogProbs:ao.def,toolChoice:ro.def});var nt=provider.ObjectSchemaConfigItem({param:"response_schema",title:provider.CHAT_CONFIG.RESPONSE_SCHEMA.title,description:provider.CHAT_CONFIG.RESPONSE_SCHEMA.description,objectSchema:types.ResponseSchema}),st=provider.SelectStringConfigItem({param:"response_format",title:provider.CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.title,description:provider.CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.description,default:"text",choices:["text","json_object","json_schema"]}),ee=(s,e)=>L(P({},$(s,e)),{responseFormat:st.def,responseSchema:nt.def}),oe=(s,e)=>F(s,e).extend({responseFormat:st.schema,responseSchema:nt.schema});var at=provider.RangeConfigItem({param:"temperature",title:provider.CHAT_CONFIG.TEMPERATURE.title,description:provider.CHAT_CONFIG.TEMPERATURE.description,min:1,max:1,step:.01,default:1}),rt=provider.SelectStringConfigItem({param:"reasoning_effort",title:"Reasoning Effort",description:"Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.",default:"medium",choices:["low","medium","high"]}),lt=(s,e)=>L(P({},ee(s,e)),{temperature:at.def,reasoningEffort:rt.def}),pt=(s,e)=>oe(s,e).extend({temperature:at.schema,reasoningEffort:rt.schema});var dt=provider.SelectStringConfigItem({param:"response_format",title:provider.CHAT_CONFIG.RESPONSE_FORMAT.title,description:provider.CHAT_CONFIG.RESPONSE_FORMAT.description,default:"text",choices:["text","json_object"]}),ct=(s,e)=>L(P({},$(s,e)),{responseFormat:dt.def}),ut=(s,e)=>F(s,e).extend({responseFormat:dt.schema});var lo=provider.SelectStringConfigItem({param:"encoding_format",title:"Encoding format",description:"Select the encoding format for the word embedding.",default:"float",choices:["float","base64"]}),po=s=>provider.RangeConfigItem({param:"dimensions",title:"Dimensions",description:"Select the number of dimensions for the word embedding.",min:1,max:s,step:1,default:s});var te=()=>zod.z.object({encodingFormat:lo.schema}),ne=()=>({encodingFormat:lo.def});var ht=s=>te().extend({dimensions:po(s).schema}),ft=s=>L(P({},ne()),{dimensions:po(s).def});var r={base:(s,e)=>({def:$(s,e),schema:F(s,e)}),responseFormat:(s,e)=>({def:ct(s,e),schema:ut(s,e)}),responseSchema:(s,e)=>({def:ee(s,e),schema:oe(s,e)}),oSeries:(s,e)=>({def:lt(s,e),schema:pt(s,e)})},v={base:()=>({def:ne(),schema:te()}),dimensions:s=>({def:ft(s),schema:ht(s)})};var T={"gpt-3.5-turbo-0125":{modelName:"gpt-3.5-turbo-0125",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.5,outputPricePerMillion:1.5}}}]},"gpt-3.5-turbo-1106":{modelName:"gpt-3.5-turbo-1106",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.5,outputPricePerMillion:1.5}}}]},"gpt-3.5-turbo":{modelName:"gpt-3.5-turbo",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.5,outputPricePerMillion:1.5}}}]},"gpt-4-0125-preview":{modelName:"gpt-4-0125-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4-0613":{modelName:"gpt-4-0613",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4-1106-preview":{modelName:"gpt-4-1106-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4-turbo-2024-04-09":{modelName:"gpt-4-turbo-2024-04-09",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:30}}}]},"gpt-4-turbo-preview":{modelName:"gpt-4-turbo-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:30}}}]},"gpt-4-turbo":{modelName:"gpt-4-turbo",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:30}}}]},"gpt-4":{modelName:"gpt-4",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4o-2024-05-13":{modelName:"gpt-4o-2024-05-13",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:5,outputPricePerMillion:20}}}]},"gpt-4o-2024-08-06":{modelName:"gpt-4o-2024-08-06",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:2.5,outputPricePerMillion:10}}}]},"gpt-4o-mini-2024-07-18":{modelName:"gpt-4o-mini-2024-07-18",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.6,outputPricePerMillion:2.4}}}]},"gpt-4o-mini":{modelName:"gpt-4o-mini",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.6,outputPricePerMillion:2.4}}}]},"gpt-4o":{modelName:"gpt-4o",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:5,outputPricePerMillion:20}}}]},"o1-2024-12-17":{modelName:"o1-2024-12-17",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:15,outputPricePerMillion:60}}}]},o1:{modelName:"o1",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:15,outputPricePerMillion:60}}}]},"o3-mini-2025-01-31":{modelName:"o3-mini-2025-01-31",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]},"o3-mini":{modelName:"o3-mini",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]},"o3-2025-04-16":{modelName:"o3-2025-04-16",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:40}}}]},o3:{modelName:"o3",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:40}}}]},"o4-mini-2025-04-16":{modelName:"o4-mini-2025-04-16",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]},"o4-mini":{modelName:"o4-mini",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]}};var Rn="openai",N=class{constructor(){this.version="v1";this.name=Rn;this.chatModelFactories={[le]:{model:pe,modelOptions:yt,modelSchema:uo},[se]:{model:ie,modelOptions:_t,modelSchema:mo},[ae]:{model:re,modelOptions:Tt,modelSchema:co},[me]:{model:de,modelOptions:Mt,modelSchema:ho},[ce]:{model:ue,modelOptions:Ot,modelSchema:fo},[he]:{model:fe,modelOptions:Ct,modelSchema:go},[ge]:{model:_e,modelOptions:bt,modelSchema:_o},[Te]:{model:ye,modelOptions:Pt,modelSchema:To},[Me]:{model:Oe,modelOptions:It,modelSchema:yo},[Ce]:{model:be,modelOptions:St,modelSchema:Mo},[Se]:{model:xe,modelOptions:Rt,modelSchema:Co},[Ee]:{model:ke,modelOptions:Et,modelSchema:Po},[we]:{model:Ge,modelOptions:kt,modelSchema:Io},[Re]:{model:Ae,modelOptions:At,modelSchema:bo},[Pe]:{model:Ie,modelOptions:xt,modelSchema:Oo},[De]:{model:Le,modelOptions:Gt,modelSchema:xo},[ve]:{model:qe,modelOptions:wt,modelSchema:So},[vo]:{model:Ue,modelOptions:Lt,modelSchema:qo},[wo]:{model:Ne,modelOptions:Dt,modelSchema:Go},[Ro]:{model:ze,modelOptions:vt,modelSchema:Ao},[Eo]:{model:Be,modelOptions:qt,modelSchema:ko},[Do]:{model:je,modelOptions:zt,modelSchema:Lo},[zo]:{model:Fe,modelOptions:Bt,modelSchema:Bo}};this.embeddingModelFactories={[No]:{model:$e,modelOptions:Nt,modelSchema:Uo},[jo]:{model:He,modelOptions:Ut,modelSchema:Fo},[$o]:{model:Ve,modelOptions:jt,modelSchema:Ho}};}chatModelLiterals(){return Object.keys(this.chatModelFactories)}chatModelSchemas(){return Object.keys(this.chatModelFactories).reduce((e,t)=>(e[t]=this.chatModelFactories[t].modelSchema,e),{})}chatModel(e){let t=e.modelName;if(!(t in this.chatModelFactories))throw new provider.ProviderError({info:`OpenAI chat model: ${t} not found`,cause:new Error(`OpenAI chat model: ${t} not found, available chat models: 
          [${this.chatModelLiterals().join(", ")}]`)});let o=this.chatModelFactories[t].model,n=this.chatModelFactories[t].modelOptions.parse(e);return new o(n)}embeddingModelLiterals(){return Object.keys(this.embeddingModelFactories)}embeddingModelSchemas(){return Object.keys(this.embeddingModelFactories).reduce((e,t)=>(e[t]=this.embeddingModelFactories[t].modelSchema,e),{})}embeddingModel(e){let t=e.modelName;if(!(t in this.embeddingModelFactories))throw new provider.ProviderError({info:`OpenAI embedding model: ${t} not found`,cause:new Error(`OpenAI embedding model: ${t} not found, available embedding models: 
          [${this.embeddingModelLiterals().join(", ")}]`)});let o=this.embeddingModelFactories[t].model,n=this.embeddingModelFactories[t].modelOptions.parse(e);return new o(n)}};N.baseUrl="https://api.openai.com/v1";var g=zod.z.enum([types.SystemRoleLiteral,types.UserRoleLiteral,types.AssistantRoleLiteral,types.ToolRoleLiteral]),_={system:types.SystemRoleLiteral,user:types.UserRoleLiteral,assistant:types.AssistantRoleLiteral,tool:types.ToolRoleLiteral};var O=[types.TextModalityLiteral,types.ImageModalityLiteral,types.ToolCallModalityLiteral,types.ToolResponseModalityLiteral],C=zod.z.enum([types.TextModalityLiteral,types.ImageModalityLiteral,types.ToolCallModalityLiteral,types.ToolResponseModalityLiteral]),oa=[types.TextModalityLiteral],ta=zod.z.enum([types.TextModalityLiteral]),S=[types.TextModalityLiteral,types.ToolCallModalityLiteral,types.ToolResponseModalityLiteral],x=zod.z.enum([types.TextModalityLiteral,types.ToolCallModalityLiteral,types.ToolResponseModalityLiteral]);var We=zod.z.object({token:zod.z.string(),logprob:zod.z.number(),bytes:zod.z.array(zod.z.number()).nullable()}),Jt=zod.z.object({content:zod.z.array(We.extend({top_logprobs:zod.z.array(We)})).nullable().optional(),refusal:zod.z.array(We.extend({top_logprobs:zod.z.array(We)})).nullable().optional()}).nullable(),En=zod.z.array(zod.z.object({id:zod.z.string().min(1),type:zod.z.enum(["function"]),function:zod.z.object({name:zod.z.string(),arguments:zod.z.string()})})),Wt=zod.z.object({id:zod.z.string(),object:zod.z.literal("chat.completion"),created:zod.z.number(),model:zod.z.string(),system_fingerprint:zod.z.string().nullable(),choices:zod.z.array(zod.z.object({index:zod.z.number(),message:zod.z.object({role:zod.z.string(),content:zod.z.string().nullable().optional(),tool_calls:En.optional(),refusal:zod.z.string().nullable().optional()}),logprobs:Jt.optional(),finish_reason:zod.z.string()})),usage:zod.z.object({prompt_tokens:zod.z.number(),completion_tokens:zod.z.number(),total_tokens:zod.z.number()})}),kn=zod.z.array(zod.z.object({index:zod.z.number().int(),id:zod.z.string().min(1).optional(),type:zod.z.enum(["function"]).optional(),function:zod.z.object({name:zod.z.string().min(1).optional(),arguments:zod.z.string().optional()}).optional()})),Yt=zod.z.object({id:zod.z.string(),object:zod.z.string(),created:zod.z.number(),model:zod.z.string(),system_fingerprint:zod.z.string().nullable().optional(),choices:zod.z.array(zod.z.object({index:zod.z.number(),delta:zod.z.object({content:zod.z.string().nullable().optional(),tool_calls:kn.optional(),refusal:zod.z.string().nullable().optional()}).or(zod.z.object({})),logprobs:Jt.optional(),finish_reason:zod.z.string().nullable()})),usage:zod.z.object({prompt_tokens:zod.z.number(),completion_tokens:zod.z.number(),total_tokens:zod.z.number()}).nullable().optional()});var wn=zod.z.object({type:zod.z.literal("function"),function:zod.z.object({name:zod.z.string().min(1),description:zod.z.string().min(1).optional(),strict:zod.z.boolean().optional(),parameters:zod.z.any()})}),Gn=zod.z.enum(["none","auto","required"]),vn=zod.z.object({type:zod.z.literal("function"),function:zod.z.object({name:zod.z.string().min(1)})}),qn=zod.z.object({type:zod.z.enum(["text","json_object"])}).or(zod.z.object({type:zod.z.literal("json_schema"),json_schema:zod.z.object({name:zod.z.string().min(1),description:zod.z.string().min(1).optional(),strict:zod.z.boolean().optional(),schema:zod.z.any()})})),Ko=zod.z.object({text:zod.z.string().min(1),type:zod.z.literal("text")}),Dn=zod.z.object({type:zod.z.literal("image_url"),image_url:zod.z.object({url:zod.z.string().url().min(1),detail:zod.z.enum(["low","high","auto"]).optional()})}),Ln=zod.z.object({id:zod.z.string().min(1),type:zod.z.literal("function"),function:zod.z.object({name:zod.z.string().min(1),arguments:zod.z.string().min(1)})}),zn=zod.z.object({role:zod.z.literal("system"),content:zod.z.string().min(1).or(zod.z.array(Ko).min(1))}),Bn=zod.z.object({role:zod.z.literal("user"),content:zod.z.string().min(1).or(zod.z.array(zod.z.union([Ko,Dn])).min(1))}),Nn=zod.z.object({role:zod.z.literal("assistant"),content:zod.z.string().min(1).or(zod.z.array(Ko).min(1)).optional(),tool_calls:zod.z.array(Ln).min(1).optional()}),Un=zod.z.object({role:zod.z.literal("tool"),tool_call_id:zod.z.string().min(1),content:zod.z.string().min(1)}),jn=zod.z.union([zn,Bn,Nn,Un]),Qt=zod.z.object({model:zod.z.string().min(1).optional(),messages:zod.z.array(jn).min(1),frequency_penalty:zod.z.number().min(-2).max(2).nullable().optional(),logprobs:zod.z.boolean().nullable().optional(),top_logprobs:zod.z.number().min(0).max(20).nullable().optional(),max_completion_tokens:zod.z.number().min(0).nullable().optional(),presence_penalty:zod.z.number().min(-2).max(2).nullable().optional(),response_format:qn.optional(),seed:zod.z.number().nullable().optional(),stop:zod.z.string().or(zod.z.array(zod.z.string()).max(4)).nullable().optional(),temperature:zod.z.number().min(0).max(2).nullable().optional(),top_p:zod.z.number().min(0).max(1).nullable().optional(),tools:zod.z.array(wn).optional(),tool_choice:Gn.or(vn).optional()});var f=zod.z.object({modelName:zod.z.string(),apiKey:zod.z.string(),baseUrl:zod.z.string().url().optional(),completeChatUrl:zod.z.string().url().optional(),streamChatUrl:zod.z.string().url().optional(),organization:zod.z.string().optional()}),u=class{constructor(e,t){this.version="v1";let o=f.parse(t);this.modelSchema=e,this.modelName=o.modelName,this.apiKey=o.apiKey,this.baseUrl=provider.urlWithoutTrailingSlash(o.baseUrl||N.baseUrl),this.streamChatUrl=provider.urlWithoutTrailingSlash(o.streamChatUrl||`${this.baseUrl}/chat/completions`),this.completeChatUrl=provider.urlWithoutTrailingSlash(o.completeChatUrl||`${this.baseUrl}/chat/completions`),this.organization=o.organization;}getDefaultBaseUrl(){return this.baseUrl}getDefaultHeaders(){return P({Authorization:`Bearer ${this.apiKey}`,"Content-Type":"application/json"},this.organization?{"OpenAI-Organization":this.organization}:{})}getDefaultParams(){return {model:this.modelName}}getRetryDelay(e){let t=a=>{let p=/(\d+)(h|m|s|ms)/g,h={h:36e5,m:6e4,s:1e3,ms:1},c,b=0;for(;(c=p.exec(a))!==null;){let y=parseInt(c[1]),M=c[2];b+=y*h[M];}return b},o=0,n=0,i=!0;e["x-ratelimit-reset-requests"]&&(o=t(e["x-ratelimit-reset-requests"])),e["x-ratelimit-reset-tokens"]&&(n=t(e["x-ratelimit-reset-tokens"]));let m=Math.max(o,n);return {shouldRetry:i,delayMs:m}}getTokenCount(e){return e.reduce((t,o)=>t+o.content.map(n=>n.modality==="text"?n.value:"").join(" ").length,0)}transformModelRequest(e){let t=Qt.safeParse(e);if(!t.success)throw new provider.InvalidModelRequestError({info:"Invalid model request",cause:t.error});let o=t.data,n=o.model;if(o.tool_choice&&(!o.tools||o.tools.length===0))throw new provider.InvalidModelRequestError({info:`Invalid model request for model : '${this.modelName}'`,cause:new Error("'tools' are required when 'tool_choice' is specified")});let i={};o.response_format&&(i.responseFormat=o.response_format.type,o.response_format.type==="json_schema"&&(i.responseSchema={name:o.response_format.json_schema.name,description:o.response_format.json_schema.description||"",strict:o.response_format.json_schema.strict,schema:o.response_format.json_schema.schema})),o.tool_choice&&(typeof o.tool_choice=="string"?i.toolChoice=o.tool_choice:i.toolChoice=o.tool_choice.function.name),i.seed=o.seed,i.maxTokens=o.max_completion_tokens,i.temperature=o.temperature,i.topP=o.top_p,i.presencePenalty=o.presence_penalty,i.frequencyPenalty=o.frequency_penalty,i.stop=o.stop,i.logProbs=o.logprobs,i.topLogProbs=o.top_logprobs;let m=types.Config().parse(provider.removeUndefinedEntries(i)),a=[],p={};o.messages.forEach(c=>{let b=c.role;switch(b){case"system":{let y=c.content;if(typeof y=="string")a.push({role:b,content:[{modality:types.TextModalityLiteral,value:y}]});else {let M=y.map(I=>({modality:types.TextModalityLiteral,value:I.text}));a.push({role:b,content:M});}}break;case"user":{let y=c.content;if(typeof y=="string")a.push({role:b,content:[{modality:types.TextModalityLiteral,value:y}]});else {let M=y.map(I=>I.type==="text"?{modality:types.TextModalityLiteral,value:I.text}:I.image_url.url.startsWith("data:")?{modality:types.ImageModalityLiteral,detail:I.image_url.detail||"auto",value:{type:types.Base64ImageContentTypeLiteral,base64:I.image_url.url,mediaType:provider.getMimeTypeFromBase64(I.image_url.url)}}:{modality:types.ImageModalityLiteral,detail:I.image_url.detail||"auto",value:{type:types.UrlImageContentTypeLiteral,url:I.image_url.url}});a.push({role:b,content:M});}}break;case"assistant":{let y=[];if(!c.content&&!c.tool_calls)throw new provider.InvalidModelRequestError({info:`Invalid model request for model : '${this.modelName}'`,cause:new Error("one of'content' or 'tool_calls' must be provided")});if(c.content){let M=c.content;typeof M=="string"?y.push({modality:types.TextModalityLiteral,value:M}):M.forEach(I=>{y.push({modality:types.TextModalityLiteral,value:I.text});});}c.tool_calls&&c.tool_calls.forEach((I,E)=>{let D={modality:types.ToolCallModalityLiteral,id:I.id,index:E,name:I.function.name,arguments:I.function.arguments};y.push(D),p[D.id]=D;}),a.push({role:b,content:y});}break;case"tool":{let y=c;a.push({role:b,content:[{modality:types.ToolResponseModalityLiteral,id:y.tool_call_id,index:p[y.tool_call_id].index,name:p[y.tool_call_id].name,data:y.content}]});}break}});let h=[];return o.tools&&o.tools.forEach(c=>{h.push({type:"function",definition:{schema:{name:c.function.name,description:c.function.description||"",strict:c.function.strict,parameters:c.function.parameters}}});}),{modelName:n,config:m,messages:a,tools:h.length>0?h:void 0}}transformConfig(e,t,o){let n=e.toolChoice;delete e.toolChoice;let i=this.modelSchema.config.schema.safeParse(e);if(!i.success)throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:i.error});let m=i.data;n!==void 0&&(m.toolChoice=n),Object.keys(m).forEach(p=>{if(!(p in this.modelSchema.config.def))throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error(`Invalid config key : '${p}', 
            available keys : [${Object.keys(this.modelSchema.config.def).join(", ")}]`)})});let a=Object.keys(m).reduce((p,h)=>{let c=this.modelSchema.config.def[h],b=c.param,y=m[h];return b==="max_completion_tokens"&&c.type==="range"&&y===0?p[b]=c.max:p[b]=y,p},{});if(a.top_logprobs&&!a.logprobs)throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'logprobs' must be 'true' when 'top_logprobs' is specified")});if("tool_choice"in a&&a.tool_choice!==void 0){let p=a.tool_choice;if(!o||o&&o.length===0)throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'tools' are required when 'toolChoice' is specified")});if(o&&o.length>0){let h=this.modelSchema.config.def.toolChoice;if(!h.choices.includes(p))if(o.map(c=>c.definition.schema.name).includes(p))a.tool_choice={type:"function",function:{name:p}};else throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error(`toolChoice : '${p}' is not part of provided 'tools' names or 
                one of [${h.choices.join(", ")}]`)})}}if("response_format"in a&&a.response_format!==void 0){let p=a.response_format;if(p==="json_schema")if("response_schema"in a)a.response_format={type:"json_schema",json_schema:a.response_schema},delete a.response_schema;else throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'responseSchema' is required in config when 'responseFormat' is 'json_schema'")});else a.response_format={type:p};}return a}transformMessages(e){if(!e||e&&e.length===0)return {messages:[]};let t=e.map(n=>{let i=types.Message().safeParse(n);if(!i.success)throw new provider.InvalidMessagesError({info:"Invalid messages",cause:i.error});return i.data});return t.forEach(n=>{n.content.forEach(i=>{if(!this.modelSchema.modalities.includes(i.modality))throw new provider.InvalidMessagesError({info:`Invalid message content for model : '${this.modelName}'`,cause:new Error(`model : '${this.modelName}' does not support modality : '${i.modality}', 
              available modalities : [${this.modelSchema.modalities.join(", ")}]`)})});}),t.forEach(n=>{if(!Object.keys(this.modelSchema.roles).includes(n.role))throw new provider.InvalidMessagesError({info:`Invalid message content for model : '${this.modelName}'`,cause:new Error(`model : '${this.modelName}' does not support role : '${n.role}', 
            available roles : [${Object.keys(this.modelSchema.roles).join(", ")}]`)})}),{messages:t.map(n=>{switch(n.role){case types.SystemRoleLiteral:{let i=[];return n.content.forEach(m=>{if(m.modality===types.TextModalityLiteral)i.push({type:"text",text:m.value});else throw new provider.InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${n.role}' cannot have content with modality : '${m.modality}'`)})}),{role:this.modelSchema.roles[n.role],content:i}}case types.AssistantRoleLiteral:{let i=[],m=[];return n.content.forEach(a=>{if(a.modality===types.TextModalityLiteral)i.push({type:"text",text:a.value});else if(a.modality===types.ToolCallModalityLiteral)m.push({id:a.id,type:"function",function:{name:a.name,arguments:a.arguments}});else throw new provider.InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${n.role}' cannot have content with modality : '${a.modality}'`)})}),P({role:this.modelSchema.roles[n.role],content:i},m.length>0?{tool_calls:m}:{})}case types.UserRoleLiteral:{let i=[],m=[];n.content.forEach(p=>{if(p.modality===types.TextModalityLiteral)i.push({type:"text",text:p.value});else if(p.modality===types.ImageModalityLiteral)m.push({type:"image_url",image_url:{url:p.value.type==="url"?p.value.url:p.value.base64,detail:p.detail}});else throw new provider.InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${n.role}' cannot have content with modality : '${p.modality}'`)})});let a=[...i,...m];return {role:this.modelSchema.roles[n.role],content:a}}case types.ToolRoleLiteral:{if(n.content.length!==1)throw new provider.InvalidMessagesError({info:`Invalid message for role : '${n.role}'`,cause:new Error(`role : '${n.role}' must have exactly one content item`)});if(n.content[0].modality!==types.ToolResponseModalityLiteral)throw new provider.InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${n.role}' must have content with modality : '${types.ToolResponseModalityLiteral}'`)});let i=n.content[0];return {role:this.modelSchema.roles[n.role],tool_call_id:i.id,content:i.data}}default:throw new provider.InvalidMessagesError({info:`Invalid message 'role' for model : ${this.modelName}`,cause:new Error(`role : '${n.role}' is not supported, 
              available roles : [${Object.keys(this.modelSchema.roles).join(", ")}]`)})}})}}transformTools(e){if(!this.modelSchema.modalities.includes(types.ToolCallModalityLiteral))throw new provider.InvalidToolsError({info:`Invalid tool 'modality' for model : ${this.modelName}`,cause:new Error(`model : '${this.modelName}' does not support tool modality : '${types.ToolCallModalityLiteral}'`)});return !e||e&&e.length===0?{tools:[]}:{tools:e.map(n=>{let i=types.Tool().safeParse(n);if(!i.success)throw new provider.InvalidToolsError({info:"Invalid tools",cause:i.error});return i.data}).map(n=>({type:"function",function:n.definition.schema}))}}getCompleteChatUrl(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.completeChatUrl);})})}getCompleteChatHeaders(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.getDefaultHeaders());})})}getCompleteChatData(e,t,o){return A(this,null,function*(){let n=this.transformConfig(e,t,o),i=this.transformMessages(t);if(i.messages&&i.messages.length===0)throw new provider.InvalidMessagesError({info:"Messages are required",cause:new Error("Messages are required")});let m=o?this.transformTools(o):{};return new Promise(a=>{a(P(P(P(P({},this.getDefaultParams()),n),i),m));})})}transformCompleteChatResponse(e){let t=Wt.safeParse(e);if(t.success){if(t.data.choices.length===0)throw new provider.ModelResponseError({info:"Invalid response from model",cause:new Error(`No choices in response : ${JSON.stringify(t.data)}`)});let o=t.data,n=[{role:types.AssistantRoleLiteral,content:[]}],i=o.choices[0].message;i.content&&n[0].content.push(types.createTextContent(i.content)),i.refusal&&n[0].content.push(types.createTextContent(i.refusal)),i.tool_calls&&i.tool_calls.forEach((h,c)=>{n[0].content.push(types.createToolCallContent(c,h.id,h.function.name,h.function.arguments));});let m={promptTokens:o.usage.prompt_tokens,completionTokens:o.usage.completion_tokens,totalTokens:o.usage.total_tokens},a=[],p=o.choices[0].logprobs;return p&&(p.content&&a.push(...p.content.map(h=>({token:h.token,logProb:h.logprob,bytes:h.bytes,topLogProbs:h.top_logprobs.map(c=>({token:c.token,logProb:c.logprob,bytes:c.bytes}))}))),p.refusal&&a.push(...p.refusal.map(h=>({token:h.token,logProb:h.logprob,bytes:h.bytes,topLogProbs:h.top_logprobs.map(c=>({token:c.token,logProb:c.logprob,bytes:c.bytes}))})))),{messages:n,usage:m,logProbs:a}}throw new provider.ModelResponseError({info:"Invalid response from model",cause:t.error})}getStreamChatUrl(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.streamChatUrl);})})}getStreamChatHeaders(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.getDefaultHeaders());})})}getStreamChatData(e,t,o){return A(this,null,function*(){let n=this.transformConfig(e,t,o),i=this.transformMessages(t);if(i.messages&&i.messages.length===0)throw new provider.InvalidMessagesError({info:"Messages are required",cause:new Error("Messages are required")});let m=o?this.transformTools(o):{};return new Promise(a=>{a(P(P(P(P({stream:!0,stream_options:{include_usage:!0}},this.getDefaultParams()),n),i),m));})})}transformStreamChatResponseChunk(e,t){return Qe(this,null,function*(){var a,p;let o=t+e,n=[],i="",m=0;for(;m<o.length;){let h=o.indexOf(`
`,m);if(h===-1){i=o.substring(m);break}else {let c=o.substring(m,h).trim();c&&n.push(c),m=h+1;}}for(let h of n){if(h==="data: [DONE]")return;if(h.startsWith("data: ")){let c=h.substring(6);try{let b=JSON.parse(c),y=Yt.safeParse(b);if(y.success){let M={partialMessages:[]},I=y.data;if(I.choices.length>0){let E=I.choices[0].delta;if(E!==void 0&&Object.keys(E).length!==0){if("content"in E&&E.content!==null)M.partialMessages.push(types.createPartialTextMessage(types.AssistantRoleLiteral,E.content));else if("refusal"in E&&E.refusal!==null)M.partialMessages.push(types.createPartialTextMessage(types.AssistantRoleLiteral,E.refusal));else if("tool_calls"in E&&E.tool_calls!==void 0){let D=E.tool_calls.at(0);M.partialMessages.push(types.createPartialToolCallMessage(types.AssistantRoleLiteral,D.index,D.id,(a=D.function)==null?void 0:a.name,(p=D.function)==null?void 0:p.arguments));}}}I.usage&&(M.usage={promptTokens:I.usage.prompt_tokens,completionTokens:I.usage.completion_tokens,totalTokens:I.usage.total_tokens}),yield {partialResponse:M,buffer:i};}else throw new provider.ModelResponseError({info:"Invalid response from model",cause:y.error})}catch(b){throw new provider.ModelResponseError({info:`Malformed JSON received in stream: ${c}`,cause:b})}}}yield {partialResponse:{partialMessages:[]},buffer:i};})}transformProxyStreamChatResponseChunk(e,t,o,n,i){return Qe(this,null,function*(){yield*tt(this.transformStreamChatResponseChunk(e,t));})}getProxyStreamChatUrl(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.streamChatUrl);})})}getProxyCompleteChatUrl(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.completeChatUrl);})})}getProxyCompleteChatHeaders(e,t,o){return A(this,null,function*(){if(!t)return {};let n=P({},t);return delete n.host,delete n["content-length"],n})}getProxyStreamChatHeaders(e,t,o){return A(this,null,function*(){return yield this.getProxyCompleteChatHeaders(e,t,o)})}getModelPricing(){if(!(this.modelName in T))throw new provider.ModelResponseError({info:`Invalid model pricing for model : '${this.modelName}'`,cause:new Error(`No pricing configuration found for model "${this.modelName}"`)});return T[this.modelName]}};var se="gpt-3.5-turbo-0125",ts="The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a   text encoding issue for non-English language function calls. Training data up to Sept 2021.",mo=provider.ChatModelSchema(g,x).parse({name:se,description:ts,maxInputTokens:4092,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.responseFormat(4092,4).def,schema:r.responseFormat(4092,4).schema},price:T[se]}),_t=f,ie=class extends u{constructor(e){super(mo,e);}};var ae="gpt-3.5-turbo-1106",ss="The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.   Returns a maximum of 4,096 output tokens. Training data up to Sept 2021.",co=provider.ChatModelSchema(g,x).parse({name:ae,description:ss,maxInputTokens:4092,maxOutputTokens:16385,roles:_,modalities:S,config:{def:r.responseFormat(16385,4).def,schema:r.responseFormat(16385,4).schema},price:T[ae]}),Tt=f,re=class extends u{constructor(e){super(co,e);}};var le="gpt-3.5-turbo",as="Currently points to gpt-3.5-turbo-0125. Training data up to Sept 2021.",uo=provider.ChatModelSchema(g,x).parse({name:le,description:as,maxInputTokens:4092,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.responseFormat(4092,4).def,schema:r.responseFormat(4092,4).schema},price:T[le]}),yt=f,pe=class extends u{constructor(e){super(uo,e);}};var me="gpt-4-0125-preview",ls="The latest GPT-4 model intended to reduce cases of \u201Claziness\u201D where the model doesn\u2019t complete a task. Training data up to Apr 2023.",ho=provider.ChatModelSchema(g,x).parse({name:me,description:ls,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.base(4092,4).def,schema:r.base(4092,4).schema},price:T[me]}),Mt=f,de=class extends u{constructor(e){super(ho,e);}};var ce="gpt-4-0613",ms="Snapshot of gpt-4 from June 13th 2023 with improved function calling support. Training data up to Sept 2021.",fo=provider.ChatModelSchema(g,x).parse({name:ce,description:ms,maxInputTokens:8192,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.base(4092,4).def,schema:r.base(4092,4).schema},price:T[ce]}),Ot=f,ue=class extends u{constructor(e){super(fo,e);}};var he="gpt-4-1106-preview",cs="GPT-4 Turbo model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.   Returns a maximum of 4,096 output tokens. This preview model is not yet suited for production traffic. Training data up to Apr 2023.",go=provider.ChatModelSchema(g,x).parse({name:he,description:cs,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.base(4092,4).def,schema:r.base(4092,4).schema},price:T[he]}),Ct=f,fe=class extends u{constructor(e){super(go,e);}};var ge="gpt-4-turbo-2024-04-09",hs="GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. gpt-4-turbo currently points to this version.   Training data up to Dec 2023.",_o=provider.ChatModelSchema(g,C).parse({name:ge,description:hs,maxInputTokens:128e3,maxOutputTokens:4096,roles:_,modalities:O,config:{def:r.responseFormat(4096,4).def,schema:r.responseFormat(4096,4).schema},price:T[ge]}),bt=f,_e=class extends u{constructor(e){super(_o,e);}};var Te="gpt-4-turbo-preview",gs="Currently points to gpt-4-0125-preview. Training data up to Apr 2023.",To=provider.ChatModelSchema(g,x).parse({name:Te,description:gs,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.responseFormat(4092,4).def,schema:r.responseFormat(4092,4).schema},price:T[Te]}),Pt=f,ye=class extends u{constructor(e){super(To,e);}};var Me="gpt-4-turbo",Ts="The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.   Currently points to gpt-4-turbo-2024-04-09. Training data up to Dec 2023.",yo=provider.ChatModelSchema(g,C).parse({name:Me,description:Ts,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseFormat(4092,4).def,schema:r.responseFormat(4092,4).schema},price:T[Me]}),It=f,Oe=class extends u{constructor(e){super(yo,e);}};var Ce="gpt-4",Ms="Currently points to gpt-4-0613. Training data up to Sept 2021.",Mo=provider.ChatModelSchema(g,x).parse({name:Ce,description:Ms,maxInputTokens:8192,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.base(4092,4).def,schema:r.base(4092,4).schema},price:T[Ce]}),St=f,be=class extends u{constructor(e){super(Mo,e);}};var Pe="gpt-4o-2024-05-13",Cs="Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.",Oo=provider.ChatModelSchema(g,C).parse({name:Pe,description:Cs,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseSchema(4092,4).def,schema:r.responseSchema(4092,4).schema},price:T[Pe]}),xt=f,Ie=class extends u{constructor(e){super(Oo,e);}};var Se="gpt-4o-2024-08-06",Ps="Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.",Co=provider.ChatModelSchema(g,C).parse({name:Se,description:Ps,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseSchema(4092,4).def,schema:r.responseSchema(4092,4).schema},price:T[Se]}),Rt=f,xe=class extends u{constructor(e){super(Co,e);}};var Re="gpt-4o-mini-2024-07-18",Ss="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",bo=provider.ChatModelSchema(g,C).parse({name:Re,description:Ss,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseSchema(4092,4).def,schema:r.responseSchema(4092,4).schema},price:T[Re]}),At=f,Ae=class extends u{constructor(e){super(bo,e);}};var Ee="gpt-4o-mini",Rs="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",Po=provider.ChatModelSchema(g,C).parse({name:Ee,description:Rs,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseSchema(4092,4).def,schema:r.responseSchema(4092,4).schema},price:T[Ee]}),Et=f,ke=class extends u{constructor(e){super(Po,e);}};var we="gpt-4o",Es="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",Io=provider.ChatModelSchema(g,C).parse({name:we,description:Es,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseSchema(4092,4).def,schema:r.responseSchema(4092,4).schema},price:T[we]}),kt=f,Ge=class extends u{constructor(e){super(Io,e);}};var ve="o1-2024-12-17",ws="A stable release model for production use, offering robust performance and advanced features. Training data up to December 2024.",So=provider.ChatModelSchema(g,C).parse({name:ve,description:ws,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema},price:T[ve]}),wt=f,qe=class extends u{constructor(e){super(So,e);}};var De="o1",vs="Highly capable general-purpose reasoning model with advanced capabilities in language, coding, and reasoning. Training data up to Oct 2023.",xo=provider.ChatModelSchema(g,C).parse({name:De,description:vs,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema},price:T[De]}),Gt=f,Le=class extends u{constructor(e){super(xo,e);}};var Ro="o3-2025-04-16",Ds="A new standard for math, science, coding, and visual reasoning tasks. Training data up to Jun 2024.",Ao=provider.ChatModelSchema(g,C).parse({name:Ro,description:Ds,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),vt=f,ze=class extends u{constructor(e){super(Ao,e);}};var Eo="o3",zs="A new standard for math, science, coding, and visual reasoning tasks. Training data up to Jun 2024.",ko=provider.ChatModelSchema(g,C).parse({name:Eo,description:zs,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),qt=f,Be=class extends u{constructor(e){super(ko,e);}};var wo="o3-mini",Ns="o3-mini is the newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. Training data up to Sep 2023.",Go=provider.ChatModelSchema(g,x).parse({name:wo,description:Ns,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:S,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),Dt=f,Ne=class extends u{constructor(e){super(Go,e);}};var vo="o3-mini-2025-01-31",js="o3-mini is the newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. Training data up to Sep 2023.",qo=provider.ChatModelSchema(g,x).parse({name:vo,description:js,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:S,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),Lt=f,Ue=class extends u{constructor(e){super(qo,e);}};var Do="o4-mini-2025-04-16",$s="Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. Training data up to Jun 2024.",Lo=provider.ChatModelSchema(g,C).parse({name:Do,description:$s,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),zt=f,je=class extends u{constructor(e){super(Lo,e);}};var zo="o4-mini",Vs="Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. Training data up to Jun 2024.",Bo=provider.ChatModelSchema(g,C).parse({name:zo,description:Vs,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),Bt=f,Fe=class extends u{constructor(e){super(Bo,e);}};var K=[types.EmbeddingTextModalityLiteral,types.EmbeddingTokenModalityLiteral],J=zod.z.enum([types.EmbeddingTextModalityLiteral,types.EmbeddingTokenModalityLiteral]);var nn=zod.z.object({object:zod.z.literal("list"),model:zod.z.string(),data:zod.z.array(zod.z.object({index:zod.z.number(),object:zod.z.literal("embedding"),embedding:zod.z.array(zod.z.number()).or(zod.z.string().base64())})),usage:zod.z.object({prompt_tokens:zod.z.number().nonnegative(),total_tokens:zod.z.number().nonnegative()})});var Js=zod.z.string().min(1).or(zod.z.array(zod.z.string().min(1)).min(1)).or(zod.z.array(zod.z.number().int().nonnegative()).min(1)).or(zod.z.array(zod.z.array(zod.z.number().int().nonnegative()).min(1)).min(1)),sn=zod.z.object({model:zod.z.string().min(1).optional(),input:Js,encoding_format:zod.z.enum(["float","base64"]).optional(),dimensions:zod.z.number().int().min(1).optional()});var j=zod.z.object({modelName:zod.z.string(),apiKey:zod.z.string(),baseUrl:zod.z.string().url().optional(),getEmbeddingsUrl:zod.z.string().url().optional()}),z=class{constructor(e,t){this.version="v1";let o=j.parse(t);this.modelSchema=e,this.modelName=o.modelName,this.apiKey=o.apiKey,this.baseUrl=provider.urlWithoutTrailingSlash(o.baseUrl||N.baseUrl),this.getEmbeddingsUrl=provider.urlWithoutTrailingSlash(o.getEmbeddingsUrl||`${this.baseUrl}/embeddings`);}getDefaultBaseUrl(){return this.baseUrl}getDefaultHeaders(){return {Authorization:`Bearer ${this.apiKey}`,"Content-Type":"application/json"}}getDefaultParams(){return {model:this.modelSchema.name}}getRetryDelay(e){let t=a=>{let p=/(\d+)(h|m|s|ms)/g,h={h:36e5,m:6e4,s:1e3,ms:1},c,b=0;for(;(c=p.exec(a))!==null;){let y=parseInt(c[1]),M=c[2];b+=y*h[M];}return b},o=0,n=0,i=!0;e["x-ratelimit-reset-requests"]&&(o=t(e["x-ratelimit-reset-requests"])),e["x-ratelimit-reset-tokens"]&&(n=t(e["x-ratelimit-reset-tokens"]));let m=Math.max(o,n);return {shouldRetry:i,delayMs:m}}getTokenCount(e){return e.requests.reduce((t,o)=>t+o.length,0)}transformModelRequest(e){let t=sn.safeParse(e);if(!t.success)throw new provider.InvalidModelRequestError({info:"Invalid model request",cause:t.error});let o=t.data,n=o.model,i={encodingFormat:o.encoding_format,dimensions:o.dimensions},m=types.Config().parse(provider.removeUndefinedEntries(i)),a,p;return typeof o.input=="string"?p=types.EmbeddingTextModalityLiteral:typeof o.input[0]=="string"?p=types.EmbeddingTextModalityLiteral:p=types.EmbeddingTokenModalityLiteral,p===types.EmbeddingTextModalityLiteral?typeof o.input=="string"?a={modality:p,requests:[o.input]}:a={modality:p,requests:o.input}:typeof o.input[0]=="number"?a={modality:p,requests:[o.input]}:a={modality:p,requests:o.input},{modelName:n,config:m,embeddingRequests:a}}transformConfig(e,t){let o=this.modelSchema.config.schema.safeParse(e);if(!o.success)throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelSchema.name}'`,cause:o.error});let n=o.data;return Object.keys(n).forEach(m=>{if(!this.modelSchema.config.def[m])throw new provider.InvalidConfigError({info:`Invalid config for model : '${this.modelSchema.name}'`,cause:new Error(`Invalid config key : '${m}', 
            available keys : [${Object.keys(this.modelSchema.config.def).join(", ")}]`)})}),Object.keys(n).reduce((m,a)=>{let h=this.modelSchema.config.def[a].param,c=n[a];return m[h]=c,m},{})}transformEmbeddingRequests(e){let t=types.EmbeddingRequests().safeParse(e);if(!t.success)throw new provider.InvalidEmbeddingRequestsError({info:"Invalid embedding requests",cause:t.error});return {input:t.data.requests}}getGetEmbeddingsUrl(e,t){return A(this,null,function*(){return new Promise(o=>{o(this.getEmbeddingsUrl);})})}getGetEmbeddingsHeaders(e,t){return A(this,null,function*(){return new Promise(o=>{o(this.getDefaultHeaders());})})}getGetEmbeddingsData(e,t){return A(this,null,function*(){return new Promise(o=>{o(P(P(P({},this.getDefaultParams()),this.transformConfig(e,t)),this.transformEmbeddingRequests(t)));})})}transformGetEmbeddingsResponse(e){let t,o=nn.safeParse(e);if(o.success){let n=o.data;t=typeof n.data[0].embedding=="string"?types.Base64EmbeddingLiteral:types.FloatEmbeddingLiteral;let i=n.data.map(m=>typeof m.embedding=="string"?{index:m.index,embedding:m.embedding}:{index:m.index,embedding:m.embedding});return {encodingFormat:t,embeddings:i,usage:{totalTokens:n.usage.total_tokens}}}throw new provider.ModelResponseError({info:"Invalid response from model",cause:o.error})}};var No="text-embedding-ada-002",ii="Most capable 2nd generation embedding model, replacing 16 first generation models",Uo=provider.EmbeddingModelSchema(J).parse({name:No,description:ii,modalities:K,maxInputTokens:8192,maxOutputTokens:1536,config:{def:v.base().def,schema:v.base().schema}}),Nt=j,$e=class extends z{constructor(e){super(Uo,e);}};var jo="text-embedding-3-small",ri="Increased performance over 2nd generation ada embedding model",Fo=provider.EmbeddingModelSchema(J).parse({name:jo,description:ri,modalities:K,maxInputTokens:8192,maxOutputTokens:1536,config:{def:v.dimensions(1536).def,schema:v.dimensions(1536).schema}}),Ut=j,He=class extends z{constructor(e){super(Fo,e);}};var $o="text-embedding-3-large",pi="Most capable embedding model for both english and non-english tasks",Ho=provider.EmbeddingModelSchema(J).parse({name:$o,description:pi,modalities:K,maxInputTokens:8192,maxOutputTokens:3072,config:{def:v.dimensions(3072).def,schema:v.dimensions(3072).schema}}),jt=j,Ve=class extends z{constructor(e){super(Ho,e);}};

exports.BaseChatModel = u;
exports.BaseChatModelOptions = f;
exports.BaseEmbeddingModel = z;
exports.BaseEmbeddingModelOptions = j;
exports.ChatModelBaseConfigDef = $;
exports.ChatModelBaseConfigSchema = F;
exports.ChatModelOSeriesConfigDef = lt;
exports.ChatModelOSeriesConfigSchema = pt;
exports.ChatModelResponseFormatConfigDef = ct;
exports.ChatModelResponseFormatConfigSchema = ut;
exports.ChatModelResponseSchemaConfigDef = ee;
exports.ChatModelResponseSchemaConfigSchema = oe;
exports.EmbeddingModelBaseConfigDef = ne;
exports.EmbeddingModelBaseConfigSchema = te;
exports.EmbeddingModelDimensionsConfigDef = ft;
exports.EmbeddingModelDimensionsConfigSchema = ht;
exports.GPT_3_5_Turbo = pe;
exports.GPT_3_5_TurboLiteral = le;
exports.GPT_3_5_TurboOptions = yt;
exports.GPT_3_5_TurboSchema = uo;
exports.GPT_3_5_Turbo_0125 = ie;
exports.GPT_3_5_Turbo_0125Literal = se;
exports.GPT_3_5_Turbo_0125Options = _t;
exports.GPT_3_5_Turbo_0125Schema = mo;
exports.GPT_3_5_Turbo_1106 = re;
exports.GPT_3_5_Turbo_1106Literal = ae;
exports.GPT_3_5_Turbo_1106Options = Tt;
exports.GPT_3_5_Turbo_1106Schema = co;
exports.GPT_4 = be;
exports.GPT_4Literal = Ce;
exports.GPT_4Options = St;
exports.GPT_4Schema = Mo;
exports.GPT_4_0125_Preview = de;
exports.GPT_4_0125_PreviewLiteral = me;
exports.GPT_4_0125_PreviewOptions = Mt;
exports.GPT_4_0125_PreviewSchema = ho;
exports.GPT_4_0613 = ue;
exports.GPT_4_0613Literal = ce;
exports.GPT_4_0613Options = Ot;
exports.GPT_4_0613Schema = fo;
exports.GPT_4_1106_Preview = fe;
exports.GPT_4_1106_PreviewLiteral = he;
exports.GPT_4_1106_PreviewOptions = Ct;
exports.GPT_4_1106_PreviewSchema = go;
exports.GPT_4_Turbo = Oe;
exports.GPT_4_TurboLiteral = Me;
exports.GPT_4_TurboOptions = It;
exports.GPT_4_TurboSchema = yo;
exports.GPT_4_Turbo_2024_04_09 = _e;
exports.GPT_4_Turbo_2024_04_09Literal = ge;
exports.GPT_4_Turbo_2024_04_09Options = bt;
exports.GPT_4_Turbo_2024_04_09Schema = _o;
exports.GPT_4_Turbo_Preview = ye;
exports.GPT_4_Turbo_PreviewLiteral = Te;
exports.GPT_4_Turbo_PreviewOptions = Pt;
exports.GPT_4_Turbo_PreviewSchema = To;
exports.GPT_4o = Ge;
exports.GPT_4oLiteral = we;
exports.GPT_4oOptions = kt;
exports.GPT_4oSchema = Io;
exports.GPT_4o_2024_05_13 = Ie;
exports.GPT_4o_2024_05_13Literal = Pe;
exports.GPT_4o_2024_05_13Options = xt;
exports.GPT_4o_2024_05_13Schema = Oo;
exports.GPT_4o_2024_08_06 = xe;
exports.GPT_4o_2024_08_06Literal = Se;
exports.GPT_4o_2024_08_06Options = Rt;
exports.GPT_4o_2024_08_06Schema = Co;
exports.GPT_4o_Mini = ke;
exports.GPT_4o_MiniLiteral = Ee;
exports.GPT_4o_MiniOptions = Et;
exports.GPT_4o_MiniSchema = Po;
exports.GPT_4o_Mini_2024_07_18 = Ae;
exports.GPT_4o_Mini_2024_07_18Literal = Re;
exports.GPT_4o_Mini_2024_07_18Options = At;
exports.GPT_4o_Mini_2024_07_18Schema = bo;
exports.O1 = Le;
exports.O1Literal = De;
exports.O1Options = Gt;
exports.O1Schema = xo;
exports.O1_2024_12_17 = qe;
exports.O1_2024_12_17Literal = ve;
exports.O1_2024_12_17Options = wt;
exports.O1_2024_12_17Schema = So;
exports.O3 = Be;
exports.O3Literal = Eo;
exports.O3Mini = Ne;
exports.O3Mini2025_01_31 = Ue;
exports.O3Mini2025_01_31Literal = vo;
exports.O3Mini2025_01_31Options = Lt;
exports.O3Mini2025_01_31Schema = qo;
exports.O3MiniLiteral = wo;
exports.O3MiniOptions = Dt;
exports.O3MiniSchema = Go;
exports.O3Options = qt;
exports.O3Schema = ko;
exports.O3_2025_04_16 = ze;
exports.O3_2025_04_16Literal = Ro;
exports.O3_2025_04_16Options = vt;
exports.O3_2025_04_16Schema = Ao;
exports.O4_Mini = Fe;
exports.O4_MiniLiteral = zo;
exports.O4_MiniOptions = Bt;
exports.O4_MiniSchema = Bo;
exports.O4_Mini_2025_04_16 = je;
exports.O4_Mini_2025_04_16Literal = Do;
exports.O4_Mini_2025_04_16Options = zt;
exports.O4_Mini_2025_04_16Schema = Lo;
exports.OpenAI = N;
exports.OpenAIChatModelConfigs = r;
exports.OpenAIChatModelModalities = O;
exports.OpenAIChatModelModalitiesEnum = C;
exports.OpenAIChatModelRoles = g;
exports.OpenAIChatModelRolesMap = _;
exports.OpenAIChatModelTextModalities = oa;
exports.OpenAIChatModelTextModalitiesEnum = ta;
exports.OpenAIChatModelTextToolModalities = S;
exports.OpenAIChatModelTextToolModalitiesEnum = x;
exports.OpenAIChatRequest = Qt;
exports.OpenAIChatRequestAssistantMessage = Nn;
exports.OpenAIChatRequestImageContent = Dn;
exports.OpenAIChatRequestMessage = jn;
exports.OpenAIChatRequestResponseFormat = qn;
exports.OpenAIChatRequestSystemMessage = zn;
exports.OpenAIChatRequestTextContent = Ko;
exports.OpenAIChatRequestTool = wn;
exports.OpenAIChatRequestToolCallContent = Ln;
exports.OpenAIChatRequestToolChoiceEnum = Gn;
exports.OpenAIChatRequestToolChoiceFunction = vn;
exports.OpenAIChatRequestToolMessage = Un;
exports.OpenAIChatRequestUserMessage = Bn;
exports.OpenAICompleteChatResponse = Wt;
exports.OpenAIEmbeddingModelConfigs = v;
exports.OpenAIEmbeddingModelModalities = K;
exports.OpenAIEmbeddingModelModalitiesEnum = J;
exports.OpenAIEmbeddingRequest = sn;
exports.OpenAIEmbeddingRequestInput = Js;
exports.OpenAIGetEmbeddingsResponse = nn;
exports.OpenAIStreamChatResponse = Yt;
exports.OpenAIToolCallsCompleteChatResponse = En;
exports.OpenAIToolCallsStreamChatResponse = kn;
exports.ProviderLiteral = Rn;
exports.Text_Embedding_3_Large = Ve;
exports.Text_Embedding_3_LargeLiteral = $o;
exports.Text_Embedding_3_LargeSchema = Ho;
exports.Text_Embedding_3_Large_Options = jt;
exports.Text_Embedding_3_Small = He;
exports.Text_Embedding_3_SmallLiteral = jo;
exports.Text_Embedding_3_SmallSchema = Fo;
exports.Text_Embedding_3_Small_Options = Ut;
exports.Text_Embedding_Ada002 = $e;
exports.Text_Embedding_Ada002Literal = No;
exports.Text_Embedding_Ada002Schema = Uo;
exports.Text_Embedding_Ada002_Options = Nt;
exports.dimensions = po;
exports.encodingFormat = lo;
exports.frequencyPenalty = to;
exports.logProbs = io;
exports.maxTokens = Ze;
exports.presencePenalty = no;
exports.seed = so;
exports.stop = eo;
exports.temperature = Xe;
exports.toolChoice = ro;
exports.topLogProbs = ao;
exports.topP = oo;
//# sourceMappingURL=index.js.map
//# sourceMappingURL=index.js.map