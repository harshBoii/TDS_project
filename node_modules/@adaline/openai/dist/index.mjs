import { z as z$1 } from 'zod';
import { RangeConfigItem, CHAT_CONFIG, SelectBooleanConfigItem, SelectStringConfigItem, ObjectSchemaConfigItem, ChatModelSchema, EmbeddingModelSchema, MultiStringConfigItem, ProviderError, urlWithoutTrailingSlash, InvalidModelRequestError, removeUndefinedEntries, getMimeTypeFromBase64, InvalidConfigError, InvalidMessagesError, InvalidToolsError, ModelResponseError, InvalidEmbeddingRequestsError } from '@adaline/provider';
import { ResponseSchema, SystemRoleLiteral, UserRoleLiteral, AssistantRoleLiteral, ToolRoleLiteral, TextModalityLiteral, ImageModalityLiteral, ToolCallModalityLiteral, ToolResponseModalityLiteral, EmbeddingTextModalityLiteral, EmbeddingTokenModalityLiteral, Config, Base64ImageContentTypeLiteral, UrlImageContentTypeLiteral, Message, Tool, createTextContent, createToolCallContent, EmbeddingRequests, Base64EmbeddingLiteral, FloatEmbeddingLiteral, createPartialTextMessage, createPartialToolCallMessage } from '@adaline/types';

var ln=Object.defineProperty,pn=Object.defineProperties;var mn=Object.getOwnPropertyDescriptors;var Zo=Object.getOwnPropertySymbols;var dn=Object.prototype.hasOwnProperty,cn=Object.prototype.propertyIsEnumerable;var X=(s,e)=>(e=Symbol[s])?e:Symbol.for("Symbol."+s),un=s=>{throw TypeError(s)};var et=(s,e,t)=>e in s?ln(s,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):s[e]=t,P=(s,e)=>{for(var t in e||(e={}))dn.call(e,t)&&et(s,t,e[t]);if(Zo)for(var t of Zo(e))cn.call(e,t)&&et(s,t,e[t]);return s},L=(s,e)=>pn(s,mn(e));var A=(s,e,t)=>new Promise((o,n)=>{var i=p=>{try{a(t.next(p));}catch(h){n(h);}},m=p=>{try{a(t.throw(p));}catch(h){n(h);}},a=p=>p.done?o(p.value):Promise.resolve(p.value).then(i,m);a((t=t.apply(s,e)).next());}),ot=function(s,e){this[0]=s,this[1]=e;},Qe=(s,e,t)=>{var o=(m,a,p,h)=>{try{var c=t[m](a),b=(a=c.value)instanceof ot,y=c.done;Promise.resolve(b?a[0]:a).then(M=>b?o(m==="return"?m:"next",a[1]?{done:M.done,value:M.value}:M,p,h):p({value:M,done:y})).catch(M=>o("throw",M,p,h));}catch(M){h(M);}},n=m=>i[m]=a=>new Promise((p,h)=>o(m,a,p,h)),i={};return t=t.apply(s,e),i[X("asyncIterator")]=()=>i,n("next"),n("throw"),n("return"),i},tt=s=>{var e=s[X("asyncIterator")],t=!1,o,n={};return e==null?(e=s[X("iterator")](),o=i=>n[i]=m=>e[i](m)):(e=e.call(s),o=i=>n[i]=m=>{if(t){if(t=!1,i==="throw")throw m;return m}return t=!0,{done:!1,value:new ot(new Promise(a=>{var p=e[i](m);p instanceof Object||un("Object expected"),a(p);}),1)}}),n[X("iterator")]=()=>n,o("next"),"throw"in e?o("throw"):n.throw=i=>{throw i},"return"in e&&o("return"),n};var Xe=RangeConfigItem({param:"temperature",title:CHAT_CONFIG.TEMPERATURE.title,description:CHAT_CONFIG.TEMPERATURE.description,min:0,max:2,step:.01,default:1}),Ze=s=>RangeConfigItem({param:"max_completion_tokens",title:CHAT_CONFIG.MAX_TOKENS.title,description:CHAT_CONFIG.MAX_TOKENS.description,min:0,max:s,step:1,default:0}),eo=s=>MultiStringConfigItem({param:"stop",title:CHAT_CONFIG.STOP(s).title,description:CHAT_CONFIG.STOP(s).description,max:s}),oo=RangeConfigItem({param:"top_p",title:CHAT_CONFIG.TOP_P.title,description:CHAT_CONFIG.TOP_P.description,min:0,max:1,step:.01,default:1}),to=RangeConfigItem({param:"frequency_penalty",title:CHAT_CONFIG.FREQUENCY_PENALTY.title,description:CHAT_CONFIG.FREQUENCY_PENALTY.description,min:-2,max:2,step:.01,default:0}),no=RangeConfigItem({param:"presence_penalty",title:CHAT_CONFIG.PRESENCE_PENALTY.title,description:CHAT_CONFIG.PRESENCE_PENALTY.description,min:-2,max:2,step:.01,default:0}),so=RangeConfigItem({param:"seed",title:CHAT_CONFIG.SEED.title,description:CHAT_CONFIG.SEED.description,min:0,max:1e6,step:1,default:0}),io=SelectBooleanConfigItem({param:"logprobs",title:CHAT_CONFIG.LOG_PROBS.title,description:CHAT_CONFIG.LOG_PROBS.description,default:!1}),ao=RangeConfigItem({param:"top_logprobs",title:CHAT_CONFIG.TOP_LOG_PROBS.title,description:CHAT_CONFIG.TOP_LOG_PROBS.description,min:0,max:20,step:1,default:0}),ro=SelectStringConfigItem({param:"tool_choice",title:"Tool choice",description:"Controls which (if any) tool is called by the model. 'none' means the model will not call a function. 'auto' means the model can pick between generating a message or calling a tool.",default:"auto",choices:["auto","required","none"]});var F=(s,e)=>z$1.object({temperature:Xe.schema,maxTokens:Ze(s).schema,stop:eo(e).schema,topP:oo.schema,frequencyPenalty:to.schema,presencePenalty:no.schema,seed:so.schema.transform(t=>t===0?void 0:t),logProbs:io.schema,topLogProbs:ao.schema,toolChoice:ro.schema}),$=(s,e)=>({temperature:Xe.def,maxTokens:Ze(s).def,stop:eo(e).def,topP:oo.def,frequencyPenalty:to.def,presencePenalty:no.def,seed:so.def,logProbs:io.def,topLogProbs:ao.def,toolChoice:ro.def});var nt=ObjectSchemaConfigItem({param:"response_schema",title:CHAT_CONFIG.RESPONSE_SCHEMA.title,description:CHAT_CONFIG.RESPONSE_SCHEMA.description,objectSchema:ResponseSchema}),st=SelectStringConfigItem({param:"response_format",title:CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.title,description:CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.description,default:"text",choices:["text","json_object","json_schema"]}),ee=(s,e)=>L(P({},$(s,e)),{responseFormat:st.def,responseSchema:nt.def}),oe=(s,e)=>F(s,e).extend({responseFormat:st.schema,responseSchema:nt.schema});var at=RangeConfigItem({param:"temperature",title:CHAT_CONFIG.TEMPERATURE.title,description:CHAT_CONFIG.TEMPERATURE.description,min:1,max:1,step:.01,default:1}),rt=SelectStringConfigItem({param:"reasoning_effort",title:"Reasoning Effort",description:"Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.",default:"medium",choices:["low","medium","high"]}),lt=(s,e)=>L(P({},ee(s,e)),{temperature:at.def,reasoningEffort:rt.def}),pt=(s,e)=>oe(s,e).extend({temperature:at.schema,reasoningEffort:rt.schema});var dt=SelectStringConfigItem({param:"response_format",title:CHAT_CONFIG.RESPONSE_FORMAT.title,description:CHAT_CONFIG.RESPONSE_FORMAT.description,default:"text",choices:["text","json_object"]}),ct=(s,e)=>L(P({},$(s,e)),{responseFormat:dt.def}),ut=(s,e)=>F(s,e).extend({responseFormat:dt.schema});var lo=SelectStringConfigItem({param:"encoding_format",title:"Encoding format",description:"Select the encoding format for the word embedding.",default:"float",choices:["float","base64"]}),po=s=>RangeConfigItem({param:"dimensions",title:"Dimensions",description:"Select the number of dimensions for the word embedding.",min:1,max:s,step:1,default:s});var te=()=>z$1.object({encodingFormat:lo.schema}),ne=()=>({encodingFormat:lo.def});var ht=s=>te().extend({dimensions:po(s).schema}),ft=s=>L(P({},ne()),{dimensions:po(s).def});var r={base:(s,e)=>({def:$(s,e),schema:F(s,e)}),responseFormat:(s,e)=>({def:ct(s,e),schema:ut(s,e)}),responseSchema:(s,e)=>({def:ee(s,e),schema:oe(s,e)}),oSeries:(s,e)=>({def:lt(s,e),schema:pt(s,e)})},v={base:()=>({def:ne(),schema:te()}),dimensions:s=>({def:ft(s),schema:ht(s)})};var T={"gpt-3.5-turbo-0125":{modelName:"gpt-3.5-turbo-0125",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.5,outputPricePerMillion:1.5}}}]},"gpt-3.5-turbo-1106":{modelName:"gpt-3.5-turbo-1106",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.5,outputPricePerMillion:1.5}}}]},"gpt-3.5-turbo":{modelName:"gpt-3.5-turbo",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.5,outputPricePerMillion:1.5}}}]},"gpt-4-0125-preview":{modelName:"gpt-4-0125-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4-0613":{modelName:"gpt-4-0613",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4-1106-preview":{modelName:"gpt-4-1106-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4-turbo-2024-04-09":{modelName:"gpt-4-turbo-2024-04-09",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:30}}}]},"gpt-4-turbo-preview":{modelName:"gpt-4-turbo-preview",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:30}}}]},"gpt-4-turbo":{modelName:"gpt-4-turbo",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:30}}}]},"gpt-4":{modelName:"gpt-4",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:30,outputPricePerMillion:60}}}]},"gpt-4o-2024-05-13":{modelName:"gpt-4o-2024-05-13",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:5,outputPricePerMillion:20}}}]},"gpt-4o-2024-08-06":{modelName:"gpt-4o-2024-08-06",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:2.5,outputPricePerMillion:10}}}]},"gpt-4o-mini-2024-07-18":{modelName:"gpt-4o-mini-2024-07-18",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.6,outputPricePerMillion:2.4}}}]},"gpt-4o-mini":{modelName:"gpt-4o-mini",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:.6,outputPricePerMillion:2.4}}}]},"gpt-4o":{modelName:"gpt-4o",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:5,outputPricePerMillion:20}}}]},"o1-2024-12-17":{modelName:"o1-2024-12-17",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:15,outputPricePerMillion:60}}}]},o1:{modelName:"o1",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:15,outputPricePerMillion:60}}}]},"o3-mini-2025-01-31":{modelName:"o3-mini-2025-01-31",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]},"o3-mini":{modelName:"o3-mini",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]},"o3-2025-04-16":{modelName:"o3-2025-04-16",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:40}}}]},o3:{modelName:"o3",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:10,outputPricePerMillion:40}}}]},"o4-mini-2025-04-16":{modelName:"o4-mini-2025-04-16",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]},"o4-mini":{modelName:"o4-mini",currency:"USD",tokenRanges:[{minTokens:0,maxTokens:null,prices:{base:{inputPricePerMillion:1.1,outputPricePerMillion:4.4}}}]}};var Rn="openai",N=class{constructor(){this.version="v1";this.name=Rn;this.chatModelFactories={[le]:{model:pe,modelOptions:yt,modelSchema:uo},[se]:{model:ie,modelOptions:_t,modelSchema:mo},[ae]:{model:re,modelOptions:Tt,modelSchema:co},[me]:{model:de,modelOptions:Mt,modelSchema:ho},[ce]:{model:ue,modelOptions:Ot,modelSchema:fo},[he]:{model:fe,modelOptions:Ct,modelSchema:go},[ge]:{model:_e,modelOptions:bt,modelSchema:_o},[Te]:{model:ye,modelOptions:Pt,modelSchema:To},[Me]:{model:Oe,modelOptions:It,modelSchema:yo},[Ce]:{model:be,modelOptions:St,modelSchema:Mo},[Se]:{model:xe,modelOptions:Rt,modelSchema:Co},[Ee]:{model:ke,modelOptions:Et,modelSchema:Po},[we]:{model:Ge,modelOptions:kt,modelSchema:Io},[Re]:{model:Ae,modelOptions:At,modelSchema:bo},[Pe]:{model:Ie,modelOptions:xt,modelSchema:Oo},[De]:{model:Le,modelOptions:Gt,modelSchema:xo},[ve]:{model:qe,modelOptions:wt,modelSchema:So},[vo]:{model:Ue,modelOptions:Lt,modelSchema:qo},[wo]:{model:Ne,modelOptions:Dt,modelSchema:Go},[Ro]:{model:ze,modelOptions:vt,modelSchema:Ao},[Eo]:{model:Be,modelOptions:qt,modelSchema:ko},[Do]:{model:je,modelOptions:zt,modelSchema:Lo},[zo]:{model:Fe,modelOptions:Bt,modelSchema:Bo}};this.embeddingModelFactories={[No]:{model:$e,modelOptions:Nt,modelSchema:Uo},[jo]:{model:He,modelOptions:Ut,modelSchema:Fo},[$o]:{model:Ve,modelOptions:jt,modelSchema:Ho}};}chatModelLiterals(){return Object.keys(this.chatModelFactories)}chatModelSchemas(){return Object.keys(this.chatModelFactories).reduce((e,t)=>(e[t]=this.chatModelFactories[t].modelSchema,e),{})}chatModel(e){let t=e.modelName;if(!(t in this.chatModelFactories))throw new ProviderError({info:`OpenAI chat model: ${t} not found`,cause:new Error(`OpenAI chat model: ${t} not found, available chat models: 
          [${this.chatModelLiterals().join(", ")}]`)});let o=this.chatModelFactories[t].model,n=this.chatModelFactories[t].modelOptions.parse(e);return new o(n)}embeddingModelLiterals(){return Object.keys(this.embeddingModelFactories)}embeddingModelSchemas(){return Object.keys(this.embeddingModelFactories).reduce((e,t)=>(e[t]=this.embeddingModelFactories[t].modelSchema,e),{})}embeddingModel(e){let t=e.modelName;if(!(t in this.embeddingModelFactories))throw new ProviderError({info:`OpenAI embedding model: ${t} not found`,cause:new Error(`OpenAI embedding model: ${t} not found, available embedding models: 
          [${this.embeddingModelLiterals().join(", ")}]`)});let o=this.embeddingModelFactories[t].model,n=this.embeddingModelFactories[t].modelOptions.parse(e);return new o(n)}};N.baseUrl="https://api.openai.com/v1";var g=z$1.enum([SystemRoleLiteral,UserRoleLiteral,AssistantRoleLiteral,ToolRoleLiteral]),_={system:SystemRoleLiteral,user:UserRoleLiteral,assistant:AssistantRoleLiteral,tool:ToolRoleLiteral};var O=[TextModalityLiteral,ImageModalityLiteral,ToolCallModalityLiteral,ToolResponseModalityLiteral],C=z$1.enum([TextModalityLiteral,ImageModalityLiteral,ToolCallModalityLiteral,ToolResponseModalityLiteral]),oa=[TextModalityLiteral],ta=z$1.enum([TextModalityLiteral]),S=[TextModalityLiteral,ToolCallModalityLiteral,ToolResponseModalityLiteral],x=z$1.enum([TextModalityLiteral,ToolCallModalityLiteral,ToolResponseModalityLiteral]);var We=z$1.object({token:z$1.string(),logprob:z$1.number(),bytes:z$1.array(z$1.number()).nullable()}),Jt=z$1.object({content:z$1.array(We.extend({top_logprobs:z$1.array(We)})).nullable().optional(),refusal:z$1.array(We.extend({top_logprobs:z$1.array(We)})).nullable().optional()}).nullable(),En=z$1.array(z$1.object({id:z$1.string().min(1),type:z$1.enum(["function"]),function:z$1.object({name:z$1.string(),arguments:z$1.string()})})),Wt=z$1.object({id:z$1.string(),object:z$1.literal("chat.completion"),created:z$1.number(),model:z$1.string(),system_fingerprint:z$1.string().nullable(),choices:z$1.array(z$1.object({index:z$1.number(),message:z$1.object({role:z$1.string(),content:z$1.string().nullable().optional(),tool_calls:En.optional(),refusal:z$1.string().nullable().optional()}),logprobs:Jt.optional(),finish_reason:z$1.string()})),usage:z$1.object({prompt_tokens:z$1.number(),completion_tokens:z$1.number(),total_tokens:z$1.number()})}),kn=z$1.array(z$1.object({index:z$1.number().int(),id:z$1.string().min(1).optional(),type:z$1.enum(["function"]).optional(),function:z$1.object({name:z$1.string().min(1).optional(),arguments:z$1.string().optional()}).optional()})),Yt=z$1.object({id:z$1.string(),object:z$1.string(),created:z$1.number(),model:z$1.string(),system_fingerprint:z$1.string().nullable().optional(),choices:z$1.array(z$1.object({index:z$1.number(),delta:z$1.object({content:z$1.string().nullable().optional(),tool_calls:kn.optional(),refusal:z$1.string().nullable().optional()}).or(z$1.object({})),logprobs:Jt.optional(),finish_reason:z$1.string().nullable()})),usage:z$1.object({prompt_tokens:z$1.number(),completion_tokens:z$1.number(),total_tokens:z$1.number()}).nullable().optional()});var wn=z$1.object({type:z$1.literal("function"),function:z$1.object({name:z$1.string().min(1),description:z$1.string().min(1).optional(),strict:z$1.boolean().optional(),parameters:z$1.any()})}),Gn=z$1.enum(["none","auto","required"]),vn=z$1.object({type:z$1.literal("function"),function:z$1.object({name:z$1.string().min(1)})}),qn=z$1.object({type:z$1.enum(["text","json_object"])}).or(z$1.object({type:z$1.literal("json_schema"),json_schema:z$1.object({name:z$1.string().min(1),description:z$1.string().min(1).optional(),strict:z$1.boolean().optional(),schema:z$1.any()})})),Ko=z$1.object({text:z$1.string().min(1),type:z$1.literal("text")}),Dn=z$1.object({type:z$1.literal("image_url"),image_url:z$1.object({url:z$1.string().url().min(1),detail:z$1.enum(["low","high","auto"]).optional()})}),Ln=z$1.object({id:z$1.string().min(1),type:z$1.literal("function"),function:z$1.object({name:z$1.string().min(1),arguments:z$1.string().min(1)})}),zn=z$1.object({role:z$1.literal("system"),content:z$1.string().min(1).or(z$1.array(Ko).min(1))}),Bn=z$1.object({role:z$1.literal("user"),content:z$1.string().min(1).or(z$1.array(z$1.union([Ko,Dn])).min(1))}),Nn=z$1.object({role:z$1.literal("assistant"),content:z$1.string().min(1).or(z$1.array(Ko).min(1)).optional(),tool_calls:z$1.array(Ln).min(1).optional()}),Un=z$1.object({role:z$1.literal("tool"),tool_call_id:z$1.string().min(1),content:z$1.string().min(1)}),jn=z$1.union([zn,Bn,Nn,Un]),Qt=z$1.object({model:z$1.string().min(1).optional(),messages:z$1.array(jn).min(1),frequency_penalty:z$1.number().min(-2).max(2).nullable().optional(),logprobs:z$1.boolean().nullable().optional(),top_logprobs:z$1.number().min(0).max(20).nullable().optional(),max_completion_tokens:z$1.number().min(0).nullable().optional(),presence_penalty:z$1.number().min(-2).max(2).nullable().optional(),response_format:qn.optional(),seed:z$1.number().nullable().optional(),stop:z$1.string().or(z$1.array(z$1.string()).max(4)).nullable().optional(),temperature:z$1.number().min(0).max(2).nullable().optional(),top_p:z$1.number().min(0).max(1).nullable().optional(),tools:z$1.array(wn).optional(),tool_choice:Gn.or(vn).optional()});var f=z$1.object({modelName:z$1.string(),apiKey:z$1.string(),baseUrl:z$1.string().url().optional(),completeChatUrl:z$1.string().url().optional(),streamChatUrl:z$1.string().url().optional(),organization:z$1.string().optional()}),u=class{constructor(e,t){this.version="v1";let o=f.parse(t);this.modelSchema=e,this.modelName=o.modelName,this.apiKey=o.apiKey,this.baseUrl=urlWithoutTrailingSlash(o.baseUrl||N.baseUrl),this.streamChatUrl=urlWithoutTrailingSlash(o.streamChatUrl||`${this.baseUrl}/chat/completions`),this.completeChatUrl=urlWithoutTrailingSlash(o.completeChatUrl||`${this.baseUrl}/chat/completions`),this.organization=o.organization;}getDefaultBaseUrl(){return this.baseUrl}getDefaultHeaders(){return P({Authorization:`Bearer ${this.apiKey}`,"Content-Type":"application/json"},this.organization?{"OpenAI-Organization":this.organization}:{})}getDefaultParams(){return {model:this.modelName}}getRetryDelay(e){let t=a=>{let p=/(\d+)(h|m|s|ms)/g,h={h:36e5,m:6e4,s:1e3,ms:1},c,b=0;for(;(c=p.exec(a))!==null;){let y=parseInt(c[1]),M=c[2];b+=y*h[M];}return b},o=0,n=0,i=!0;e["x-ratelimit-reset-requests"]&&(o=t(e["x-ratelimit-reset-requests"])),e["x-ratelimit-reset-tokens"]&&(n=t(e["x-ratelimit-reset-tokens"]));let m=Math.max(o,n);return {shouldRetry:i,delayMs:m}}getTokenCount(e){return e.reduce((t,o)=>t+o.content.map(n=>n.modality==="text"?n.value:"").join(" ").length,0)}transformModelRequest(e){let t=Qt.safeParse(e);if(!t.success)throw new InvalidModelRequestError({info:"Invalid model request",cause:t.error});let o=t.data,n=o.model;if(o.tool_choice&&(!o.tools||o.tools.length===0))throw new InvalidModelRequestError({info:`Invalid model request for model : '${this.modelName}'`,cause:new Error("'tools' are required when 'tool_choice' is specified")});let i={};o.response_format&&(i.responseFormat=o.response_format.type,o.response_format.type==="json_schema"&&(i.responseSchema={name:o.response_format.json_schema.name,description:o.response_format.json_schema.description||"",strict:o.response_format.json_schema.strict,schema:o.response_format.json_schema.schema})),o.tool_choice&&(typeof o.tool_choice=="string"?i.toolChoice=o.tool_choice:i.toolChoice=o.tool_choice.function.name),i.seed=o.seed,i.maxTokens=o.max_completion_tokens,i.temperature=o.temperature,i.topP=o.top_p,i.presencePenalty=o.presence_penalty,i.frequencyPenalty=o.frequency_penalty,i.stop=o.stop,i.logProbs=o.logprobs,i.topLogProbs=o.top_logprobs;let m=Config().parse(removeUndefinedEntries(i)),a=[],p={};o.messages.forEach(c=>{let b=c.role;switch(b){case"system":{let y=c.content;if(typeof y=="string")a.push({role:b,content:[{modality:TextModalityLiteral,value:y}]});else {let M=y.map(I=>({modality:TextModalityLiteral,value:I.text}));a.push({role:b,content:M});}}break;case"user":{let y=c.content;if(typeof y=="string")a.push({role:b,content:[{modality:TextModalityLiteral,value:y}]});else {let M=y.map(I=>I.type==="text"?{modality:TextModalityLiteral,value:I.text}:I.image_url.url.startsWith("data:")?{modality:ImageModalityLiteral,detail:I.image_url.detail||"auto",value:{type:Base64ImageContentTypeLiteral,base64:I.image_url.url,mediaType:getMimeTypeFromBase64(I.image_url.url)}}:{modality:ImageModalityLiteral,detail:I.image_url.detail||"auto",value:{type:UrlImageContentTypeLiteral,url:I.image_url.url}});a.push({role:b,content:M});}}break;case"assistant":{let y=[];if(!c.content&&!c.tool_calls)throw new InvalidModelRequestError({info:`Invalid model request for model : '${this.modelName}'`,cause:new Error("one of'content' or 'tool_calls' must be provided")});if(c.content){let M=c.content;typeof M=="string"?y.push({modality:TextModalityLiteral,value:M}):M.forEach(I=>{y.push({modality:TextModalityLiteral,value:I.text});});}c.tool_calls&&c.tool_calls.forEach((I,E)=>{let D={modality:ToolCallModalityLiteral,id:I.id,index:E,name:I.function.name,arguments:I.function.arguments};y.push(D),p[D.id]=D;}),a.push({role:b,content:y});}break;case"tool":{let y=c;a.push({role:b,content:[{modality:ToolResponseModalityLiteral,id:y.tool_call_id,index:p[y.tool_call_id].index,name:p[y.tool_call_id].name,data:y.content}]});}break}});let h=[];return o.tools&&o.tools.forEach(c=>{h.push({type:"function",definition:{schema:{name:c.function.name,description:c.function.description||"",strict:c.function.strict,parameters:c.function.parameters}}});}),{modelName:n,config:m,messages:a,tools:h.length>0?h:void 0}}transformConfig(e,t,o){let n=e.toolChoice;delete e.toolChoice;let i=this.modelSchema.config.schema.safeParse(e);if(!i.success)throw new InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:i.error});let m=i.data;n!==void 0&&(m.toolChoice=n),Object.keys(m).forEach(p=>{if(!(p in this.modelSchema.config.def))throw new InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error(`Invalid config key : '${p}', 
            available keys : [${Object.keys(this.modelSchema.config.def).join(", ")}]`)})});let a=Object.keys(m).reduce((p,h)=>{let c=this.modelSchema.config.def[h],b=c.param,y=m[h];return b==="max_completion_tokens"&&c.type==="range"&&y===0?p[b]=c.max:p[b]=y,p},{});if(a.top_logprobs&&!a.logprobs)throw new InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'logprobs' must be 'true' when 'top_logprobs' is specified")});if("tool_choice"in a&&a.tool_choice!==void 0){let p=a.tool_choice;if(!o||o&&o.length===0)throw new InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'tools' are required when 'toolChoice' is specified")});if(o&&o.length>0){let h=this.modelSchema.config.def.toolChoice;if(!h.choices.includes(p))if(o.map(c=>c.definition.schema.name).includes(p))a.tool_choice={type:"function",function:{name:p}};else throw new InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error(`toolChoice : '${p}' is not part of provided 'tools' names or 
                one of [${h.choices.join(", ")}]`)})}}if("response_format"in a&&a.response_format!==void 0){let p=a.response_format;if(p==="json_schema")if("response_schema"in a)a.response_format={type:"json_schema",json_schema:a.response_schema},delete a.response_schema;else throw new InvalidConfigError({info:`Invalid config for model : '${this.modelName}'`,cause:new Error("'responseSchema' is required in config when 'responseFormat' is 'json_schema'")});else a.response_format={type:p};}return a}transformMessages(e){if(!e||e&&e.length===0)return {messages:[]};let t=e.map(n=>{let i=Message().safeParse(n);if(!i.success)throw new InvalidMessagesError({info:"Invalid messages",cause:i.error});return i.data});return t.forEach(n=>{n.content.forEach(i=>{if(!this.modelSchema.modalities.includes(i.modality))throw new InvalidMessagesError({info:`Invalid message content for model : '${this.modelName}'`,cause:new Error(`model : '${this.modelName}' does not support modality : '${i.modality}', 
              available modalities : [${this.modelSchema.modalities.join(", ")}]`)})});}),t.forEach(n=>{if(!Object.keys(this.modelSchema.roles).includes(n.role))throw new InvalidMessagesError({info:`Invalid message content for model : '${this.modelName}'`,cause:new Error(`model : '${this.modelName}' does not support role : '${n.role}', 
            available roles : [${Object.keys(this.modelSchema.roles).join(", ")}]`)})}),{messages:t.map(n=>{switch(n.role){case SystemRoleLiteral:{let i=[];return n.content.forEach(m=>{if(m.modality===TextModalityLiteral)i.push({type:"text",text:m.value});else throw new InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${n.role}' cannot have content with modality : '${m.modality}'`)})}),{role:this.modelSchema.roles[n.role],content:i}}case AssistantRoleLiteral:{let i=[],m=[];return n.content.forEach(a=>{if(a.modality===TextModalityLiteral)i.push({type:"text",text:a.value});else if(a.modality===ToolCallModalityLiteral)m.push({id:a.id,type:"function",function:{name:a.name,arguments:a.arguments}});else throw new InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${n.role}' cannot have content with modality : '${a.modality}'`)})}),P({role:this.modelSchema.roles[n.role],content:i},m.length>0?{tool_calls:m}:{})}case UserRoleLiteral:{let i=[],m=[];n.content.forEach(p=>{if(p.modality===TextModalityLiteral)i.push({type:"text",text:p.value});else if(p.modality===ImageModalityLiteral)m.push({type:"image_url",image_url:{url:p.value.type==="url"?p.value.url:p.value.base64,detail:p.detail}});else throw new InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${n.role}' cannot have content with modality : '${p.modality}'`)})});let a=[...i,...m];return {role:this.modelSchema.roles[n.role],content:a}}case ToolRoleLiteral:{if(n.content.length!==1)throw new InvalidMessagesError({info:`Invalid message for role : '${n.role}'`,cause:new Error(`role : '${n.role}' must have exactly one content item`)});if(n.content[0].modality!==ToolResponseModalityLiteral)throw new InvalidMessagesError({info:`Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,cause:new Error(`role : '${n.role}' must have content with modality : '${ToolResponseModalityLiteral}'`)});let i=n.content[0];return {role:this.modelSchema.roles[n.role],tool_call_id:i.id,content:i.data}}default:throw new InvalidMessagesError({info:`Invalid message 'role' for model : ${this.modelName}`,cause:new Error(`role : '${n.role}' is not supported, 
              available roles : [${Object.keys(this.modelSchema.roles).join(", ")}]`)})}})}}transformTools(e){if(!this.modelSchema.modalities.includes(ToolCallModalityLiteral))throw new InvalidToolsError({info:`Invalid tool 'modality' for model : ${this.modelName}`,cause:new Error(`model : '${this.modelName}' does not support tool modality : '${ToolCallModalityLiteral}'`)});return !e||e&&e.length===0?{tools:[]}:{tools:e.map(n=>{let i=Tool().safeParse(n);if(!i.success)throw new InvalidToolsError({info:"Invalid tools",cause:i.error});return i.data}).map(n=>({type:"function",function:n.definition.schema}))}}getCompleteChatUrl(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.completeChatUrl);})})}getCompleteChatHeaders(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.getDefaultHeaders());})})}getCompleteChatData(e,t,o){return A(this,null,function*(){let n=this.transformConfig(e,t,o),i=this.transformMessages(t);if(i.messages&&i.messages.length===0)throw new InvalidMessagesError({info:"Messages are required",cause:new Error("Messages are required")});let m=o?this.transformTools(o):{};return new Promise(a=>{a(P(P(P(P({},this.getDefaultParams()),n),i),m));})})}transformCompleteChatResponse(e){let t=Wt.safeParse(e);if(t.success){if(t.data.choices.length===0)throw new ModelResponseError({info:"Invalid response from model",cause:new Error(`No choices in response : ${JSON.stringify(t.data)}`)});let o=t.data,n=[{role:AssistantRoleLiteral,content:[]}],i=o.choices[0].message;i.content&&n[0].content.push(createTextContent(i.content)),i.refusal&&n[0].content.push(createTextContent(i.refusal)),i.tool_calls&&i.tool_calls.forEach((h,c)=>{n[0].content.push(createToolCallContent(c,h.id,h.function.name,h.function.arguments));});let m={promptTokens:o.usage.prompt_tokens,completionTokens:o.usage.completion_tokens,totalTokens:o.usage.total_tokens},a=[],p=o.choices[0].logprobs;return p&&(p.content&&a.push(...p.content.map(h=>({token:h.token,logProb:h.logprob,bytes:h.bytes,topLogProbs:h.top_logprobs.map(c=>({token:c.token,logProb:c.logprob,bytes:c.bytes}))}))),p.refusal&&a.push(...p.refusal.map(h=>({token:h.token,logProb:h.logprob,bytes:h.bytes,topLogProbs:h.top_logprobs.map(c=>({token:c.token,logProb:c.logprob,bytes:c.bytes}))})))),{messages:n,usage:m,logProbs:a}}throw new ModelResponseError({info:"Invalid response from model",cause:t.error})}getStreamChatUrl(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.streamChatUrl);})})}getStreamChatHeaders(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.getDefaultHeaders());})})}getStreamChatData(e,t,o){return A(this,null,function*(){let n=this.transformConfig(e,t,o),i=this.transformMessages(t);if(i.messages&&i.messages.length===0)throw new InvalidMessagesError({info:"Messages are required",cause:new Error("Messages are required")});let m=o?this.transformTools(o):{};return new Promise(a=>{a(P(P(P(P({stream:!0,stream_options:{include_usage:!0}},this.getDefaultParams()),n),i),m));})})}transformStreamChatResponseChunk(e,t){return Qe(this,null,function*(){var a,p;let o=t+e,n=[],i="",m=0;for(;m<o.length;){let h=o.indexOf(`
`,m);if(h===-1){i=o.substring(m);break}else {let c=o.substring(m,h).trim();c&&n.push(c),m=h+1;}}for(let h of n){if(h==="data: [DONE]")return;if(h.startsWith("data: ")){let c=h.substring(6);try{let b=JSON.parse(c),y=Yt.safeParse(b);if(y.success){let M={partialMessages:[]},I=y.data;if(I.choices.length>0){let E=I.choices[0].delta;if(E!==void 0&&Object.keys(E).length!==0){if("content"in E&&E.content!==null)M.partialMessages.push(createPartialTextMessage(AssistantRoleLiteral,E.content));else if("refusal"in E&&E.refusal!==null)M.partialMessages.push(createPartialTextMessage(AssistantRoleLiteral,E.refusal));else if("tool_calls"in E&&E.tool_calls!==void 0){let D=E.tool_calls.at(0);M.partialMessages.push(createPartialToolCallMessage(AssistantRoleLiteral,D.index,D.id,(a=D.function)==null?void 0:a.name,(p=D.function)==null?void 0:p.arguments));}}}I.usage&&(M.usage={promptTokens:I.usage.prompt_tokens,completionTokens:I.usage.completion_tokens,totalTokens:I.usage.total_tokens}),yield {partialResponse:M,buffer:i};}else throw new ModelResponseError({info:"Invalid response from model",cause:y.error})}catch(b){throw new ModelResponseError({info:`Malformed JSON received in stream: ${c}`,cause:b})}}}yield {partialResponse:{partialMessages:[]},buffer:i};})}transformProxyStreamChatResponseChunk(e,t,o,n,i){return Qe(this,null,function*(){yield*tt(this.transformStreamChatResponseChunk(e,t));})}getProxyStreamChatUrl(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.streamChatUrl);})})}getProxyCompleteChatUrl(e,t,o){return A(this,null,function*(){return new Promise(n=>{n(this.completeChatUrl);})})}getProxyCompleteChatHeaders(e,t,o){return A(this,null,function*(){if(!t)return {};let n=P({},t);return delete n.host,delete n["content-length"],n})}getProxyStreamChatHeaders(e,t,o){return A(this,null,function*(){return yield this.getProxyCompleteChatHeaders(e,t,o)})}getModelPricing(){if(!(this.modelName in T))throw new ModelResponseError({info:`Invalid model pricing for model : '${this.modelName}'`,cause:new Error(`No pricing configuration found for model "${this.modelName}"`)});return T[this.modelName]}};var se="gpt-3.5-turbo-0125",ts="The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a   text encoding issue for non-English language function calls. Training data up to Sept 2021.",mo=ChatModelSchema(g,x).parse({name:se,description:ts,maxInputTokens:4092,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.responseFormat(4092,4).def,schema:r.responseFormat(4092,4).schema},price:T[se]}),_t=f,ie=class extends u{constructor(e){super(mo,e);}};var ae="gpt-3.5-turbo-1106",ss="The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.   Returns a maximum of 4,096 output tokens. Training data up to Sept 2021.",co=ChatModelSchema(g,x).parse({name:ae,description:ss,maxInputTokens:4092,maxOutputTokens:16385,roles:_,modalities:S,config:{def:r.responseFormat(16385,4).def,schema:r.responseFormat(16385,4).schema},price:T[ae]}),Tt=f,re=class extends u{constructor(e){super(co,e);}};var le="gpt-3.5-turbo",as="Currently points to gpt-3.5-turbo-0125. Training data up to Sept 2021.",uo=ChatModelSchema(g,x).parse({name:le,description:as,maxInputTokens:4092,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.responseFormat(4092,4).def,schema:r.responseFormat(4092,4).schema},price:T[le]}),yt=f,pe=class extends u{constructor(e){super(uo,e);}};var me="gpt-4-0125-preview",ls="The latest GPT-4 model intended to reduce cases of \u201Claziness\u201D where the model doesn\u2019t complete a task. Training data up to Apr 2023.",ho=ChatModelSchema(g,x).parse({name:me,description:ls,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.base(4092,4).def,schema:r.base(4092,4).schema},price:T[me]}),Mt=f,de=class extends u{constructor(e){super(ho,e);}};var ce="gpt-4-0613",ms="Snapshot of gpt-4 from June 13th 2023 with improved function calling support. Training data up to Sept 2021.",fo=ChatModelSchema(g,x).parse({name:ce,description:ms,maxInputTokens:8192,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.base(4092,4).def,schema:r.base(4092,4).schema},price:T[ce]}),Ot=f,ue=class extends u{constructor(e){super(fo,e);}};var he="gpt-4-1106-preview",cs="GPT-4 Turbo model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.   Returns a maximum of 4,096 output tokens. This preview model is not yet suited for production traffic. Training data up to Apr 2023.",go=ChatModelSchema(g,x).parse({name:he,description:cs,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.base(4092,4).def,schema:r.base(4092,4).schema},price:T[he]}),Ct=f,fe=class extends u{constructor(e){super(go,e);}};var ge="gpt-4-turbo-2024-04-09",hs="GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. gpt-4-turbo currently points to this version.   Training data up to Dec 2023.",_o=ChatModelSchema(g,C).parse({name:ge,description:hs,maxInputTokens:128e3,maxOutputTokens:4096,roles:_,modalities:O,config:{def:r.responseFormat(4096,4).def,schema:r.responseFormat(4096,4).schema},price:T[ge]}),bt=f,_e=class extends u{constructor(e){super(_o,e);}};var Te="gpt-4-turbo-preview",gs="Currently points to gpt-4-0125-preview. Training data up to Apr 2023.",To=ChatModelSchema(g,x).parse({name:Te,description:gs,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.responseFormat(4092,4).def,schema:r.responseFormat(4092,4).schema},price:T[Te]}),Pt=f,ye=class extends u{constructor(e){super(To,e);}};var Me="gpt-4-turbo",Ts="The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling.   Currently points to gpt-4-turbo-2024-04-09. Training data up to Dec 2023.",yo=ChatModelSchema(g,C).parse({name:Me,description:Ts,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseFormat(4092,4).def,schema:r.responseFormat(4092,4).schema},price:T[Me]}),It=f,Oe=class extends u{constructor(e){super(yo,e);}};var Ce="gpt-4",Ms="Currently points to gpt-4-0613. Training data up to Sept 2021.",Mo=ChatModelSchema(g,x).parse({name:Ce,description:Ms,maxInputTokens:8192,maxOutputTokens:4092,roles:_,modalities:S,config:{def:r.base(4092,4).def,schema:r.base(4092,4).schema},price:T[Ce]}),St=f,be=class extends u{constructor(e){super(Mo,e);}};var Pe="gpt-4o-2024-05-13",Cs="Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.",Oo=ChatModelSchema(g,C).parse({name:Pe,description:Cs,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseSchema(4092,4).def,schema:r.responseSchema(4092,4).schema},price:T[Pe]}),xt=f,Ie=class extends u{constructor(e){super(Oo,e);}};var Se="gpt-4o-2024-08-06",Ps="Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.",Co=ChatModelSchema(g,C).parse({name:Se,description:Ps,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseSchema(4092,4).def,schema:r.responseSchema(4092,4).schema},price:T[Se]}),Rt=f,xe=class extends u{constructor(e){super(Co,e);}};var Re="gpt-4o-mini-2024-07-18",Ss="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",bo=ChatModelSchema(g,C).parse({name:Re,description:Ss,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseSchema(4092,4).def,schema:r.responseSchema(4092,4).schema},price:T[Re]}),At=f,Ae=class extends u{constructor(e){super(bo,e);}};var Ee="gpt-4o-mini",Rs="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",Po=ChatModelSchema(g,C).parse({name:Ee,description:Rs,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseSchema(4092,4).def,schema:r.responseSchema(4092,4).schema},price:T[Ee]}),Et=f,ke=class extends u{constructor(e){super(Po,e);}};var we="gpt-4o",Es="Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13.   Training data up to Oct 2023.",Io=ChatModelSchema(g,C).parse({name:we,description:Es,maxInputTokens:128e3,maxOutputTokens:4092,roles:_,modalities:O,config:{def:r.responseSchema(4092,4).def,schema:r.responseSchema(4092,4).schema},price:T[we]}),kt=f,Ge=class extends u{constructor(e){super(Io,e);}};var ve="o1-2024-12-17",ws="A stable release model for production use, offering robust performance and advanced features. Training data up to December 2024.",So=ChatModelSchema(g,C).parse({name:ve,description:ws,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema},price:T[ve]}),wt=f,qe=class extends u{constructor(e){super(So,e);}};var De="o1",vs="Highly capable general-purpose reasoning model with advanced capabilities in language, coding, and reasoning. Training data up to Oct 2023.",xo=ChatModelSchema(g,C).parse({name:De,description:vs,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema},price:T[De]}),Gt=f,Le=class extends u{constructor(e){super(xo,e);}};var Ro="o3-2025-04-16",Ds="A new standard for math, science, coding, and visual reasoning tasks. Training data up to Jun 2024.",Ao=ChatModelSchema(g,C).parse({name:Ro,description:Ds,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),vt=f,ze=class extends u{constructor(e){super(Ao,e);}};var Eo="o3",zs="A new standard for math, science, coding, and visual reasoning tasks. Training data up to Jun 2024.",ko=ChatModelSchema(g,C).parse({name:Eo,description:zs,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),qt=f,Be=class extends u{constructor(e){super(ko,e);}};var wo="o3-mini",Ns="o3-mini is the newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. Training data up to Sep 2023.",Go=ChatModelSchema(g,x).parse({name:wo,description:Ns,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:S,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),Dt=f,Ne=class extends u{constructor(e){super(Go,e);}};var vo="o3-mini-2025-01-31",js="o3-mini is the newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. Training data up to Sep 2023.",qo=ChatModelSchema(g,x).parse({name:vo,description:js,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:S,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),Lt=f,Ue=class extends u{constructor(e){super(qo,e);}};var Do="o4-mini-2025-04-16",$s="Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. Training data up to Jun 2024.",Lo=ChatModelSchema(g,C).parse({name:Do,description:$s,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),zt=f,je=class extends u{constructor(e){super(Lo,e);}};var zo="o4-mini",Vs="Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. Training data up to Jun 2024.",Bo=ChatModelSchema(g,C).parse({name:zo,description:Vs,maxInputTokens:2e5,maxOutputTokens:1e5,roles:_,modalities:O,config:{def:r.oSeries(1e5,4).def,schema:r.oSeries(1e5,4).schema}}),Bt=f,Fe=class extends u{constructor(e){super(Bo,e);}};var K=[EmbeddingTextModalityLiteral,EmbeddingTokenModalityLiteral],J=z$1.enum([EmbeddingTextModalityLiteral,EmbeddingTokenModalityLiteral]);var nn=z$1.object({object:z$1.literal("list"),model:z$1.string(),data:z$1.array(z$1.object({index:z$1.number(),object:z$1.literal("embedding"),embedding:z$1.array(z$1.number()).or(z$1.string().base64())})),usage:z$1.object({prompt_tokens:z$1.number().nonnegative(),total_tokens:z$1.number().nonnegative()})});var Js=z$1.string().min(1).or(z$1.array(z$1.string().min(1)).min(1)).or(z$1.array(z$1.number().int().nonnegative()).min(1)).or(z$1.array(z$1.array(z$1.number().int().nonnegative()).min(1)).min(1)),sn=z$1.object({model:z$1.string().min(1).optional(),input:Js,encoding_format:z$1.enum(["float","base64"]).optional(),dimensions:z$1.number().int().min(1).optional()});var j=z$1.object({modelName:z$1.string(),apiKey:z$1.string(),baseUrl:z$1.string().url().optional(),getEmbeddingsUrl:z$1.string().url().optional()}),z=class{constructor(e,t){this.version="v1";let o=j.parse(t);this.modelSchema=e,this.modelName=o.modelName,this.apiKey=o.apiKey,this.baseUrl=urlWithoutTrailingSlash(o.baseUrl||N.baseUrl),this.getEmbeddingsUrl=urlWithoutTrailingSlash(o.getEmbeddingsUrl||`${this.baseUrl}/embeddings`);}getDefaultBaseUrl(){return this.baseUrl}getDefaultHeaders(){return {Authorization:`Bearer ${this.apiKey}`,"Content-Type":"application/json"}}getDefaultParams(){return {model:this.modelSchema.name}}getRetryDelay(e){let t=a=>{let p=/(\d+)(h|m|s|ms)/g,h={h:36e5,m:6e4,s:1e3,ms:1},c,b=0;for(;(c=p.exec(a))!==null;){let y=parseInt(c[1]),M=c[2];b+=y*h[M];}return b},o=0,n=0,i=!0;e["x-ratelimit-reset-requests"]&&(o=t(e["x-ratelimit-reset-requests"])),e["x-ratelimit-reset-tokens"]&&(n=t(e["x-ratelimit-reset-tokens"]));let m=Math.max(o,n);return {shouldRetry:i,delayMs:m}}getTokenCount(e){return e.requests.reduce((t,o)=>t+o.length,0)}transformModelRequest(e){let t=sn.safeParse(e);if(!t.success)throw new InvalidModelRequestError({info:"Invalid model request",cause:t.error});let o=t.data,n=o.model,i={encodingFormat:o.encoding_format,dimensions:o.dimensions},m=Config().parse(removeUndefinedEntries(i)),a,p;return typeof o.input=="string"?p=EmbeddingTextModalityLiteral:typeof o.input[0]=="string"?p=EmbeddingTextModalityLiteral:p=EmbeddingTokenModalityLiteral,p===EmbeddingTextModalityLiteral?typeof o.input=="string"?a={modality:p,requests:[o.input]}:a={modality:p,requests:o.input}:typeof o.input[0]=="number"?a={modality:p,requests:[o.input]}:a={modality:p,requests:o.input},{modelName:n,config:m,embeddingRequests:a}}transformConfig(e,t){let o=this.modelSchema.config.schema.safeParse(e);if(!o.success)throw new InvalidConfigError({info:`Invalid config for model : '${this.modelSchema.name}'`,cause:o.error});let n=o.data;return Object.keys(n).forEach(m=>{if(!this.modelSchema.config.def[m])throw new InvalidConfigError({info:`Invalid config for model : '${this.modelSchema.name}'`,cause:new Error(`Invalid config key : '${m}', 
            available keys : [${Object.keys(this.modelSchema.config.def).join(", ")}]`)})}),Object.keys(n).reduce((m,a)=>{let h=this.modelSchema.config.def[a].param,c=n[a];return m[h]=c,m},{})}transformEmbeddingRequests(e){let t=EmbeddingRequests().safeParse(e);if(!t.success)throw new InvalidEmbeddingRequestsError({info:"Invalid embedding requests",cause:t.error});return {input:t.data.requests}}getGetEmbeddingsUrl(e,t){return A(this,null,function*(){return new Promise(o=>{o(this.getEmbeddingsUrl);})})}getGetEmbeddingsHeaders(e,t){return A(this,null,function*(){return new Promise(o=>{o(this.getDefaultHeaders());})})}getGetEmbeddingsData(e,t){return A(this,null,function*(){return new Promise(o=>{o(P(P(P({},this.getDefaultParams()),this.transformConfig(e,t)),this.transformEmbeddingRequests(t)));})})}transformGetEmbeddingsResponse(e){let t,o=nn.safeParse(e);if(o.success){let n=o.data;t=typeof n.data[0].embedding=="string"?Base64EmbeddingLiteral:FloatEmbeddingLiteral;let i=n.data.map(m=>typeof m.embedding=="string"?{index:m.index,embedding:m.embedding}:{index:m.index,embedding:m.embedding});return {encodingFormat:t,embeddings:i,usage:{totalTokens:n.usage.total_tokens}}}throw new ModelResponseError({info:"Invalid response from model",cause:o.error})}};var No="text-embedding-ada-002",ii="Most capable 2nd generation embedding model, replacing 16 first generation models",Uo=EmbeddingModelSchema(J).parse({name:No,description:ii,modalities:K,maxInputTokens:8192,maxOutputTokens:1536,config:{def:v.base().def,schema:v.base().schema}}),Nt=j,$e=class extends z{constructor(e){super(Uo,e);}};var jo="text-embedding-3-small",ri="Increased performance over 2nd generation ada embedding model",Fo=EmbeddingModelSchema(J).parse({name:jo,description:ri,modalities:K,maxInputTokens:8192,maxOutputTokens:1536,config:{def:v.dimensions(1536).def,schema:v.dimensions(1536).schema}}),Ut=j,He=class extends z{constructor(e){super(Fo,e);}};var $o="text-embedding-3-large",pi="Most capable embedding model for both english and non-english tasks",Ho=EmbeddingModelSchema(J).parse({name:$o,description:pi,modalities:K,maxInputTokens:8192,maxOutputTokens:3072,config:{def:v.dimensions(3072).def,schema:v.dimensions(3072).schema}}),jt=j,Ve=class extends z{constructor(e){super(Ho,e);}};

export { u as BaseChatModel, f as BaseChatModelOptions, z as BaseEmbeddingModel, j as BaseEmbeddingModelOptions, $ as ChatModelBaseConfigDef, F as ChatModelBaseConfigSchema, lt as ChatModelOSeriesConfigDef, pt as ChatModelOSeriesConfigSchema, ct as ChatModelResponseFormatConfigDef, ut as ChatModelResponseFormatConfigSchema, ee as ChatModelResponseSchemaConfigDef, oe as ChatModelResponseSchemaConfigSchema, ne as EmbeddingModelBaseConfigDef, te as EmbeddingModelBaseConfigSchema, ft as EmbeddingModelDimensionsConfigDef, ht as EmbeddingModelDimensionsConfigSchema, pe as GPT_3_5_Turbo, le as GPT_3_5_TurboLiteral, yt as GPT_3_5_TurboOptions, uo as GPT_3_5_TurboSchema, ie as GPT_3_5_Turbo_0125, se as GPT_3_5_Turbo_0125Literal, _t as GPT_3_5_Turbo_0125Options, mo as GPT_3_5_Turbo_0125Schema, re as GPT_3_5_Turbo_1106, ae as GPT_3_5_Turbo_1106Literal, Tt as GPT_3_5_Turbo_1106Options, co as GPT_3_5_Turbo_1106Schema, be as GPT_4, Ce as GPT_4Literal, St as GPT_4Options, Mo as GPT_4Schema, de as GPT_4_0125_Preview, me as GPT_4_0125_PreviewLiteral, Mt as GPT_4_0125_PreviewOptions, ho as GPT_4_0125_PreviewSchema, ue as GPT_4_0613, ce as GPT_4_0613Literal, Ot as GPT_4_0613Options, fo as GPT_4_0613Schema, fe as GPT_4_1106_Preview, he as GPT_4_1106_PreviewLiteral, Ct as GPT_4_1106_PreviewOptions, go as GPT_4_1106_PreviewSchema, Oe as GPT_4_Turbo, Me as GPT_4_TurboLiteral, It as GPT_4_TurboOptions, yo as GPT_4_TurboSchema, _e as GPT_4_Turbo_2024_04_09, ge as GPT_4_Turbo_2024_04_09Literal, bt as GPT_4_Turbo_2024_04_09Options, _o as GPT_4_Turbo_2024_04_09Schema, ye as GPT_4_Turbo_Preview, Te as GPT_4_Turbo_PreviewLiteral, Pt as GPT_4_Turbo_PreviewOptions, To as GPT_4_Turbo_PreviewSchema, Ge as GPT_4o, we as GPT_4oLiteral, kt as GPT_4oOptions, Io as GPT_4oSchema, Ie as GPT_4o_2024_05_13, Pe as GPT_4o_2024_05_13Literal, xt as GPT_4o_2024_05_13Options, Oo as GPT_4o_2024_05_13Schema, xe as GPT_4o_2024_08_06, Se as GPT_4o_2024_08_06Literal, Rt as GPT_4o_2024_08_06Options, Co as GPT_4o_2024_08_06Schema, ke as GPT_4o_Mini, Ee as GPT_4o_MiniLiteral, Et as GPT_4o_MiniOptions, Po as GPT_4o_MiniSchema, Ae as GPT_4o_Mini_2024_07_18, Re as GPT_4o_Mini_2024_07_18Literal, At as GPT_4o_Mini_2024_07_18Options, bo as GPT_4o_Mini_2024_07_18Schema, Le as O1, De as O1Literal, Gt as O1Options, xo as O1Schema, qe as O1_2024_12_17, ve as O1_2024_12_17Literal, wt as O1_2024_12_17Options, So as O1_2024_12_17Schema, Be as O3, Eo as O3Literal, Ne as O3Mini, Ue as O3Mini2025_01_31, vo as O3Mini2025_01_31Literal, Lt as O3Mini2025_01_31Options, qo as O3Mini2025_01_31Schema, wo as O3MiniLiteral, Dt as O3MiniOptions, Go as O3MiniSchema, qt as O3Options, ko as O3Schema, ze as O3_2025_04_16, Ro as O3_2025_04_16Literal, vt as O3_2025_04_16Options, Ao as O3_2025_04_16Schema, Fe as O4_Mini, zo as O4_MiniLiteral, Bt as O4_MiniOptions, Bo as O4_MiniSchema, je as O4_Mini_2025_04_16, Do as O4_Mini_2025_04_16Literal, zt as O4_Mini_2025_04_16Options, Lo as O4_Mini_2025_04_16Schema, N as OpenAI, r as OpenAIChatModelConfigs, O as OpenAIChatModelModalities, C as OpenAIChatModelModalitiesEnum, g as OpenAIChatModelRoles, _ as OpenAIChatModelRolesMap, oa as OpenAIChatModelTextModalities, ta as OpenAIChatModelTextModalitiesEnum, S as OpenAIChatModelTextToolModalities, x as OpenAIChatModelTextToolModalitiesEnum, Qt as OpenAIChatRequest, Nn as OpenAIChatRequestAssistantMessage, Dn as OpenAIChatRequestImageContent, jn as OpenAIChatRequestMessage, qn as OpenAIChatRequestResponseFormat, zn as OpenAIChatRequestSystemMessage, Ko as OpenAIChatRequestTextContent, wn as OpenAIChatRequestTool, Ln as OpenAIChatRequestToolCallContent, Gn as OpenAIChatRequestToolChoiceEnum, vn as OpenAIChatRequestToolChoiceFunction, Un as OpenAIChatRequestToolMessage, Bn as OpenAIChatRequestUserMessage, Wt as OpenAICompleteChatResponse, v as OpenAIEmbeddingModelConfigs, K as OpenAIEmbeddingModelModalities, J as OpenAIEmbeddingModelModalitiesEnum, sn as OpenAIEmbeddingRequest, Js as OpenAIEmbeddingRequestInput, nn as OpenAIGetEmbeddingsResponse, Yt as OpenAIStreamChatResponse, En as OpenAIToolCallsCompleteChatResponse, kn as OpenAIToolCallsStreamChatResponse, Rn as ProviderLiteral, Ve as Text_Embedding_3_Large, $o as Text_Embedding_3_LargeLiteral, Ho as Text_Embedding_3_LargeSchema, jt as Text_Embedding_3_Large_Options, He as Text_Embedding_3_Small, jo as Text_Embedding_3_SmallLiteral, Fo as Text_Embedding_3_SmallSchema, Ut as Text_Embedding_3_Small_Options, $e as Text_Embedding_Ada002, No as Text_Embedding_Ada002Literal, Uo as Text_Embedding_Ada002Schema, Nt as Text_Embedding_Ada002_Options, po as dimensions, lo as encodingFormat, to as frequencyPenalty, io as logProbs, Ze as maxTokens, no as presencePenalty, so as seed, eo as stop, Xe as temperature, ro as toolChoice, ao as topLogProbs, oo as topP };
//# sourceMappingURL=index.mjs.map
//# sourceMappingURL=index.mjs.map