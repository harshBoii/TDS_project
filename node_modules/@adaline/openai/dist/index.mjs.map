{"version":3,"sources":["../src/configs/chat-model/common.config.chat-model.openai.ts","../src/configs/chat-model/base.config.chat-model.openai.ts","../src/configs/chat-model/o-series.config.chat-model.openai.ts","../src/configs/chat-model/response-schema.config.chat-model.openai.ts","../src/configs/chat-model/response-format.config.chat-model.openai.ts","../src/configs/embedding-model/common.config.embedding-model.openai.ts","../src/configs/embedding-model/base.config.embedding-model.openai.ts","../src/configs/embedding-model/dimensions.config.embedding-model.openai.ts","../src/configs/configs.openai.ts","../src/models/pricing.json","../src/provider/provider.openai.ts","../src/models/chat-models/types/roles.chat-model.openai.ts","../src/models/chat-models/types/modalities.chat-model.openai.ts","../src/models/chat-models/types/response.chat-model.openai.ts","../src/models/chat-models/types/request.chat-model.openai.ts","../src/models/chat-models/base-chat-model.openai.ts","../src/models/chat-models/gpt-3-5-turbo-0125.openai.ts","../src/models/chat-models/gpt-3-5-turbo-1106.openai.ts","../src/models/chat-models/gpt-3-5-turbo.openai.ts","../src/models/chat-models/gpt-4-0125-preview.openai.ts","../src/models/chat-models/gpt-4-0613.openai.ts","../src/models/chat-models/gpt-4-1106-preview.openai.ts","../src/models/chat-models/gpt-4-turbo-2024-04-09.openai.ts","../src/models/chat-models/gpt-4-turbo-preview.openai.ts","../src/models/chat-models/gpt-4-turbo.openai.ts","../src/models/chat-models/gpt-4.openai.ts","../src/models/chat-models/gpt-4o-2024-05-13.openai.ts","../src/models/chat-models/gpt-4o-2024-08-06.openai.ts","../src/models/chat-models/gpt-4o-mini-2024-07-18.openai.ts","../src/models/chat-models/gpt-4o-mini.openai.ts","../src/models/chat-models/gpt-4o.openai.ts","../src/models/chat-models/o1-2024-12-17.openai.ts","../src/models/chat-models/o1.openai.ts","../src/models/chat-models/o3-2025-04-16.openai.ts","../src/models/chat-models/o3.openai.ts","../src/models/chat-models/o3-mini.openai.ts","../src/models/chat-models/o3-mini-2025-01-31.openai.ts","../src/models/chat-models/o4-mini-2025-04-16.openai.ts","../src/models/chat-models/o4-mini.openai.ts","../src/models/embedding-models/types/modalitites.embedding-model.openai.ts","../src/models/embedding-models/types/response.embedding-model.openai.ts","../src/models/embedding-models/types/request.embedding-model.openai.ts","../src/models/embedding-models/base-embedding-model.openai.ts","../src/models/embedding-models/text-embedding-ada-002.openai.ts","../src/models/embedding-models/text-embedding-3-small.openai.ts","../src/models/embedding-models/text-embedding-3-large.openai.ts"],"names":["temperature","RangeConfigItem","CHAT_CONFIG","maxTokens","maxOutputTokens","stop","maxSequences","MultiStringConfigItem","topP","frequencyPenalty","presencePenalty","seed","logProbs","SelectBooleanConfigItem","topLogProbs","toolChoice","SelectStringConfigItem","ChatModelBaseConfigSchema","z","value","ChatModelBaseConfigDef","responseSchema","ObjectSchemaConfigItem","ResponseSchema","responseFormat","ChatModelResponseSchemaConfigDef","__spreadProps","__spreadValues","ChatModelResponseSchemaConfigSchema","reasoningEffort","ChatModelOSeriesConfigDef","ChatModelOSeriesConfigSchema","ChatModelResponseFormatConfigDef","ChatModelResponseFormatConfigSchema","encodingFormat","dimensions","maxDimensions","EmbeddingModelBaseConfigSchema","EmbeddingModelBaseConfigDef","EmbeddingModelDimensionsConfigSchema","EmbeddingModelDimensionsConfigDef","OpenAIChatModelConfigs","OpenAIEmbeddingModelConfigs","pricing_default","ProviderLiteral","OpenAI","GPT_3_5_TurboLiteral","GPT_3_5_Turbo","GPT_3_5_TurboOptions","GPT_3_5_TurboSchema","GPT_3_5_Turbo_0125Literal","GPT_3_5_Turbo_0125","GPT_3_5_Turbo_0125Options","GPT_3_5_Turbo_0125Schema","GPT_3_5_Turbo_1106Literal","GPT_3_5_Turbo_1106","GPT_3_5_Turbo_1106Options","GPT_3_5_Turbo_1106Schema","GPT_4_0125_PreviewLiteral","GPT_4_0125_Preview","GPT_4_0125_PreviewOptions","GPT_4_0125_PreviewSchema","GPT_4_0613Literal","GPT_4_0613","GPT_4_0613Options","GPT_4_0613Schema","GPT_4_1106_PreviewLiteral","GPT_4_1106_Preview","GPT_4_1106_PreviewOptions","GPT_4_1106_PreviewSchema","GPT_4_Turbo_2024_04_09Literal","GPT_4_Turbo_2024_04_09","GPT_4_Turbo_2024_04_09Options","GPT_4_Turbo_2024_04_09Schema","GPT_4_Turbo_PreviewLiteral","GPT_4_Turbo_Preview","GPT_4_Turbo_PreviewOptions","GPT_4_Turbo_PreviewSchema","GPT_4_TurboLiteral","GPT_4_Turbo","GPT_4_TurboOptions","GPT_4_TurboSchema","GPT_4Literal","GPT_4","GPT_4Options","GPT_4Schema","GPT_4o_2024_08_06Literal","GPT_4o_2024_08_06","GPT_4o_2024_08_06Options","GPT_4o_2024_08_06Schema","GPT_4o_MiniLiteral","GPT_4o_Mini","GPT_4o_MiniOptions","GPT_4o_MiniSchema","GPT_4oLiteral","GPT_4o","GPT_4oOptions","GPT_4oSchema","GPT_4o_Mini_2024_07_18Literal","GPT_4o_Mini_2024_07_18","GPT_4o_Mini_2024_07_18Options","GPT_4o_Mini_2024_07_18Schema","GPT_4o_2024_05_13Literal","GPT_4o_2024_05_13","GPT_4o_2024_05_13Options","GPT_4o_2024_05_13Schema","O1Literal","O1","O1Options","O1Schema","O1_2024_12_17Literal","O1_2024_12_17","O1_2024_12_17Options","O1_2024_12_17Schema","O3Mini2025_01_31Literal","O3Mini2025_01_31","O3Mini2025_01_31Options","O3Mini2025_01_31Schema","O3MiniLiteral","O3Mini","O3MiniOptions","O3MiniSchema","O3_2025_04_16Literal","O3_2025_04_16","O3_2025_04_16Options","O3_2025_04_16Schema","O3Literal","O3","O3Options","O3Schema","O4_Mini_2025_04_16Literal","O4_Mini_2025_04_16","O4_Mini_2025_04_16Options","O4_Mini_2025_04_16Schema","O4_MiniLiteral","O4_Mini","O4_MiniOptions","O4_MiniSchema","Text_Embedding_Ada002Literal","Text_Embedding_Ada002","Text_Embedding_Ada002_Options","Text_Embedding_Ada002Schema","Text_Embedding_3_SmallLiteral","Text_Embedding_3_Small","Text_Embedding_3_Small_Options","Text_Embedding_3_SmallSchema","Text_Embedding_3_LargeLiteral","Text_Embedding_3_Large","Text_Embedding_3_Large_Options","Text_Embedding_3_LargeSchema","acc","key","options","modelName","ProviderError","model","parsedOptions","OpenAIChatModelRoles","SystemRoleLiteral","UserRoleLiteral","AssistantRoleLiteral","ToolRoleLiteral","OpenAIChatModelRolesMap","OpenAIChatModelModalities","TextModalityLiteral","ImageModalityLiteral","ToolCallModalityLiteral","ToolResponseModalityLiteral","OpenAIChatModelModalitiesEnum","OpenAIChatModelTextModalities","OpenAIChatModelTextModalitiesEnum","OpenAIChatModelTextToolModalities","OpenAIChatModelTextToolModalitiesEnum","OpenAIBaseLogProb","OpenAILogProb","OpenAIToolCallsCompleteChatResponse","OpenAICompleteChatResponse","OpenAIToolCallsStreamChatResponse","OpenAIStreamChatResponse","OpenAIChatRequestTool","OpenAIChatRequestToolChoiceEnum","OpenAIChatRequestToolChoiceFunction","OpenAIChatRequestResponseFormat","OpenAIChatRequestTextContent","OpenAIChatRequestImageContent","OpenAIChatRequestToolCallContent","OpenAIChatRequestSystemMessage","OpenAIChatRequestUserMessage","OpenAIChatRequestAssistantMessage","OpenAIChatRequestToolMessage","OpenAIChatRequestMessage","OpenAIChatRequest","BaseChatModelOptions","BaseChatModel","modelSchema","urlWithoutTrailingSlash","responseHeaders","parseDuration","duration","regex","timeUnits","match","totalMs","unit","resetRequestsDelayMs","resetTokensDelayMs","shouldRetry","delayMs","messages","message","content","request","safeRequest","InvalidModelRequestError","parsedRequest","_config","config","Config","removeUndefinedEntries","toolCallMap","role","_content","c","Base64ImageContentTypeLiteral","getMimeTypeFromBase64","UrlImageContentTypeLiteral","assistantContent","toolCall","index","toolCallContent","toolResponse","tools","tool","_toolChoice","_parsedConfig","InvalidConfigError","parsedConfig","transformedConfig","def","paramKey","paramValue","configToolChoice","parsedMessages","parsedMessage","Message","InvalidMessagesError","textContent","toolCalls","imageContent","combinedContent","InvalidToolsError","parsedTool","Tool","__async","resolve","transformedMessages","transformedTools","response","safe","ModelResponseError","parsedResponse","createTextContent","createToolCallContent","usage","_logProbs","logProb","topLogProb","chunk","buffer","__asyncGenerator","_a","_b","data","lines","newBuffer","currentIndex","newlineIndex","line","jsonStr","structuredLine","partialResponse","createPartialTextMessage","createPartialToolCallMessage","error","headers","query","__yieldStar","sanitizedHeaders","GPT_3_5_Turbo_0125Description","ChatModelSchema","GPT_3_5_Turbo_1106Description","GPT_3_5_TurboDescription","GPT_4_0125_PreviewDescription","GPT_4_0613Description","GPT_4_1106_PreviewDescription","GPT_4_Turbo_2024_04_09Description","GPT_4_Turbo_PreviewDescription","GPT_4_TurboDescription","GPT_4Description","GPT_4o_2024_05_13Description","GPT_4o_2024_08_06Description","GPT_4o_MiniDescription","GPT_4oDescription","O1_2024_12_17Description","O1Description","O3_2025_04_16Description","O3Description","O3MiniDescription","O3Mini2025_01_31Description","O4_Mini_2025_04_16Description","O4_MiniDescription","OpenAIEmbeddingModelModalities","EmbeddingTextModalityLiteral","EmbeddingTokenModalityLiteral","OpenAIEmbeddingModelModalitiesEnum","OpenAIGetEmbeddingsResponse","OpenAIEmbeddingRequestInput","OpenAIEmbeddingRequest","BaseEmbeddingModelOptions","BaseEmbeddingModel","requests","embeddingRequests","embeddingFormat","_parsedRequests","EmbeddingRequests","InvalidEmbeddingRequestsError","Base64EmbeddingLiteral","FloatEmbeddingLiteral","embeddings","item","Text_Embedding_Ada002Description","EmbeddingModelSchema","Text_Embedding_3_SmallDescription","Text_Embedding_3_LargeDescription"],"mappings":";;;;2hDAEA,IAAMA,EAAcC,CAAAA,eAAAA,CAAgB,CAClC,KAAO,CAAA,aAAA,CACP,KAAOC,CAAAA,WAAAA,CAAY,WAAY,CAAA,KAAA,CAC/B,YAAaA,WAAY,CAAA,WAAA,CAAY,WACrC,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAK,EACL,IAAM,CAAA,GAAA,CACN,OAAS,CAAA,CACX,CAAC,CAAA,CAEKC,GAAaC,CACjBH,EAAAA,eAAAA,CAAgB,CACd,KAAA,CAAO,uBACP,CAAA,KAAA,CAAOC,YAAY,UAAW,CAAA,KAAA,CAC9B,WAAaA,CAAAA,WAAAA,CAAY,UAAW,CAAA,WAAA,CACpC,IAAK,CACL,CAAA,GAAA,CAAKE,CACL,CAAA,IAAA,CAAM,CACN,CAAA,OAAA,CAAS,CACX,CAAC,CAAA,CAEGC,EAAQC,CAAAA,CAAAA,EACZC,qBAAsB,CAAA,CACpB,MAAO,MACP,CAAA,KAAA,CAAOL,WAAY,CAAA,IAAA,CAAKI,CAAY,CAAA,CAAE,MACtC,WAAaJ,CAAAA,WAAAA,CAAY,IAAKI,CAAAA,CAAY,CAAE,CAAA,WAAA,CAC5C,IAAKA,CACP,CAAC,CAEGE,CAAAA,EAAAA,CAAOP,eAAgB,CAAA,CAC3B,MAAO,OACP,CAAA,KAAA,CAAOC,WAAY,CAAA,KAAA,CAAM,KACzB,CAAA,WAAA,CAAaA,YAAY,KAAM,CAAA,WAAA,CAC/B,GAAK,CAAA,CAAA,CACL,GAAK,CAAA,CAAA,CACL,KAAM,GACN,CAAA,OAAA,CAAS,CACX,CAAC,CAEKO,CAAAA,EAAAA,CAAmBR,gBAAgB,CACvC,KAAA,CAAO,mBACP,CAAA,KAAA,CAAOC,WAAY,CAAA,iBAAA,CAAkB,MACrC,WAAaA,CAAAA,WAAAA,CAAY,iBAAkB,CAAA,WAAA,CAC3C,GAAK,CAAA,CAAA,CAAA,CACL,IAAK,CACL,CAAA,IAAA,CAAM,GACN,CAAA,OAAA,CAAS,CACX,CAAC,EAEKQ,EAAkBT,CAAAA,eAAAA,CAAgB,CACtC,KAAA,CAAO,kBACP,CAAA,KAAA,CAAOC,YAAY,gBAAiB,CAAA,KAAA,CACpC,WAAaA,CAAAA,WAAAA,CAAY,gBAAiB,CAAA,WAAA,CAC1C,IAAK,CACL,CAAA,CAAA,GAAA,CAAK,CACL,CAAA,IAAA,CAAM,GACN,CAAA,OAAA,CAAS,CACX,CAAC,CAAA,CAEKS,EAAOV,CAAAA,eAAAA,CAAgB,CAC3B,KAAA,CAAO,OACP,KAAOC,CAAAA,WAAAA,CAAY,IAAK,CAAA,KAAA,CACxB,WAAaA,CAAAA,WAAAA,CAAY,KAAK,WAC9B,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAK,GACL,CAAA,IAAA,CAAM,EACN,OAAS,CAAA,CACX,CAAC,CAAA,CAEKU,EAAWC,CAAAA,uBAAAA,CAAwB,CACvC,KAAO,CAAA,UAAA,CACP,KAAOX,CAAAA,WAAAA,CAAY,SAAU,CAAA,KAAA,CAC7B,YAAaA,WAAY,CAAA,SAAA,CAAU,WACnC,CAAA,OAAA,CAAS,CACX,CAAA,CAAC,EAEKY,EAAcb,CAAAA,eAAAA,CAAgB,CAClC,KAAA,CAAO,cACP,CAAA,KAAA,CAAOC,YAAY,aAAc,CAAA,KAAA,CACjC,WAAaA,CAAAA,WAAAA,CAAY,aAAc,CAAA,WAAA,CACvC,IAAK,CACL,CAAA,GAAA,CAAK,EACL,CAAA,IAAA,CAAM,CACN,CAAA,OAAA,CAAS,CACX,CAAC,CAAA,CAEKa,EAAaC,CAAAA,sBAAAA,CAAuB,CACxC,KAAA,CAAO,cACP,KAAO,CAAA,aAAA,CACP,YACE,uLACF,CAAA,OAAA,CAAS,OACT,OAAS,CAAA,CAAC,MAAQ,CAAA,UAAA,CAAY,MAAM,CACtC,CAAC,EChFD,IAAMC,CAA4B,CAAA,CAACb,CAAyBE,CAAAA,CAAAA,GAC1DY,IAAE,MAAO,CAAA,CACP,WAAalB,CAAAA,EAAAA,CAAY,MACzB,CAAA,SAAA,CAAWG,GAAUC,CAAe,CAAA,CAAE,MACtC,CAAA,IAAA,CAAMC,EAAKC,CAAAA,CAAY,EAAE,MACzB,CAAA,IAAA,CAAME,EAAK,CAAA,MAAA,CACX,gBAAkBC,CAAAA,EAAAA,CAAiB,OACnC,eAAiBC,CAAAA,EAAAA,CAAgB,MACjC,CAAA,IAAA,CAAMC,EAAK,CAAA,MAAA,CAAO,UAAWQ,CAAWA,EAAAA,CAAAA,GAAU,CAAI,CAAA,KAAA,CAAA,CAAYA,CAAM,CAAA,CACxE,SAAUP,EAAS,CAAA,MAAA,CACnB,WAAaE,CAAAA,EAAAA,CAAY,MACzB,CAAA,UAAA,CAAYC,GAAW,MACzB,CAAC,CAEGK,CAAAA,CAAAA,CAAyB,CAAChB,CAAAA,CAAyBE,KACtD,CACC,WAAA,CAAaN,EAAY,CAAA,GAAA,CACzB,SAAWG,CAAAA,EAAAA,CAAUC,CAAe,CAAE,CAAA,GAAA,CACtC,IAAMC,CAAAA,EAAAA,CAAKC,CAAY,CAAA,CAAE,IACzB,IAAME,CAAAA,EAAAA,CAAK,GACX,CAAA,gBAAA,CAAkBC,EAAiB,CAAA,GAAA,CACnC,gBAAiBC,EAAgB,CAAA,GAAA,CACjC,IAAMC,CAAAA,EAAAA,CAAK,GACX,CAAA,QAAA,CAAUC,GAAS,GACnB,CAAA,WAAA,CAAaE,EAAY,CAAA,GAAA,CACzB,UAAYC,CAAAA,EAAAA,CAAW,GACzB,CCzCF,ECKMM,IAAAA,EAAAA,CAAiBC,sBAAuB,CAAA,CAC5C,KAAO,CAAA,iBAAA,CACP,MAAOpB,WAAY,CAAA,eAAA,CAAgB,KACnC,CAAA,WAAA,CAAaA,WAAY,CAAA,eAAA,CAAgB,YACzC,YAAcqB,CAAAA,cAChB,CAAC,CAAA,CAEKC,EAAiBR,CAAAA,sBAAAA,CAAuB,CAC5C,KAAO,CAAA,iBAAA,CACP,KAAOd,CAAAA,WAAAA,CAAY,2BAA4B,CAAA,KAAA,CAC/C,YAAaA,WAAY,CAAA,2BAAA,CAA4B,WACrD,CAAA,OAAA,CAAS,MACT,CAAA,OAAA,CAAS,CAAC,MAAQ,CAAA,aAAA,CAAe,aAAa,CAChD,CAAC,CAAA,CAEKuB,GAAmC,CAACrB,CAAAA,CAAyBE,CAA0BoB,GAAAA,CAAAA,CAAAC,CAAA,CAAA,EAAA,CACxFP,EAAuBhB,CAAiBE,CAAAA,CAAY,CADoC,CAAA,CAAA,CAE3F,cAAgBkB,CAAAA,EAAAA,CAAe,IAC/B,cAAgBH,CAAAA,EAAAA,CAAe,GACjC,CAAA,CAAA,CAEMO,EAAsC,CAAA,CAACxB,EAAyBE,CACpEW,GAAAA,CAAAA,CAA0Bb,CAAiBE,CAAAA,CAAY,CAAE,CAAA,MAAA,CAAO,CAC9D,cAAgBkB,CAAAA,EAAAA,CAAe,MAC/B,CAAA,cAAA,CAAgBH,EAAe,CAAA,MACjC,CAAC,EDzBH,IAAMrB,EAAcC,CAAAA,eAAAA,CAAgB,CAClC,KAAA,CAAO,cACP,KAAOC,CAAAA,WAAAA,CAAY,WAAY,CAAA,KAAA,CAC/B,WAAaA,CAAAA,WAAAA,CAAY,YAAY,WACrC,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAK,CACL,CAAA,IAAA,CAAM,IACN,OAAS,CAAA,CACX,CAAC,CAEK2B,CAAAA,EAAAA,CAAkBb,uBAAuB,CAC7C,KAAA,CAAO,kBACP,CAAA,KAAA,CAAO,kBACP,CAAA,WAAA,CACE,kKACF,OAAS,CAAA,QAAA,CACT,OAAS,CAAA,CAAC,KAAO,CAAA,QAAA,CAAU,MAAM,CACnC,CAAC,CACKc,CAAAA,EAAAA,CAA4B,CAAC1B,CAAAA,CAAyBE,IAA0BoB,CAAAC,CAAAA,CAAAA,CAAA,EACjFF,CAAAA,EAAAA,CAAiCrB,CAAiBE,CAAAA,CAAY,GADmB,CAEpF,WAAA,CAAaN,EAAY,CAAA,GAAA,CACzB,eAAiB6B,CAAAA,EAAAA,CAAgB,GACnC,CAEME,CAAAA,CAAAA,EAAAA,CAA+B,CAAC3B,CAAAA,CAAyBE,CAC7DsB,GAAAA,EAAAA,CAAoCxB,EAAiBE,CAAY,CAAA,CAAE,MAAO,CAAA,CACxE,WAAaN,CAAAA,EAAAA,CAAY,OACzB,eAAiB6B,CAAAA,EAAAA,CAAgB,MACnC,CAAC,EE7BGL,IAAAA,EAAAA,CAAiBR,uBAAuB,CAC5C,KAAA,CAAO,iBACP,CAAA,KAAA,CAAOd,WAAY,CAAA,eAAA,CAAgB,MACnC,WAAaA,CAAAA,WAAAA,CAAY,eAAgB,CAAA,WAAA,CACzC,OAAS,CAAA,MAAA,CACT,QAAS,CAAC,MAAA,CAAQ,aAAa,CACjC,CAAC,CAAA,CAEK8B,GAAmC,CAAC5B,CAAAA,CAAyBE,CAA0BoB,GAAAA,CAAAA,CAAAC,CAAA,CAAA,EAAA,CACxFP,EAAuBhB,CAAiBE,CAAAA,CAAY,CADoC,CAAA,CAAA,CAE3F,cAAgBkB,CAAAA,EAAAA,CAAe,GACjC,CAEMS,CAAAA,CAAAA,EAAAA,CAAsC,CAAC7B,CAAAA,CAAyBE,CACpEW,GAAAA,CAAAA,CAA0Bb,EAAiBE,CAAY,CAAA,CAAE,MAAO,CAAA,CAC9D,cAAgBkB,CAAAA,EAAAA,CAAe,MACjC,CAAC,EClBH,IAAMU,GAAiBlB,sBAAuB,CAAA,CAC5C,KAAO,CAAA,iBAAA,CACP,KAAO,CAAA,iBAAA,CACP,YAAa,oDACb,CAAA,OAAA,CAAS,OACT,CAAA,OAAA,CAAS,CAAC,OAAA,CAAS,QAAQ,CAC7B,CAAC,CAEKmB,CAAAA,EAAAA,CAAcC,CAClBnC,EAAAA,eAAAA,CAAgB,CACd,KAAO,CAAA,YAAA,CACP,KAAO,CAAA,YAAA,CACP,WAAa,CAAA,yDAAA,CACb,IAAK,CACL,CAAA,GAAA,CAAKmC,CACL,CAAA,IAAA,CAAM,CACN,CAAA,OAAA,CAASA,CACX,CAAC,ECfGC,IAAAA,EAAAA,CAAiC,IACrCnB,GAAAA,CAAE,OAAO,CACP,cAAA,CAAgBgB,EAAe,CAAA,MACjC,CAAC,CAAA,CAEGI,GAA8B,KACjC,CACC,cAAgBJ,CAAAA,EAAAA,CAAe,GACjC,CAAA,MCTIK,EAAwCH,CAAAA,CAAAA,EAC5CC,EAA+B,EAAA,CAAE,MAAO,CAAA,CACtC,WAAYF,EAAWC,CAAAA,CAAa,CAAE,CAAA,MACxC,CAAC,CAAA,CAEGI,GAAqCJ,CACxCV,EAAAA,CAAAA,CAAAC,CAAA,CAAA,EAAA,CACIW,EAA4B,EAAA,CAAA,CADhC,CAEC,UAAYH,CAAAA,EAAAA,CAAWC,CAAa,CAAA,CAAE,GACxC,CAAA,MCKIK,CAAyB,CAAA,CAC7B,IAAM,CAAA,CAACrC,CAAyBE,CAAAA,CAAAA,IAA0B,CACxD,GAAKc,CAAAA,CAAAA,CAAuBhB,CAAiBE,CAAAA,CAAY,CACzD,CAAA,MAAA,CAAQW,EAA0Bb,CAAiBE,CAAAA,CAAY,CACjE,CAAA,CAAA,CACA,cAAgB,CAAA,CAACF,EAAyBE,CAA0B,IAAA,CAClE,GAAK0B,CAAAA,EAAAA,CAAiC5B,CAAiBE,CAAAA,CAAY,EACnE,MAAQ2B,CAAAA,EAAAA,CAAoC7B,CAAiBE,CAAAA,CAAY,CAC3E,CAAA,CAAA,CACA,eAAgB,CAACF,CAAAA,CAAyBE,CAA0B,IAAA,CAClE,GAAKmB,CAAAA,EAAAA,CAAiCrB,EAAiBE,CAAY,CAAA,CACnE,MAAQsB,CAAAA,EAAAA,CAAoCxB,CAAiBE,CAAAA,CAAY,CAC3E,CACA,CAAA,CAAA,OAAA,CAAS,CAACF,CAAAA,CAAyBE,CAA0B,IAAA,CAC3D,IAAKwB,EAA0B1B,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CAC5D,MAAQyB,CAAAA,EAAAA,CAA6B3B,EAAiBE,CAAY,CACpE,CACF,CAAA,CAAA,CAEMoC,CAA8B,CAAA,CAClC,KAAM,KAAO,CACX,GAAKJ,CAAAA,EAAAA,EACL,CAAA,MAAA,CAAQD,IACV,CAAA,CAAA,CACA,UAAaD,CAAAA,CAAAA,GAA2B,CACtC,GAAA,CAAKI,GAAkCJ,CAAa,CAAA,CACpD,MAAQG,CAAAA,EAAAA,CAAqCH,CAAa,CAC5D,EACF,EC7CA,IAAAO,CAAA,CAAA,CACE,qBAAsB,CACpB,SAAA,CAAa,oBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,oBAAsB,CAAA,CACpB,UAAa,oBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,UAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,eAAiB,CAAA,CACf,SAAa,CAAA,eAAA,CACb,SAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,UAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,GACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,CACF,CACF,EACA,oBAAsB,CAAA,CACpB,UAAa,oBACb,CAAA,QAAA,CAAY,MACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,KACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,EAAA,CACxB,sBAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,aAAc,CACZ,SAAA,CAAa,YACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,oBAAsB,CAAA,CACpB,UAAa,oBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,UAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,wBAA0B,CAAA,CACxB,SAAa,CAAA,wBAAA,CACb,SAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,UAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,GACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,EACA,qBAAuB,CAAA,CACrB,SAAa,CAAA,qBAAA,CACb,QAAY,CAAA,KAAA,CACZ,YAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,OAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,aAAA,CAAe,CACb,SAAa,CAAA,aAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,KAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,OAAA,CAAS,CACP,SAAA,CAAa,QACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,EACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,qBAAwB,EACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,mBAAA,CAAqB,CACnB,SAAA,CAAa,mBACb,CAAA,QAAA,CAAY,MACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,KACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,CAAA,CACxB,sBAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,oBAAqB,CACnB,SAAA,CAAa,mBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAQ,CAAA,CACN,qBAAwB,GACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,wBAAA,CAA0B,CACxB,SAAa,CAAA,wBAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,KAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,aAAA,CAAe,CACb,SAAA,CAAa,cACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,EACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,qBAAwB,EACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,QAAA,CAAU,CACR,SAAA,CAAa,QACb,CAAA,QAAA,CAAY,MACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,KACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,CAAA,CACxB,sBAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,gBAAiB,CACf,SAAA,CAAa,eACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,EAAM,CAAA,CACJ,UAAa,IACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,UAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,oBAAsB,CAAA,CACpB,SAAa,CAAA,oBAAA,CACb,SAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,UAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,IACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,CACF,CACF,EACA,SAAW,CAAA,CACT,SAAa,CAAA,SAAA,CACb,QAAY,CAAA,KAAA,CACZ,YAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,OAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,GACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,eAAA,CAAiB,CACf,SAAa,CAAA,eAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,KAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,EAAA,CAAM,CACJ,SAAA,CAAa,KACb,QAAY,CAAA,KAAA,CACZ,YAAe,CACb,CACE,UAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,oBAAsB,CAAA,CACpB,SAAa,CAAA,oBAAA,CACb,SAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,UAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,IACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,CACF,CACF,EACA,SAAW,CAAA,CACT,SAAa,CAAA,SAAA,CACb,QAAY,CAAA,KAAA,CACZ,YAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,OAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,GACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CACF,CAAA,CC3WA,IAAMC,EAAkB,CAAA,QAAA,CAClBC,EAAN,KAAoI,CAApI,WACE,EAAA,CAAA,IAAA,CAAS,OAAU,CAAA,IAAA,CACnB,KAAS,IAAOD,CAAAA,EAAAA,CAGhB,IAAiB,CAAA,kBAAA,CAOb,CACF,CAAQE,EAAoB,EAAG,CAC7B,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,YAAoBC,EACtB,CAAA,CACA,CAAQC,EAAyB,EAAG,CAClC,MAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAyB,EAAG,CAClC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,GACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,EACA,CAAQC,EAAiB,EAAG,CAC1B,KAAcC,CAAAA,EAAAA,CACd,aAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAyB,EAAG,CAClC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACA,CAAA,CAAQC,EAA6B,EAAG,CACtC,KAAA,CAAcC,GACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAA0B,EAAG,CACnC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,YAAoBC,EACtB,CAAA,CACA,CAAQC,EAAkB,EAAG,CAC3B,MAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAY,EAAG,CACrB,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,GACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAwB,EAAG,CACjC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,EACA,CAAQC,EAAkB,EAAG,CAC3B,KAAcC,CAAAA,EAAAA,CACd,aAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAa,EAAG,CACtB,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACA,CAAA,CAAQC,EAA6B,EAAG,CACtC,KAAA,CAAcC,GACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAwB,EAAG,CACjC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,YAAoBC,EACtB,CAAA,CACA,CAAQC,EAAS,EAAG,CAClB,MAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAoB,EAAG,CAC7B,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,GACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAuB,EAAG,CAChC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,EACA,CAAQC,EAAa,EAAG,CACtB,KAAcC,CAAAA,EAAAA,CACd,aAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAoB,EAAG,CAC7B,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACA,CAAA,CAAQC,EAAS,EAAG,CAClB,KAAA,CAAcC,GACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,YAAoBC,EACtB,CAAA,CACA,CAAQC,EAAc,EAAG,CACvB,MAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACF,EAEA,IAAiB,CAAA,uBAAA,CAOb,CACF,CAAQC,EAA4B,EAAG,CACrC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,EACA,CAAQC,EAA6B,EAAG,CACtC,KAAcC,CAAAA,EAAAA,CACd,aAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAA6B,EAAG,CACtC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACF,EAAA,CAEA,iBAA8B,EAAA,CAC5B,OAAO,MAAA,CAAO,KAAK,IAAK,CAAA,kBAAkB,CAC5C,CAEA,gBAAwD,EAAA,CACtD,OAAO,MAAO,CAAA,IAAA,CAAK,IAAK,CAAA,kBAAkB,CAAE,CAAA,MAAA,CAC1C,CAACC,CAAKC,CAAAA,CAAAA,IACJD,CAAIC,CAAAA,CAAG,CAAI,CAAA,IAAA,CAAK,mBAAmBA,CAAG,CAAA,CAAE,WACjCD,CAAAA,CAAAA,CAAAA,CAET,EACF,CACF,CAEA,SAAA,CAAUE,CAAyB,CAAA,CACjC,IAAMC,CAAAA,CAAYD,EAAQ,SAC1B,CAAA,GAAI,EAAEC,CAAAA,IAAa,IAAK,CAAA,kBAAA,CAAA,CACtB,MAAM,IAAIC,aAAAA,CAAc,CACtB,IAAA,CAAM,CAAsBD,mBAAAA,EAAAA,CAAS,aACrC,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,mBAAA,EAAsBA,CAAS,CAAA;AAAA,WAAA,EAC3C,KAAK,iBAAkB,EAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC7C,CAAC,EAGH,IAAME,CAAAA,CAAQ,KAAK,kBAAmBF,CAAAA,CAAS,EAAE,KAC3CG,CAAAA,CAAAA,CAAgB,KAAK,kBAAmBH,CAAAA,CAAS,EAAE,YAAa,CAAA,KAAA,CAAMD,CAAO,CACnF,CAAA,OAAO,IAAIG,CAAMC,CAAAA,CAAa,CAChC,CAEA,sBAAA,EAAmC,CACjC,OAAO,MAAA,CAAO,KAAK,IAAK,CAAA,uBAAuB,CACjD,CAEA,qBAAA,EAAkE,CAChE,OAAO,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,uBAAuB,CAAE,CAAA,MAAA,CAC/C,CAACN,CAAKC,CAAAA,CAAAA,IACJD,EAAIC,CAAG,CAAA,CAAI,KAAK,uBAAwBA,CAAAA,CAAG,EAAE,WACtCD,CAAAA,CAAAA,CAAAA,CAET,EACF,CACF,CAEA,cAAeE,CAAAA,CAAAA,CAA8B,CAC3C,IAAMC,CAAAA,CAAYD,EAAQ,SAC1B,CAAA,GAAI,EAAEC,CAAa,IAAA,IAAA,CAAK,yBACtB,MAAM,IAAIC,cAAc,CACtB,IAAA,CAAM,2BAA2BD,CAAS,CAAA,UAAA,CAAA,CAC1C,MAAO,IAAI,KAAA,CAAM,2BAA2BA,CAAS,CAAA;AAAA,WAChD,EAAA,IAAA,CAAK,sBAAuB,EAAA,CAAE,IAAK,CAAA,IAAI,CAAC,CAAG,CAAA,CAAA,CAClD,CAAC,CAAA,CAGH,IAAME,CAAAA,CAAQ,KAAK,uBAAwBF,CAAAA,CAAS,CAAE,CAAA,KAAA,CAChDG,CAAgB,CAAA,IAAA,CAAK,uBAAwBH,CAAAA,CAAS,CAAE,CAAA,YAAA,CAAa,KAAMD,CAAAA,CAAO,CACxF,CAAA,OAAO,IAAIG,CAAMC,CAAAA,CAAa,CAChC,CACF,EApNM/G,CAAAA,CAGY,OAAU,CAAA,2BAAA,CCN5B,IAAMgH,CAAuB3I,CAAAA,GAAAA,CAAE,IAAK,CAAA,CAAC4I,iBAAmBC,CAAAA,eAAAA,CAAiBC,qBAAsBC,eAAe,CAAC,CAEzGC,CAAAA,CAAAA,CAA0B,CAC9B,MAAA,CAAQJ,iBACR,CAAA,IAAA,CAAMC,eACN,CAAA,SAAA,CAAWC,oBACX,CAAA,IAAA,CAAMC,eACR,ECNA,IAAME,EAA+D,CACnEC,mBAAAA,CACAC,oBACAC,CAAAA,uBAAAA,CACAC,2BACF,CAAA,CAEMC,CAAgCtJ,CAAAA,GAAAA,CAAE,IAAK,CAAA,CAC3CkJ,mBACAC,CAAAA,oBAAAA,CACAC,uBACAC,CAAAA,2BACF,CAAC,CAEKE,CAAAA,EAAAA,CAAmE,CAACL,mBAAmB,CAEvFM,CAAAA,EAAAA,CAAoCxJ,GAAE,CAAA,IAAA,CAAK,CAACkJ,mBAAmB,CAAC,CAAA,CAEhEO,CAAuE,CAAA,CAC3EP,oBACAE,uBACAC,CAAAA,2BACF,CAEMK,CAAAA,CAAAA,CAAwC1J,GAAE,CAAA,IAAA,CAAK,CAACkJ,mBAAAA,CAAqBE,uBAAyBC,CAAAA,2BAA2B,CAAC,EC3BhI,IAAMM,EAAoB3J,CAAAA,GAAAA,CAAE,MAAO,CAAA,CACjC,KAAOA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAChB,OAASA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAClB,MAAOA,GAAE,CAAA,KAAA,CAAMA,GAAE,CAAA,MAAA,EAAQ,CAAA,CAAE,QAAS,EACtC,CAAC,CAAA,CAEK4J,EAAgB5J,CAAAA,GAAAA,CACnB,MAAO,CAAA,CACN,QAASA,GACN,CAAA,KAAA,CACC2J,EAAkB,CAAA,MAAA,CAAO,CACvB,YAAA,CAAc3J,GAAE,CAAA,KAAA,CAAM2J,EAAiB,CACzC,CAAC,CACH,CACC,CAAA,QAAA,GACA,QAAS,EAAA,CACZ,OAAS3J,CAAAA,GAAAA,CACN,KACC2J,CAAAA,EAAAA,CAAkB,MAAO,CAAA,CACvB,YAAc3J,CAAAA,GAAAA,CAAE,KAAM2J,CAAAA,EAAiB,CACzC,CAAC,CACH,CACC,CAAA,QAAA,EACA,CAAA,QAAA,EACL,CAAC,CACA,CAAA,QAAA,EAEGE,CAAAA,EAAAA,CAAsC7J,GAAE,CAAA,KAAA,CAC5CA,GAAE,CAAA,MAAA,CAAO,CACP,EAAIA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CACpB,CAAA,IAAA,CAAMA,GAAE,CAAA,IAAA,CAAK,CAAC,UAAU,CAAC,CAAA,CACzB,SAAUA,GAAE,CAAA,MAAA,CAAO,CACjB,IAAA,CAAMA,GAAE,CAAA,MAAA,EACR,CAAA,SAAA,CAAWA,GAAE,CAAA,MAAA,EACf,CAAC,CACH,CAAC,CACH,CAEM8J,CAAAA,EAAAA,CAA6B9J,GAAE,CAAA,MAAA,CAAO,CAC1C,EAAA,CAAIA,GAAE,CAAA,MAAA,EACN,CAAA,MAAA,CAAQA,GAAE,CAAA,OAAA,CAAQ,iBAAiB,CAAA,CACnC,QAASA,GAAE,CAAA,MAAA,EACX,CAAA,KAAA,CAAOA,GAAE,CAAA,MAAA,EACT,CAAA,kBAAA,CAAoBA,GAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAC/B,CAAA,OAAA,CAASA,IAAE,KACTA,CAAAA,GAAAA,CAAE,MAAO,CAAA,CACP,KAAOA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAChB,OAASA,CAAAA,GAAAA,CAAE,MAAO,CAAA,CAChB,IAAMA,CAAAA,GAAAA,CAAE,QACR,CAAA,OAAA,CAASA,GAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAAW,CAAA,QAAA,EAC/B,CAAA,UAAA,CAAY6J,EAAoC,CAAA,QAAA,EAChD,CAAA,OAAA,CAAS7J,IAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAC1C,CAAC,CAAA,CACD,QAAU4J,CAAAA,EAAAA,CAAc,QAAS,EAAA,CACjC,aAAe5J,CAAAA,GAAAA,CAAE,QACnB,CAAC,CACH,CAAA,CACA,KAAOA,CAAAA,GAAAA,CAAE,MAAO,CAAA,CACd,aAAeA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CACxB,iBAAmBA,CAAAA,GAAAA,CAAE,QACrB,CAAA,YAAA,CAAcA,GAAE,CAAA,MAAA,EAClB,CAAC,CACH,CAAC,CAGK+J,CAAAA,EAAAA,CAAoC/J,GAAE,CAAA,KAAA,CAC1CA,GAAE,CAAA,MAAA,CAAO,CACP,KAAOA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,EAAA,CACtB,EAAIA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,GACtB,IAAMA,CAAAA,GAAAA,CAAE,IAAK,CAAA,CAAC,UAAU,CAAC,CAAE,CAAA,QAAA,EAC3B,CAAA,QAAA,CAAUA,GACP,CAAA,MAAA,CAAO,CACN,IAAA,CAAMA,IAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EACxB,CAAA,SAAA,CAAWA,GAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EACxB,CAAC,EACA,QAAS,EACd,CAAC,CACH,CAEMgK,CAAAA,EAAAA,CAA2BhK,GAAE,CAAA,MAAA,CAAO,CACxC,EAAA,CAAIA,GAAE,CAAA,MAAA,EACN,CAAA,MAAA,CAAQA,IAAE,MAAO,EAAA,CACjB,OAASA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAClB,KAAOA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAChB,kBAAoBA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,UAAW,CAAA,QAAA,EAC1C,CAAA,OAAA,CAASA,GAAE,CAAA,KAAA,CACTA,GAAE,CAAA,MAAA,CAAO,CACP,KAAA,CAAOA,GAAE,CAAA,MAAA,EACT,CAAA,KAAA,CAAOA,IACJ,MAAO,CAAA,CACN,OAASA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CACxC,UAAY+J,CAAAA,EAAAA,CAAkC,QAAS,EAAA,CACvD,QAAS/J,GAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAAW,CAAA,QAAA,EACjC,CAAC,CACA,CAAA,EAAA,CAAGA,GAAE,CAAA,MAAA,CAAO,EAAE,CAAC,CAClB,CAAA,QAAA,CAAU4J,EAAc,CAAA,QAAA,EACxB,CAAA,aAAA,CAAe5J,GAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAC5B,CAAC,CACH,CAAA,CACA,MAAOA,GACJ,CAAA,MAAA,CAAO,CACN,aAAA,CAAeA,GAAE,CAAA,MAAA,GACjB,iBAAmBA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAC5B,YAAcA,CAAAA,GAAAA,CAAE,QAClB,CAAC,CACA,CAAA,QAAA,EACA,CAAA,QAAA,EACL,CAAC,EC3GD,IAAMiK,GAAwBjK,GAAE,CAAA,MAAA,CAAO,CACrC,IAAA,CAAMA,GAAE,CAAA,OAAA,CAAQ,UAAU,CAAA,CAC1B,QAAUA,CAAAA,GAAAA,CAAE,MAAO,CAAA,CACjB,IAAMA,CAAAA,GAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CACtB,WAAaA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EAC/B,CAAA,MAAA,CAAQA,IAAE,OAAQ,EAAA,CAAE,QAAS,EAAA,CAC7B,UAAYA,CAAAA,GAAAA,CAAE,GAAI,EACpB,CAAC,CACH,CAAC,CAAA,CAGKkK,EAAkClK,CAAAA,GAAAA,CAAE,KAAK,CAAC,MAAA,CAAQ,MAAQ,CAAA,UAAU,CAAC,CAAA,CAGrEmK,EAAsCnK,CAAAA,GAAAA,CAAE,MAAO,CAAA,CACnD,IAAMA,CAAAA,GAAAA,CAAE,OAAQ,CAAA,UAAU,EAC1B,QAAUA,CAAAA,GAAAA,CAAE,MAAO,CAAA,CACjB,IAAMA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CACxB,CAAC,CACH,CAAC,EAGKoK,EAAkCpK,CAAAA,GAAAA,CACrC,MAAO,CAAA,CACN,IAAMA,CAAAA,GAAAA,CAAE,IAAK,CAAA,CAAC,MAAQ,CAAA,aAAa,CAAC,CACtC,CAAC,CAAA,CACA,GACCA,GAAE,CAAA,MAAA,CAAO,CACP,IAAA,CAAMA,GAAE,CAAA,OAAA,CAAQ,aAAa,CAAA,CAC7B,WAAaA,CAAAA,GAAAA,CAAE,MAAO,CAAA,CACpB,IAAMA,CAAAA,GAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CACtB,WAAaA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EAC/B,CAAA,MAAA,CAAQA,IAAE,OAAQ,EAAA,CAAE,QAAS,EAAA,CAC7B,MAAQA,CAAAA,GAAAA,CAAE,GAAI,EAChB,CAAC,CACH,CAAC,CACH,CAGIqK,CAAAA,EAAAA,CAA+BrK,IAAE,MAAO,CAAA,CAC5C,IAAMA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CACtB,CAAA,IAAA,CAAMA,GAAE,CAAA,OAAA,CAAQ,MAAM,CACxB,CAAC,CAGKsK,CAAAA,EAAAA,CAAgCtK,GAAE,CAAA,MAAA,CAAO,CAC7C,IAAA,CAAMA,GAAE,CAAA,OAAA,CAAQ,WAAW,CAAA,CAC3B,SAAWA,CAAAA,GAAAA,CAAE,MAAO,CAAA,CAClB,IAAKA,GAAE,CAAA,MAAA,EAAS,CAAA,GAAA,EAAM,CAAA,GAAA,CAAI,CAAC,CAAA,CAC3B,MAAQA,CAAAA,GAAAA,CAAE,IAAK,CAAA,CAAC,KAAO,CAAA,MAAA,CAAQ,MAAM,CAAC,CAAA,CAAE,QAAS,EACnD,CAAC,CACH,CAAC,CAAA,CAGKuK,EAAmCvK,CAAAA,GAAAA,CAAE,MAAO,CAAA,CAChD,EAAIA,CAAAA,GAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CACpB,IAAMA,CAAAA,GAAAA,CAAE,OAAQ,CAAA,UAAU,CAC1B,CAAA,QAAA,CAAUA,GAAE,CAAA,MAAA,CAAO,CACjB,IAAA,CAAMA,IAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CACtB,CAAA,SAAA,CAAWA,GAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAC7B,CAAC,CACH,CAAC,CAGKwK,CAAAA,EAAAA,CAAiCxK,GAAE,CAAA,MAAA,CAAO,CAC9C,IAAA,CAAMA,GAAE,CAAA,OAAA,CAAQ,QAAQ,CAAA,CACxB,OAASA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,IAAI,CAAC,CAAA,CAAE,EAAGA,CAAAA,GAAAA,CAAE,KAAMqK,CAAAA,EAA4B,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAC5E,CAAC,CAGKI,CAAAA,EAAAA,CAA+BzK,IAAE,MAAO,CAAA,CAC5C,IAAMA,CAAAA,GAAAA,CAAE,OAAQ,CAAA,MAAM,CACtB,CAAA,OAAA,CAASA,GACN,CAAA,MAAA,EACA,CAAA,GAAA,CAAI,CAAC,CAAA,CACL,GAAGA,GAAE,CAAA,KAAA,CAAMA,GAAE,CAAA,KAAA,CAAM,CAACqK,EAAAA,CAA8BC,EAA6B,CAAC,CAAC,CAAA,CAAE,GAAI,CAAA,CAAC,CAAC,CAC9F,CAAC,CAGKI,CAAAA,EAAAA,CAAoC1K,GAAE,CAAA,MAAA,CAAO,CACjD,IAAA,CAAMA,GAAE,CAAA,OAAA,CAAQ,WAAW,CAAA,CAC3B,OAASA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,IAAI,CAAC,CAAA,CAAE,EAAGA,CAAAA,GAAAA,CAAE,KAAMqK,CAAAA,EAA4B,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAAE,CAAA,QAAA,EAC5E,CAAA,UAAA,CAAYrK,IAAE,KAAMuK,CAAAA,EAAgC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EACxE,CAAC,CAAA,CAGKI,EAA+B3K,CAAAA,GAAAA,CAAE,MAAO,CAAA,CAC5C,KAAMA,GAAE,CAAA,OAAA,CAAQ,MAAM,CAAA,CACtB,YAAcA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAC9B,CAAA,OAAA,CAASA,GAAE,CAAA,MAAA,GAAS,GAAI,CAAA,CAAC,CAC3B,CAAC,CAGK4K,CAAAA,EAAAA,CAA2B5K,GAAE,CAAA,KAAA,CAAM,CACvCwK,EAAAA,CACAC,EACAC,CAAAA,EAAAA,CACAC,EACF,CAAC,EAGKE,EAAoB7K,CAAAA,GAAAA,CAAE,MAAO,CAAA,CACjC,KAAOA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EACzB,CAAA,QAAA,CAAUA,IAAE,KAAM4K,CAAAA,EAAwB,CAAE,CAAA,GAAA,CAAI,CAAC,CAAA,CACjD,iBAAmB5K,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAA,CAAE,CAAE,CAAA,GAAA,CAAI,CAAC,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,EACxD,CAAA,QAAA,CAAUA,GAAE,CAAA,OAAA,EAAU,CAAA,QAAA,EAAW,CAAA,QAAA,EACjC,CAAA,YAAA,CAAcA,IAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,GAAA,CAAI,EAAE,CAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CAC5D,qBAAuBA,CAAAA,GAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CAC7D,gBAAkBA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAA,CAAE,EAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,EACvD,CAAA,eAAA,CAAiBoK,EAAgC,CAAA,QAAA,EACjD,CAAA,IAAA,CAAMpK,GAAE,CAAA,MAAA,GAAS,QAAS,EAAA,CAAE,QAAS,EAAA,CACrC,IAAMA,CAAAA,GAAAA,CAAE,QAAS,CAAA,EAAA,CAAGA,GAAE,CAAA,KAAA,CAAMA,GAAE,CAAA,MAAA,EAAQ,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,EAC3D,CAAA,WAAA,CAAaA,GAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CAC1D,KAAOA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,EAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,EAC3C,CAAA,KAAA,CAAOA,GAAE,CAAA,KAAA,CAAMiK,EAAqB,CAAA,CAAE,QAAS,EAAA,CAC/C,YAAaC,EAAgC,CAAA,EAAA,CAAGC,EAAmC,CAAA,CAAE,QAAS,EAChG,CAAC,ECtDKW,IAAAA,CAAAA,CAAuB9K,GAAE,CAAA,MAAA,CAAO,CACpC,SAAA,CAAWA,IAAE,MAAO,EAAA,CACpB,MAAQA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CACjB,OAASA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,EAAA,CAAE,QAAS,EAAA,CACnC,gBAAiBA,GAAE,CAAA,MAAA,EAAS,CAAA,GAAA,EAAM,CAAA,QAAA,EAClC,CAAA,aAAA,CAAeA,GAAE,CAAA,MAAA,EAAS,CAAA,GAAA,EAAM,CAAA,QAAA,GAChC,YAAcA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EACpC,CAAC,CAAA,CAGK+K,CAAN,CAAA,KAAgE,CAW9D,WAAA,CAAYC,CAAkC1C,CAAAA,CAAAA,CAAmC,CAVjF,IAAS,CAAA,OAAA,CAAU,IAWjB,CAAA,IAAMI,CAAgBoC,CAAAA,CAAAA,CAAqB,KAAMxC,CAAAA,CAAO,CACxD,CAAA,IAAA,CAAK,WAAc0C,CAAAA,CAAAA,CACnB,IAAK,CAAA,SAAA,CAAYtC,EAAc,SAC/B,CAAA,IAAA,CAAK,MAASA,CAAAA,CAAAA,CAAc,MAC5B,CAAA,IAAA,CAAK,OAAUuC,CAAAA,uBAAAA,CAAwBvC,CAAc,CAAA,OAAA,EAAW/G,CAAO,CAAA,OAAO,CAC9E,CAAA,IAAA,CAAK,cAAgBsJ,uBAAwBvC,CAAAA,CAAAA,CAAc,aAAiB,EAAA,CAAA,EAAG,IAAK,CAAA,OAAO,CAAmB,iBAAA,CAAA,CAAA,CAC9G,IAAK,CAAA,eAAA,CAAkBuC,uBAAwBvC,CAAAA,CAAAA,CAAc,eAAmB,EAAA,CAAA,EAAG,KAAK,OAAO,CAAA,iBAAA,CAAmB,CAClH,CAAA,IAAA,CAAK,YAAeA,CAAAA,CAAAA,CAAc,aACpC,CAEA,iBAA6B,EAAA,CAC3B,OAAO,IAAA,CAAK,OACd,CAEA,mBAAiC,CAC/B,OAAOjI,CAAA,CAAA,CACL,aAAe,CAAA,CAAA,OAAA,EAAU,IAAK,CAAA,MAAM,CACpC,CAAA,CAAA,cAAA,CAAgB,kBACZ,CAAA,CAAA,IAAA,CAAK,YAAe,CAAA,CAAE,sBAAuB,IAAK,CAAA,YAAa,CAAI,CAAA,EAE3E,CAAA,CAEA,gBAA+B,EAAA,CAC7B,OAAO,CACL,KAAO,CAAA,IAAA,CAAK,SACd,CACF,CAQA,aAAcyK,CAAAA,CAAAA,CAAyE,CAErF,IAAMC,CAAiBC,CAAAA,CAAAA,EAA6B,CAClD,IAAMC,CAAQ,CAAA,kBAAA,CACRC,CAAwC,CAAA,CAC5C,CAAG,CAAA,IAAA,CACH,EAAG,GACH,CAAA,CAAA,CAAG,GACH,CAAA,EAAA,CAAI,CACN,CAAA,CAEIC,CACAC,CAAAA,CAAAA,CAAU,CACd,CAAA,KAAA,CAAQD,CAAQF,CAAAA,CAAAA,CAAM,IAAKD,CAAAA,CAAQ,KAAO,IAAM,EAAA,CAC9C,IAAMnL,CAAAA,CAAQ,QAASsL,CAAAA,CAAAA,CAAM,CAAC,CAAC,CACzBE,CAAAA,CAAAA,CAAOF,CAAM,CAAA,CAAC,CACpBC,CAAAA,CAAAA,EAAWvL,EAAQqL,CAAUG,CAAAA,CAAI,EACnC,CAEA,OAAOD,CACT,CAEIE,CAAAA,CAAAA,CAAuB,CACvBC,CAAAA,CAAAA,CAAqB,CACnBC,CAAAA,CAAAA,CAAc,CAChBV,CAAAA,CAAAA,CAAAA,CAAgB,4BAA4B,CAC9CQ,GAAAA,CAAAA,CAAuBP,CAAcD,CAAAA,CAAAA,CAAgB,4BAA4B,CAAC,CAEhFA,CAAAA,CAAAA,CAAAA,CAAgB,0BAA0B,CAAA,GAC5CS,CAAqBR,CAAAA,CAAAA,CAAcD,CAAgB,CAAA,0BAA0B,CAAC,CAIhF,CAAA,CAAA,IAAMW,CAAU,CAAA,IAAA,CAAK,GAAIH,CAAAA,CAAAA,CAAsBC,CAAkB,CAAA,CACjE,OAAO,CAAE,WAAAC,CAAAA,CAAAA,CAAa,OAAAC,CAAAA,CAAQ,CAChC,CAEA,aAAA,CAAcC,CAAiC,CAAA,CAC7C,OAAOA,CAAAA,CAAS,MAAO,CAAA,CAAC1D,CAAK2D,CAAAA,CAAAA,GACpB3D,CAAM2D,CAAAA,CAAAA,CAAQ,OAAQ,CAAA,GAAA,CAAKC,GAAaA,CAAQ,CAAA,QAAA,GAAa,MAASA,CAAAA,CAAAA,CAAQ,KAAQ,CAAA,EAAG,CAAE,CAAA,IAAA,CAAK,GAAG,CAAA,CAAE,MAC3G,CAAA,CAAC,CACN,CAEA,sBAAsBC,CAKpB,CAAA,CACA,IAAMC,CAAAA,CAAcrB,EAAkB,CAAA,SAAA,CAAUoB,CAAO,CAAA,CACvD,GAAI,CAACC,CAAY,CAAA,OAAA,CACf,MAAM,IAAIC,yBAAyB,CAAE,IAAA,CAAM,uBAAyB,CAAA,KAAA,CAAOD,CAAY,CAAA,KAAM,CAAC,CAAA,CAGhG,IAAME,CAAAA,CAAgBF,CAAY,CAAA,IAAA,CAE5B3D,CAAY6D,CAAAA,CAAAA,CAAc,MAEhC,GAAIA,CAAAA,CAAc,WAAgB,GAAA,CAACA,CAAc,CAAA,KAAA,EAASA,CAAc,CAAA,KAAA,CAAM,MAAW,GAAA,CAAA,CAAA,CACvF,MAAM,IAAID,wBAAyB,CAAA,CACjC,KAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAA,CAC1D,KAAO,CAAA,IAAI,KAAM,CAAA,sDAAsD,CACzE,CAAC,CAGH,CAAA,IAAME,CAAsB,CAAA,GACxBD,CAAc,CAAA,eAAA,GAChBC,CAAQ,CAAA,cAAA,CAAiBD,CAAc,CAAA,eAAA,CAAgB,IACnDA,CAAAA,CAAAA,CAAc,eAAgB,CAAA,IAAA,GAAS,aACzCC,GAAAA,CAAAA,CAAQ,cAAiB,CAAA,CACvB,KAAMD,CAAc,CAAA,eAAA,CAAgB,WAAY,CAAA,IAAA,CAChD,WAAaA,CAAAA,CAAAA,CAAc,eAAgB,CAAA,WAAA,CAAY,WAAe,EAAA,EAAA,CACtE,MAAQA,CAAAA,CAAAA,CAAc,eAAgB,CAAA,WAAA,CAAY,OAClD,MAAQA,CAAAA,CAAAA,CAAc,eAAgB,CAAA,WAAA,CAAY,MACpD,CAAA,CAAA,CAAA,CAIAA,CAAc,CAAA,WAAA,GACZ,OAAOA,CAAAA,CAAc,WAAgB,EAAA,QAAA,CACvCC,CAAQ,CAAA,UAAA,CAAaD,EAAc,WAEnCC,CAAAA,CAAAA,CAAQ,UAAaD,CAAAA,CAAAA,CAAc,WAAY,CAAA,QAAA,CAAS,IAI5DC,CAAAA,CAAAA,CAAAA,CAAQ,IAAOD,CAAAA,CAAAA,CAAc,IAC7BC,CAAAA,CAAAA,CAAQ,SAAYD,CAAAA,CAAAA,CAAc,sBAClCC,CAAQ,CAAA,WAAA,CAAcD,CAAc,CAAA,WAAA,CACpCC,CAAQ,CAAA,IAAA,CAAOD,CAAc,CAAA,KAAA,CAC7BC,CAAQ,CAAA,eAAA,CAAkBD,CAAc,CAAA,gBAAA,CACxCC,CAAQ,CAAA,gBAAA,CAAmBD,EAAc,iBACzCC,CAAAA,CAAAA,CAAQ,IAAOD,CAAAA,CAAAA,CAAc,IAC7BC,CAAAA,CAAAA,CAAQ,QAAWD,CAAAA,CAAAA,CAAc,QACjCC,CAAAA,CAAAA,CAAQ,WAAcD,CAAAA,CAAAA,CAAc,YAEpC,CAAA,IAAME,EAASC,MAAO,EAAA,CAAE,KAAMC,CAAAA,sBAAAA,CAAuBH,CAAO,CAAC,EAEvDP,CAA0B,CAAA,EAC1BW,CAAAA,CAAAA,CAAqD,EAAC,CAC5DL,EAAc,QAAS,CAAA,OAAA,CAASL,CAAY,EAAA,CAC1C,IAAMW,CAAAA,CAAOX,CAAQ,CAAA,IAAA,CACrB,OAAQW,CAAAA,EACN,IAAK,QACH,CAAA,CACE,IAAMV,CAAUD,CAAAA,CAAAA,CAAQ,OACxB,CAAA,GAAI,OAAOC,CAAAA,EAAY,QACrBF,CAAAA,CAAAA,CAAS,IAAK,CAAA,CACZ,IAAMY,CAAAA,CAAAA,CACN,OAAS,CAAA,CAAC,CAAE,QAAUxD,CAAAA,mBAAAA,CAAqB,KAAO8C,CAAAA,CAAQ,CAAC,CAC7D,CAAC,CAAA,CAAA,KACI,CACL,IAAMW,CAAWX,CAAAA,CAAAA,CAAQ,GAAKY,CAAAA,CAAAA,GACrB,CAAE,QAAU1D,CAAAA,mBAAAA,CAAqB,KAAO0D,CAAAA,CAAAA,CAAE,IAAK,CAAA,CACvD,CACDd,CAAAA,CAAAA,CAAS,IAAK,CAAA,CAAE,IAAMY,CAAAA,CAAAA,CAAM,OAASC,CAAAA,CAAS,CAAC,EACjD,CACF,CACA,MAEF,IAAK,MAAA,CACH,CACE,IAAMX,CAAUD,CAAAA,CAAAA,CAAQ,OACxB,CAAA,GAAI,OAAOC,CAAAA,EAAY,SACrBF,CAAS,CAAA,IAAA,CAAK,CACZ,IAAA,CAAMY,CACN,CAAA,OAAA,CAAS,CAAC,CAAE,QAAUxD,CAAAA,mBAAAA,CAAqB,KAAO8C,CAAAA,CAAQ,CAAC,CAC7D,CAAC,CACI,CAAA,KAAA,CACL,IAAMW,CAAAA,CAAWX,CAAQ,CAAA,GAAA,CAAKY,CACxBA,EAAAA,CAAAA,CAAE,IAAS,GAAA,MAAA,CACN,CAAE,QAAA,CAAU1D,mBAAqB,CAAA,KAAA,CAAO0D,EAAE,IAAK,CAAA,CAElDA,CAAE,CAAA,SAAA,CAAU,GAAI,CAAA,UAAA,CAAW,OAAO,CAAA,CAC7B,CACL,QAAA,CAAUzD,oBACV,CAAA,MAAA,CAAQyD,CAAE,CAAA,SAAA,CAAU,QAAU,MAC9B,CAAA,KAAA,CAAO,CACL,IAAA,CAAMC,6BACN,CAAA,MAAA,CAAQD,CAAE,CAAA,SAAA,CAAU,GACpB,CAAA,SAAA,CAAWE,qBAAsBF,CAAAA,CAAAA,CAAE,SAAU,CAAA,GAAG,CAClD,CACF,CAAA,CAEO,CACL,QAAA,CAAUzD,oBACV,CAAA,MAAA,CAAQyD,CAAE,CAAA,SAAA,CAAU,MAAU,EAAA,MAAA,CAC9B,KAAO,CAAA,CAAE,IAAMG,CAAAA,0BAAAA,CAA4B,IAAKH,CAAE,CAAA,SAAA,CAAU,GAAI,CAClE,CAGL,CAAA,CACDd,CAAS,CAAA,IAAA,CAAK,CAAE,IAAA,CAAMY,CAAM,CAAA,OAAA,CAASC,CAAS,CAAC,EACjD,CACF,CACA,MAEF,IAAK,WACH,CAAA,CACE,IAAMK,CAAAA,CAAkC,EAAC,CAEzC,GAAI,CAACjB,CAAQ,CAAA,OAAA,EAAW,CAACA,CAAQ,CAAA,UAAA,CAC/B,MAAM,IAAII,wBAAyB,CAAA,CACjC,IAAM,CAAA,CAAA,mCAAA,EAAsC,IAAK,CAAA,SAAS,CAC1D,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,kDAAkD,CACrE,CAAC,CAGH,CAAA,GAAIJ,CAAQ,CAAA,OAAA,CAAS,CACnB,IAAMC,CAAUD,CAAAA,CAAAA,CAAQ,OACpB,CAAA,OAAOC,CAAY,EAAA,QAAA,CACrBgB,EAAiB,IAAK,CAAA,CAAE,QAAU9D,CAAAA,mBAAAA,CAAqB,KAAO8C,CAAAA,CAAQ,CAAC,CAAA,CAEvEA,CAAQ,CAAA,OAAA,CAASY,CAAM,EAAA,CACrBI,CAAiB,CAAA,IAAA,CAAK,CAAE,QAAU9D,CAAAA,mBAAAA,CAAqB,KAAO0D,CAAAA,CAAAA,CAAE,IAAK,CAAC,EACxE,CAAC,EAEL,CAEIb,CAAQ,CAAA,UAAA,EACQA,CAAQ,CAAA,UAAA,CAChB,QAAQ,CAACkB,CAAAA,CAAUC,CAAU,GAAA,CACrC,IAAMC,CAAAA,CAAuC,CAC3C,QAAA,CAAU/D,uBACV,CAAA,EAAA,CAAI6D,CAAS,CAAA,EAAA,CACb,KAAOC,CAAAA,CAAAA,CACP,KAAMD,CAAS,CAAA,QAAA,CAAS,IACxB,CAAA,SAAA,CAAWA,CAAS,CAAA,QAAA,CAAS,SAC/B,CAAA,CACAD,CAAiB,CAAA,IAAA,CAAKG,CAAe,CAAA,CACrCV,CAAYU,CAAAA,CAAAA,CAAgB,EAAE,CAAIA,CAAAA,EACpC,CAAC,CAAA,CAEHrB,CAAS,CAAA,IAAA,CAAK,CAAE,IAAA,CAAMY,CAAM,CAAA,OAAA,CAASM,CAAiB,CAAC,EACzD,CACA,MAEF,IAAK,MAAA,CACH,CACE,IAAMI,CAAerB,CAAAA,CAAAA,CACrBD,CAAS,CAAA,IAAA,CAAK,CACZ,IAAA,CAAMY,CACN,CAAA,OAAA,CAAS,CACP,CACE,SAAUrD,2BACV,CAAA,EAAA,CAAI+D,CAAa,CAAA,YAAA,CACjB,KAAOX,CAAAA,CAAAA,CAAYW,CAAa,CAAA,YAAY,CAAE,CAAA,KAAA,CAC9C,IAAMX,CAAAA,CAAAA,CAAYW,CAAa,CAAA,YAAY,EAAE,IAC7C,CAAA,IAAA,CAAMA,CAAa,CAAA,OACrB,CACF,CACF,CAAC,EACH,CACA,KACJ,CACF,CAAC,CAED,CAAA,IAAMC,EAAoB,EAAC,CAC3B,OAAIjB,CAAAA,CAAc,KAChBA,EAAAA,CAAAA,CAAc,KAAM,CAAA,OAAA,CAASkB,CAAoC,EAAA,CAC/DD,CAAM,CAAA,IAAA,CAAK,CACT,IAAA,CAAM,WACN,UAAY,CAAA,CACV,MAAQ,CAAA,CACN,IAAMC,CAAAA,CAAAA,CAAK,QAAS,CAAA,IAAA,CACpB,WAAaA,CAAAA,CAAAA,CAAK,QAAS,CAAA,WAAA,EAAe,EAC1C,CAAA,MAAA,CAAQA,EAAK,QAAS,CAAA,MAAA,CACtB,UAAYA,CAAAA,CAAAA,CAAK,QAAS,CAAA,UAC5B,CACF,CACF,CAAC,EACH,CAAC,CAAA,CAGI,CACL,SAAA,CAAA/E,EACA,MAAA+D,CAAAA,CAAAA,CACA,QAAAR,CAAAA,CAAAA,CACA,KAAOuB,CAAAA,CAAAA,CAAM,MAAS,CAAA,CAAA,CAAIA,CAAQ,CAAA,KAAA,CACpC,CACF,CAGA,eAAgBf,CAAAA,CAAAA,CAAoBR,EAA0BuB,CAAgC,CAAA,CAC5F,IAAME,CAAAA,CAAcjB,CAAO,CAAA,UAAA,CAC3B,OAAOA,CAAAA,CAAO,UAEd,CAAA,IAAMkB,CAAgB,CAAA,IAAA,CAAK,WAAY,CAAA,MAAA,CAAO,OAAO,SAAUlB,CAAAA,CAAM,CACrE,CAAA,GAAI,CAACkB,CAAAA,CAAc,OACjB,CAAA,MAAM,IAAIC,kBAAAA,CAAmB,CAC3B,IAAA,CAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,SAAS,CACnD,CAAA,CAAA,CAAA,KAAA,CAAOD,CAAc,CAAA,KACvB,CAAC,CAAA,CAGH,IAAME,CAAAA,CAAeF,CAAc,CAAA,IAAA,CAC/BD,CAAgB,GAAA,KAAA,CAAA,GAClBG,CAAa,CAAA,UAAA,CAAaH,GAG5B,MAAO,CAAA,IAAA,CAAKG,CAAY,CAAA,CAAE,OAASrF,CAAAA,CAAAA,EAAQ,CACzC,GAAI,EAAEA,CAAAA,IAAO,IAAK,CAAA,WAAA,CAAY,MAAO,CAAA,GAAA,CAAA,CACnC,MAAM,IAAIoF,kBAAAA,CAAmB,CAC3B,IAAA,CAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAA,CACnD,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,sBAAA,EAAyBpF,CAAG,CAAA;AAAA,8BAAA,EACvB,OAAO,IAAK,CAAA,IAAA,CAAK,YAAY,MAAO,CAAA,GAAG,EAAE,IAAK,CAAA,IAAI,CAAC,CAAA,CAAA,CAAG,CAC9E,CAAC,CAEL,CAAC,CAED,CAAA,IAAMsF,EAAoB,MAAO,CAAA,IAAA,CAAKD,CAAY,CAAA,CAAE,OAAO,CAACtF,CAAAA,CAAKC,IAAQ,CACvE,IAAMuF,EAAM,IAAK,CAAA,WAAA,CAAY,OAAO,GAAIvF,CAAAA,CAAG,EACrCwF,CAAWD,CAAAA,CAAAA,CAAI,MACfE,CAAcJ,CAAAA,CAAAA,CAA4BrF,CAAG,CAEnD,CAAA,OAAIwF,CAAa,GAAA,uBAAA,EAA2BD,EAAI,IAAS,GAAA,OAAA,EAAWE,IAAe,CACjF1F,CAAAA,CAAAA,CAAIyF,CAAQ,CAAID,CAAAA,CAAAA,CAAI,GAEpBxF,CAAAA,CAAAA,CAAIyF,CAAQ,CAAIC,CAAAA,CAAAA,CAGX1F,CACT,CAAG,CAAA,EAAgB,CAEnB,CAAA,GAAIuF,CAAkB,CAAA,YAAA,EAAgB,CAACA,CAAkB,CAAA,QAAA,CACvD,MAAM,IAAIF,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,KAAK,SAAS,CAAA,CAAA,CAAA,CACnD,MAAO,IAAI,KAAA,CAAM,4DAA4D,CAC/E,CAAC,EAGH,GAAI,aAAA,GAAiBE,CAAqBA,EAAAA,CAAAA,CAAkB,cAAgB,KAAW,CAAA,CAAA,CACrF,IAAM9N,CAAa8N,CAAAA,CAAAA,CAAkB,YACrC,GAAI,CAACN,CAAUA,EAAAA,CAAAA,EAASA,EAAM,MAAW,GAAA,CAAA,CACvC,MAAM,IAAII,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,IAAK,CAAA,SAAS,IACnD,KAAO,CAAA,IAAI,MAAM,qDAAqD,CACxE,CAAC,CACI,CAAA,GAAIJ,GAASA,CAAM,CAAA,MAAA,CAAS,EAAG,CACpC,IAAMU,EAAmB,IAAK,CAAA,WAAA,CAAY,OAAO,GAAI,CAAA,UAAA,CACrD,GAAI,CAACA,EAAiB,OAAQ,CAAA,QAAA,CAASlO,CAAU,CAC/C,CAAA,GAAIwN,EAAM,GAAKC,CAAAA,CAAAA,EAASA,CAAK,CAAA,UAAA,CAAW,OAAO,IAAI,CAAA,CAAE,SAASzN,CAAU,CAAA,CACtE8N,EAAkB,WAAc,CAAA,CAAE,IAAM,CAAA,UAAA,CAAY,SAAU,CAAE,IAAA,CAAM9N,CAAW,CAAE,CAAA,CAAA,WAE7E,IAAI4N,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,KAAK,SAAS,CAAA,CAAA,CAAA,CACnD,MAAO,IAAI,KAAA,CAAM,iBAAiB5N,CAAU,CAAA;AAAA,wBAAA,EAChCkO,CAAiB,CAAA,OAAA,CAAQ,IAAK,CAAA,IAAI,CAAC,CAAG,CAAA,CAAA,CACpD,CAAC,CAGP,CACF,CAEA,GAAI,iBAAqBJ,GAAAA,CAAAA,EAAqBA,EAAkB,eAAoB,GAAA,KAAA,CAAA,CAAW,CAC7F,IAAMrN,CAAiBqN,CAAAA,CAAAA,CAAkB,eACzC,CAAA,GAAIrN,IAAmB,aACrB,CAAA,GAAM,iBAAqBqN,GAAAA,CAAAA,CAMzBA,EAAkB,eAAkB,CAAA,CAClC,IAAM,CAAA,aAAA,CACN,YAAaA,CAAkB,CAAA,eACjC,CACA,CAAA,OAAOA,CAAkB,CAAA,eAAA,CAAA,KATnB,MAAA,IAAIF,mBAAmB,CAC3B,IAAA,CAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,SAAS,CACnD,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,+EAA+E,CAClG,CAAC,CASHE,CAAAA,KAAAA,CAAAA,CAAkB,gBAAkB,CAAE,IAAA,CAAMrN,CAAe,EAE/D,CAEA,OAAOqN,CACT,CAEA,iBAAA,CAAkB7B,EAAqC,CACrD,GAAI,CAACA,CAAAA,EAAaA,GAAYA,CAAS,CAAA,MAAA,GAAW,CAChD,CAAA,OAAO,CAAE,QAAA,CAAU,EAAG,EAGxB,IAAMkC,CAAAA,CAAiBlC,CAAS,CAAA,GAAA,CAAKC,GAAY,CAC/C,IAAMkC,CAAgBC,CAAAA,OAAAA,GAAU,SAAUnC,CAAAA,CAAO,CACjD,CAAA,GAAI,CAACkC,CAAc,CAAA,OAAA,CACjB,MAAM,IAAIE,qBAAqB,CAAE,IAAA,CAAM,kBAAoB,CAAA,KAAA,CAAOF,EAAc,KAAM,CAAC,CAEzF,CAAA,OAAOA,EAAc,IACvB,CAAC,CAED,CAAA,OAAAD,CAAe,CAAA,OAAA,CAASjC,CAAY,EAAA,CAClCA,EAAQ,OAAQ,CAAA,OAAA,CAASC,CAAY,EAAA,CACnC,GAAI,CAAC,IAAA,CAAK,WAAY,CAAA,UAAA,CAAW,SAASA,CAAQ,CAAA,QAAQ,CACxD,CAAA,MAAM,IAAImC,oBAAqB,CAAA,CAC7B,IAAM,CAAA,CAAA,qCAAA,EAAwC,KAAK,SAAS,CAAA,CAAA,CAAA,CAC5D,KAAO,CAAA,IAAI,MAAM,CAAY,SAAA,EAAA,IAAA,CAAK,SAAS,CAAA,+BAAA,EAAkCnC,EAAQ,QAAQ,CAAA;AAAA,sCACjE,EAAA,IAAA,CAAK,YAAY,UAAW,CAAA,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CACvE,CAAC,CAEL,CAAC,EACH,CAAC,EAEDgC,CAAe,CAAA,OAAA,CAASjC,GAAY,CAClC,GAAI,CAAC,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,YAAY,KAAK,CAAA,CAAE,SAASA,CAAQ,CAAA,IAAI,EAC5D,MAAM,IAAIoC,oBAAqB,CAAA,CAC7B,IAAM,CAAA,CAAA,qCAAA,EAAwC,KAAK,SAAS,CAAA,CAAA,CAAA,CAC5D,MAAO,IAAI,KAAA,CAAM,YAAY,IAAK,CAAA,SAAS,CAA8BpC,2BAAAA,EAAAA,CAAAA,CAAQ,IAAI,CAAA;AAAA,+BAAA,EAC9D,OAAO,IAAK,CAAA,IAAA,CAAK,YAAY,KAAK,CAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC1E,CAAC,CAEL,CAAC,CAAA,CAiHM,CAAE,QA/GmBiC,CAAAA,CAAAA,CAAe,IAAKjC,CAAY,EAAA,CAC1D,OAAQA,CAAQ,CAAA,IAAA,EACd,KAAKnD,iBAAAA,CAAmB,CACtB,IAAMwF,CAAAA,CAAgD,EACtD,CAAA,OAAArC,EAAQ,OAAQ,CAAA,OAAA,CAASC,GAAY,CACnC,GAAIA,EAAQ,QAAa9C,GAAAA,mBAAAA,CACvBkF,EAAY,IAAK,CAAA,CAAE,KAAM,MAAQ,CAAA,IAAA,CAAMpC,EAAQ,KAAM,CAAC,OAEhD,MAAA,IAAImC,qBAAqB,CAC7B,IAAA,CAAM,iEAAiE,IAAK,CAAA,SAAS,GACrF,KAAO,CAAA,IAAI,MAAM,CAAWpC,QAAAA,EAAAA,CAAAA,CAAQ,IAAI,CAA0CC,uCAAAA,EAAAA,CAAAA,CAAQ,QAAQ,CAAG,CAAA,CAAA,CACvG,CAAC,CAEL,CAAC,EAEM,CACL,IAAA,CAAM,KAAK,WAAY,CAAA,KAAA,CAAMD,EAAQ,IAAI,CAAA,CACzC,QAASqC,CACX,CACF,CAEA,KAAKtF,oBAAAA,CAAsB,CACzB,IAAMsF,CAAAA,CAAgD,EAChDC,CAAAA,CAAAA,CAA+F,EACrG,CAAA,OAAAtC,EAAQ,OAAQ,CAAA,OAAA,CAASC,GAAY,CACnC,GAAIA,EAAQ,QAAa9C,GAAAA,mBAAAA,CACvBkF,EAAY,IAAK,CAAA,CAAE,KAAM,MAAQ,CAAA,IAAA,CAAMpC,EAAQ,KAAM,CAAC,UAC7CA,CAAQ,CAAA,QAAA,GAAa5C,wBAC9BiF,CAAU,CAAA,IAAA,CAAK,CACb,EAAIrC,CAAAA,CAAAA,CAAQ,GACZ,IAAM,CAAA,UAAA,CACN,SAAU,CAAE,IAAA,CAAMA,EAAQ,IAAM,CAAA,SAAA,CAAWA,EAAQ,SAAU,CAC/D,CAAC,CAED,CAAA,KAAA,MAAM,IAAImC,oBAAqB,CAAA,CAC7B,KAAM,CAAiE,8DAAA,EAAA,IAAA,CAAK,SAAS,CACrF,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWpC,EAAQ,IAAI,CAAA,uCAAA,EAA0CC,EAAQ,QAAQ,CAAA,CAAA,CAAG,CACvG,CAAC,CAEL,CAAC,CAEMvL,CAAAA,CAAAA,CAAA,CACL,IAAM,CAAA,IAAA,CAAK,YAAY,KAAMsL,CAAAA,CAAAA,CAAQ,IAAI,CACzC,CAAA,OAAA,CAASqC,GACLC,CAAU,CAAA,MAAA,CAAS,EAAI,CAAE,UAAA,CAAYA,CAAU,CAAI,CAAA,GAE3D,CAEA,KAAKxF,gBAAiB,CACpB,IAAMuF,EAAgD,EAAC,CACjDE,EAAoF,EAAC,CAC3FvC,EAAQ,OAAQ,CAAA,OAAA,CAASC,GAAY,CACnC,GAAIA,EAAQ,QAAa9C,GAAAA,mBAAAA,CACvBkF,EAAY,IAAK,CAAA,CAAE,KAAM,MAAQ,CAAA,IAAA,CAAMpC,EAAQ,KAAM,CAAC,UAC7CA,CAAQ,CAAA,QAAA,GAAa7C,qBAC9BmF,CAAa,CAAA,IAAA,CAAK,CAChB,IAAM,CAAA,WAAA,CACN,UAAW,CACT,GAAA,CAAKtC,EAAQ,KAAM,CAAA,IAAA,GAAS,MAAQA,CAAQ,CAAA,KAAA,CAAM,IAAMA,CAAQ,CAAA,KAAA,CAAM,OACtE,MAAQA,CAAAA,CAAAA,CAAQ,MAClB,CACF,CAAC,OAEK,MAAA,IAAImC,qBAAqB,CAC7B,IAAA,CAAM,iEAAiE,IAAK,CAAA,SAAS,GACrF,KAAO,CAAA,IAAI,MAAM,CAAWpC,QAAAA,EAAAA,CAAAA,CAAQ,IAAI,CAA0CC,uCAAAA,EAAAA,CAAAA,CAAQ,QAAQ,CAAG,CAAA,CAAA,CACvG,CAAC,CAEL,CAAC,EAED,IAAMuC,CAAAA,CAAkB,CAAC,GAAGH,CAAAA,CAAa,GAAGE,CAAY,CAAA,CAExD,OAAO,CACL,IAAA,CAAM,KAAK,WAAY,CAAA,KAAA,CAAMvC,EAAQ,IAAI,CAAA,CACzC,QAASwC,CACX,CACF,CAEA,KAAKxF,eAAAA,CAAiB,CACpB,GAAIgD,CAAAA,CAAQ,QAAQ,MAAW,GAAA,CAAA,CAC7B,MAAM,IAAIoC,oBAAAA,CAAqB,CAC7B,IAAM,CAAA,CAAA,4BAAA,EAA+BpC,EAAQ,IAAI,CAAA,CAAA,CAAA,CACjD,MAAO,IAAI,KAAA,CAAM,WAAWA,CAAQ,CAAA,IAAI,sCAAsC,CAChF,CAAC,EAGH,GAAIA,CAAAA,CAAQ,QAAQ,CAAC,CAAA,CAAE,WAAa1C,2BAClC,CAAA,MAAM,IAAI8E,oBAAqB,CAAA,CAC7B,KAAM,CAAiE,8DAAA,EAAA,IAAA,CAAK,SAAS,CACrF,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWpC,EAAQ,IAAI,CAAA,qCAAA,EAAwC1C,2BAA2B,CAAG,CAAA,CAAA,CAChH,CAAC,CAGH,CAAA,IAAM+D,EAAerB,CAAQ,CAAA,OAAA,CAAQ,CAAC,CACtC,CAAA,OAAO,CACL,IAAM,CAAA,IAAA,CAAK,YAAY,KAAMA,CAAAA,CAAAA,CAAQ,IAAI,CACzC,CAAA,YAAA,CAAcqB,EAAa,EAC3B,CAAA,OAAA,CAASA,EAAa,IACxB,CACF,CAEA,QACE,MAAM,IAAIe,oBAAqB,CAAA,CAC7B,KAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAC1D,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWpC,EAAQ,IAAI,CAAA;AAAA,iCAAA,EACjB,MAAO,CAAA,IAAA,CAAK,IAAK,CAAA,WAAA,CAAY,KAAK,CAAE,CAAA,IAAA,CAAK,IAAI,CAAC,CAAG,CAAA,CAAA,CAC1E,CAAC,CAEL,CACF,CAAC,CAEsC,CACzC,CAEA,cAAesB,CAAAA,CAAAA,CAA+B,CAC5C,GAAI,CAAC,IAAK,CAAA,WAAA,CAAY,UAAW,CAAA,QAAA,CAASjE,uBAAuB,CAC/D,CAAA,MAAM,IAAIoF,iBAAAA,CAAkB,CAC1B,IAAM,CAAA,CAAA,oCAAA,EAAuC,IAAK,CAAA,SAAS,CAC3D,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,YAAY,IAAK,CAAA,SAAS,CAAuCpF,oCAAAA,EAAAA,uBAAuB,CAAG,CAAA,CAAA,CAC9G,CAAC,CAAA,CAGH,OAAI,CAACiE,CAAAA,EAAUA,CAASA,EAAAA,CAAAA,CAAM,MAAW,GAAA,CAAA,CAChC,CAAE,KAAA,CAAO,EAAiB,CAAA,CAgB5B,CAAE,KAAA,CAbWA,EAAM,GAAKC,CAAAA,CAAAA,EAAS,CACtC,IAAMmB,EAAaC,IAAK,EAAA,CAAE,SAAUpB,CAAAA,CAAI,CACxC,CAAA,GAAI,CAACmB,CAAAA,CAAW,QACd,MAAM,IAAID,iBAAkB,CAAA,CAAE,IAAM,CAAA,eAAA,CAAiB,KAAOC,CAAAA,CAAAA,CAAW,KAAM,CAAC,CAAA,CAEhF,OAAOA,CAAAA,CAAW,IACpB,CAAC,CAEoC,CAAA,GAAA,CAAKnB,IAAU,CAClD,IAAA,CAAM,UACN,CAAA,QAAA,CAAUA,EAAK,UAAW,CAAA,MAC5B,CAAE,CAAA,CAE+B,CACnC,CAGM,kBAAA,CAAmBhB,CAAqBR,CAAAA,CAAAA,CAA0BuB,CAAsC,CAAA,CAAA,OAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC5G,OAAO,IAAI,OAAA,CAASC,CAAY,EAAA,CAC9BA,CAAQ,CAAA,IAAA,CAAK,eAAe,EAC9B,CAAC,CACH,CAAA,CAAA,CAGM,sBAAuBtC,CAAAA,CAAAA,CAAqBR,CAA0BuB,CAAAA,CAAAA,CAA0C,CAAAsB,OAAAA,CAAAA,CAAA,sBACpH,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAQ,CAAA,IAAA,CAAK,iBAAkB,EAAC,EAClC,CAAC,CACH,CAEM,CAAA,CAAA,mBAAA,CAAoBtC,CAAoBR,CAAAA,CAAAA,CAAyBuB,CAAyC,CAAA,CAAA,OAAAsB,EAAA,IAC9G,CAAA,IAAA,CAAA,WAAA,CAAA,IAAMhB,CAAoB,CAAA,IAAA,CAAK,eAAgBrB,CAAAA,CAAAA,CAAQR,CAAUuB,CAAAA,CAAK,EAChEwB,CAAsB,CAAA,IAAA,CAAK,iBAAkB/C,CAAAA,CAAQ,CAC3D,CAAA,GAAI+C,CAAoB,CAAA,QAAA,EAAaA,EAAoB,QAA2B,CAAA,MAAA,GAAW,CAC7F,CAAA,MAAM,IAAIV,oBAAqB,CAAA,CAC7B,IAAM,CAAA,uBAAA,CACN,MAAO,IAAI,KAAA,CAAM,uBAAuB,CAC1C,CAAC,CAAA,CAGH,IAAMW,CAAAA,CAAmBzB,EAAQ,IAAK,CAAA,cAAA,CAAeA,CAAK,CAAA,CAAI,EAAC,CAE/D,OAAO,IAAI,QAASuB,CAAY,EAAA,CAC9BA,CAAQnO,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAA,EACH,CAAA,IAAA,CAAK,gBAAiB,EAAA,CAAA,CACtBkN,GACAkB,CACAC,CAAAA,CAAAA,CAAAA,CACJ,EACH,CAAC,CACH,CAEA,CAAA,CAAA,6BAAA,CAA8BC,CAAiC,CAAA,CAC7D,IAAMC,CAAOlF,CAAAA,EAAAA,CAA2B,SAAUiF,CAAAA,CAAQ,CAC1D,CAAA,GAAIC,CAAK,CAAA,OAAA,CAAS,CAChB,GAAIA,CAAAA,CAAK,IAAK,CAAA,OAAA,CAAQ,MAAW,GAAA,CAAA,CAC/B,MAAM,IAAIC,mBAAmB,CAC3B,IAAA,CAAM,6BACN,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,CAA4B,yBAAA,EAAA,IAAA,CAAK,UAAUD,CAAK,CAAA,IAAI,CAAC,CAAA,CAAE,CAC1E,CAAC,CAAA,CAGH,IAAME,CAAAA,CAAiDF,EAAK,IACtDlD,CAAAA,CAAAA,CAA0B,CAC9B,CACE,IAAMhD,CAAAA,oBAAAA,CACN,OAAS,CAAA,EACX,CACF,CAAA,CACMiD,CAAUmD,CAAAA,CAAAA,CAAe,QAAQ,CAAC,CAAA,CAAE,OACtCnD,CAAAA,CAAAA,CAAQ,SACVD,CAAS,CAAA,CAAC,CAAE,CAAA,OAAA,CAAQ,IAAKqD,CAAAA,iBAAAA,CAAkBpD,CAAQ,CAAA,OAAO,CAAC,CAGzDA,CAAAA,CAAAA,CAAQ,OACVD,EAAAA,CAAAA,CAAS,CAAC,CAAE,CAAA,OAAA,CAAQ,IAAKqD,CAAAA,iBAAAA,CAAkBpD,EAAQ,OAAO,CAAC,CAGzDA,CAAAA,CAAAA,CAAQ,UACVA,EAAAA,CAAAA,CAAQ,UAAW,CAAA,OAAA,CAAQ,CAACkB,CAAUC,CAAAA,CAAAA,GAAU,CAC9CpB,CAAAA,CAAS,CAAC,CAAA,CAAE,OAAQ,CAAA,IAAA,CAAKsD,sBAAsBlC,CAAOD,CAAAA,CAAAA,CAAS,EAAIA,CAAAA,CAAAA,CAAS,QAAS,CAAA,IAAA,CAAMA,CAAS,CAAA,QAAA,CAAS,SAAS,CAAC,EACzH,CAAC,CAAA,CAGH,IAAMoC,CAAuB,CAAA,CAC3B,YAAcH,CAAAA,CAAAA,CAAe,MAAM,aACnC,CAAA,gBAAA,CAAkBA,CAAe,CAAA,KAAA,CAAM,iBACvC,CAAA,WAAA,CAAaA,CAAe,CAAA,KAAA,CAAM,YACpC,CAEMxP,CAAAA,CAAAA,CAA6B,EAAC,CAC9B4P,CAAYJ,CAAAA,CAAAA,CAAe,OAAQ,CAAA,CAAC,EAAE,QAC5C,CAAA,OAAII,CACEA,GAAAA,CAAAA,CAAU,OACZ5P,EAAAA,CAAAA,CAAS,IACP,CAAA,GAAG4P,EAAU,OAAQ,CAAA,GAAA,CAAKC,CAAa,GAAA,CACrC,MAAOA,CAAQ,CAAA,KAAA,CACf,OAASA,CAAAA,CAAAA,CAAQ,QACjB,KAAOA,CAAAA,CAAAA,CAAQ,KACf,CAAA,WAAA,CAAaA,CAAQ,CAAA,YAAA,CAAa,GAAKC,CAAAA,CAAAA,GAAgB,CACrD,KAAOA,CAAAA,CAAAA,CAAW,KAClB,CAAA,OAAA,CAASA,CAAW,CAAA,OAAA,CACpB,KAAOA,CAAAA,CAAAA,CAAW,KACpB,CAAE,CAAA,CACJ,CAAE,CAAA,CACJ,CAEEF,CAAAA,CAAAA,CAAU,OACZ5P,EAAAA,CAAAA,CAAS,KACP,GAAG4P,CAAAA,CAAU,OAAQ,CAAA,GAAA,CAAKC,IAAa,CACrC,KAAA,CAAOA,CAAQ,CAAA,KAAA,CACf,QAASA,CAAQ,CAAA,OAAA,CACjB,KAAOA,CAAAA,CAAAA,CAAQ,KACf,CAAA,WAAA,CAAaA,CAAQ,CAAA,YAAA,CAAa,IAAKC,CAAgB,GAAA,CACrD,KAAOA,CAAAA,CAAAA,CAAW,MAClB,OAASA,CAAAA,CAAAA,CAAW,OACpB,CAAA,KAAA,CAAOA,EAAW,KACpB,CAAA,CAAE,CACJ,CAAA,CAAE,CACJ,CAAA,CAAA,CAIG,CACL,QAAA,CAAU1D,EACV,KAAOuD,CAAAA,CAAAA,CACP,QAAU3P,CAAAA,CACZ,CACF,CAEA,MAAM,IAAIuP,kBAAAA,CAAmB,CAAE,IAAM,CAAA,6BAAA,CAA+B,KAAOD,CAAAA,CAAAA,CAAK,KAAM,CAAC,CACzF,CAGM,iBAAiB1C,CAAqBR,CAAAA,CAAAA,CAA0BuB,CAAsC,CAAA,CAAA,OAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC1G,OAAO,IAAI,QAASC,CAAY,EAAA,CAC9BA,CAAQ,CAAA,IAAA,CAAK,aAAa,EAC5B,CAAC,CACH,GAGM,oBAAqBtC,CAAAA,CAAAA,CAAqBR,CAA0BuB,CAAAA,CAAAA,CAA0C,QAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAClH,OAAO,IAAI,QAASC,CAAY,EAAA,CAC9BA,CAAQ,CAAA,IAAA,CAAK,iBAAkB,EAAC,EAClC,CAAC,CACH,CAEM,CAAA,CAAA,iBAAA,CAAkBtC,CAAoBR,CAAAA,CAAAA,CAAyBuB,CAAyC,CAAA,CAAA,OAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC5G,IAAMhB,CAAoB,CAAA,IAAA,CAAK,eAAgBrB,CAAAA,CAAAA,CAAQR,CAAUuB,CAAAA,CAAK,CAChEwB,CAAAA,CAAAA,CAAsB,KAAK,iBAAkB/C,CAAAA,CAAQ,CAC3D,CAAA,GAAI+C,EAAoB,QAAaA,EAAAA,CAAAA,CAAoB,QAA2B,CAAA,MAAA,GAAW,EAC7F,MAAM,IAAIV,oBAAqB,CAAA,CAC7B,IAAM,CAAA,uBAAA,CACN,KAAO,CAAA,IAAI,MAAM,uBAAuB,CAC1C,CAAC,CAAA,CAGH,IAAMW,CAAAA,CAAmBzB,CAAQ,CAAA,IAAA,CAAK,eAAeA,CAAK,CAAA,CAAI,EAAC,CAE/D,OAAO,IAAI,OAASuB,CAAAA,CAAAA,EAAY,CAC9BA,CAAQnO,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAA,CACN,MAAA,CAAQ,GACR,cAAgB,CAAA,CAAE,aAAe,CAAA,CAAA,CAAK,GACnC,IAAK,CAAA,gBAAA,EACLkN,CAAAA,CAAAA,CAAAA,CAAAA,CACAkB,CACAC,CAAAA,CAAAA,CAAAA,CACJ,EACH,CAAC,CACH,CAEO,CAAA,CAAA,gCAAA,CACLW,CACAC,CAAAA,CAAAA,CAC8E,QAAAC,EAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAxxBlF,IAAAC,CAAAA,CAAAC,EAyxBI,IAAMC,CAAAA,CAAOJ,CAASD,CAAAA,CAAAA,CAClBM,CAAkB,CAAA,EAClBC,CAAAA,CAAAA,CAAY,GAGZC,CAAe,CAAA,CAAA,CACnB,KAAOA,CAAAA,CAAeH,EAAK,MAAQ,EAAA,CACjC,IAAMI,CAAAA,CAAeJ,EAAK,OAAQ,CAAA,CAAA;AAAA,CAAA,CAAMG,CAAY,CAAA,CACpD,GAAIC,CAAAA,GAAiB,GAAI,CACvBF,CAAAA,CAAYF,CAAK,CAAA,SAAA,CAAUG,CAAY,CACvC,CAAA,KACF,CAAO,KAAA,CACL,IAAME,CAAOL,CAAAA,CAAAA,CAAK,SAAUG,CAAAA,CAAAA,CAAcC,CAAY,CAAA,CAAE,IAAK,EAAA,CACzDC,GACFJ,CAAM,CAAA,IAAA,CAAKI,CAAI,CAAA,CAEjBF,EAAeC,CAAe,CAAA,EAChC,CACF,CAGA,QAAWC,CAAQJ,IAAAA,CAAAA,CAAO,CACxB,GAAII,CAAS,GAAA,cAAA,CACX,OAGF,GAAIA,EAAK,UAAW,CAAA,QAAQ,CAAG,CAAA,CAC7B,IAAMC,CAAUD,CAAAA,CAAAA,CAAK,SAAU,CAAA,CAAe,EAC9C,GAAI,CACF,IAAME,CAAAA,CAAiB,KAAK,KAAMD,CAAAA,CAAO,CACnCpB,CAAAA,CAAAA,CAAOhF,GAAyB,SAAUqG,CAAAA,CAAc,CAC9D,CAAA,GAAIrB,EAAK,OAAS,CAAA,CAChB,IAAMsB,CAAAA,CAA2C,CAAE,eAAiB,CAAA,EAAG,CAAA,CACjEpB,CAA+CF,CAAAA,CAAAA,CAAK,IAE1D,CAAA,GAAIE,EAAe,OAAQ,CAAA,MAAA,CAAS,CAAG,CAAA,CACrC,IAAMnD,CAAUmD,CAAAA,CAAAA,CAAe,OAAQ,CAAA,CAAC,EAAE,KAC1C,CAAA,GAAInD,CAAY,GAAA,KAAA,CAAA,EAAa,OAAO,IAAKA,CAAAA,CAAO,CAAE,CAAA,MAAA,GAAW,GAC3D,GAAI,SAAA,GAAaA,CAAWA,EAAAA,CAAAA,CAAQ,UAAY,IAC9CuE,CAAAA,CAAAA,CAAgB,eAAgB,CAAA,IAAA,CAAKC,yBAAyBzH,oBAAsBiD,CAAAA,CAAAA,CAAQ,OAAiB,CAAC,CACrG,CAAA,KAAA,GAAA,SAAA,GAAaA,CAAWA,EAAAA,CAAAA,CAAQ,UAAY,IACrDuE,CAAAA,CAAAA,CAAgB,eAAgB,CAAA,IAAA,CAAKC,yBAAyBzH,oBAAsBiD,CAAAA,CAAAA,CAAQ,OAAiB,CAAC,UACrG,YAAgBA,GAAAA,CAAAA,EAAWA,CAAQ,CAAA,UAAA,GAAe,OAAW,CACtE,IAAMkB,CAAWlB,CAAAA,CAAAA,CAAQ,WAAW,EAAG,CAAA,CAAC,CACxCuE,CAAAA,CAAAA,CAAgB,gBAAgB,IAC9BE,CAAAA,4BAAAA,CACE1H,oBACAmE,CAAAA,CAAAA,CAAS,MACTA,CAAS,CAAA,EAAA,CAAA,CACT2C,CAAA3C,CAAAA,CAAAA,CAAS,QAAT,GAAA,IAAA,CAAA,KAAA,CAAA,CAAA2C,CAAmB,CAAA,IAAA,CAAA,CACnBC,EAAA5C,CAAS,CAAA,QAAA,GAAT,IAAA4C,CAAAA,KAAAA,CAAAA,CAAAA,CAAAA,CAAmB,SACrB,CACF,EACF,CAEJ,CAAA,CAEIX,EAAe,KACjBoB,GAAAA,CAAAA,CAAgB,KAAQ,CAAA,CACtB,aAAcpB,CAAe,CAAA,KAAA,CAAM,aACnC,CAAA,gBAAA,CAAkBA,EAAe,KAAM,CAAA,iBAAA,CACvC,WAAaA,CAAAA,CAAAA,CAAe,MAAM,YACpC,CAAA,CAAA,CAEF,MAAM,CAAE,gBAAiBoB,CAAiB,CAAA,MAAA,CAAQN,CAAU,EAC9D,CACE,KAAA,MAAM,IAAIf,kBAAAA,CAAmB,CAAE,IAAM,CAAA,6BAAA,CAA+B,KAAOD,CAAAA,CAAAA,CAAK,KAAM,CAAC,CAE3F,CAASyB,MAAAA,CAAAA,CAAO,CACd,MAAM,IAAIxB,kBAAmB,CAAA,CAC3B,KAAM,CAAsCmB,mCAAAA,EAAAA,CAAO,CACnD,CAAA,CAAA,KAAA,CAAOK,CACT,CAAC,CACH,CACF,CACF,CAGA,MAAM,CAAE,eAAiB,CAAA,CAAE,gBAAiB,EAAG,CAAG,CAAA,MAAA,CAAQT,CAAU,EACtE,CACO,CAAA,CAAA,qCAAA,CACLP,EACAC,CACAI,CAAAA,CAAAA,CACAY,CACAC,CAAAA,CAAAA,CAC8E,QAAAhB,EAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAE9E,MAAAiB,EAAAA,CAAO,KAAK,gCAAiCnB,CAAAA,CAAAA,CAAOC,CAAM,CAAA,EAC5D,GACM,qBAAsBI,CAAAA,CAAAA,CAAYY,CAAkCC,CAAAA,CAAAA,CAAkD,QAAAhC,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC1H,OAAO,IAAI,QAASC,CAAY,EAAA,CAC9BA,CAAQ,CAAA,IAAA,CAAK,aAAa,EAC5B,CAAC,CACH,CAAA,CAAA,CACM,uBAAwBkB,CAAAA,CAAAA,CAAYY,CAAkCC,CAAAA,CAAAA,CAAkD,QAAAhC,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC5H,OAAO,IAAI,QAASC,CAAY,EAAA,CAC9BA,CAAQ,CAAA,IAAA,CAAK,eAAe,EAC9B,CAAC,CACH,CAAA,CAAA,CAEM,4BAA4BkB,CAAYY,CAAAA,CAAAA,CAAkCC,CAAsD,CAAA,CAAA,OAAAhC,EAAA,IACpI,CAAA,IAAA,CAAA,WAAA,CAAA,GAAI,CAAC+B,CAAAA,CACH,OAAO,EAAC,CAEV,IAAMG,CAAAA,CAA2CpQ,EAAA,EAAKiQ,CAAAA,CAAAA,CAAAA,CAEtD,OAAOG,OAAAA,CAAAA,CAAiB,IACxB,CAAA,OAAOA,CAAiB,CAAA,gBAAgB,EACjCA,CACT,CAAA,CAAA,CACM,yBAA0Bf,CAAAA,CAAAA,CAAYY,EAAkCC,CAAsD,CAAA,CAAA,OAAAhC,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAElI,OAAO,MAAM,IAAA,CAAK,2BAA4BmB,CAAAA,CAAAA,CAAMY,EAASC,CAAK,CACpE,CAEA,CAAA,CAAA,eAAA,EAAsC,CAEpC,GAAI,EAAE,IAAK,CAAA,SAAA,IAAalP,GACtB,MAAM,IAAIwN,kBAAmB,CAAA,CAC3B,KAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAA,CAC1D,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,0CAAA,EAA6C,KAAK,SAAS,CAAA,CAAA,CAAG,CACjF,CAAC,EAIH,OADcxN,CAAAA,CAAY,IAAK,CAAA,SAAqC,CAEtE,CACF,EC34BA,IAAMO,EAA4B,CAAA,oBAAA,CAC5B8O,GACJ,yNAGI3O,CAAAA,EAAAA,CAA2B4O,eAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAE,CAAA,KAAA,CAAM,CAClH,IAAA,CAAM1H,GACN,WAAa8O,CAAAA,EAAAA,CACb,cAAgB,CAAA,IAAA,CAChB,eAAiB,CAAA,IAAA,CACjB,KAAO9H,CAAAA,CAAAA,CACP,WAAYS,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKlI,EAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,IACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,MACzD,CACA,CAAA,KAAA,CAAOE,EAAYO,EAAyB,CAC9C,CAAC,CAAA,CAEKE,GAA4B4I,CAG5B7I,CAAAA,EAAAA,CAAN,cAAiC8I,CAAc,CAC7C,WAAYzC,CAAAA,CAAAA,CAAwC,CAClD,KAAA,CAAMnG,EAA0BmG,CAAAA,CAAO,EACzC,CACF,MC1BMlG,EAA4B,CAAA,oBAAA,CAC5B4O,EACJ,CAAA,sNAAA,CAGIzO,GAA2BwO,eAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAA,CAAE,MAAM,CAClH,IAAA,CAAMtH,EACN,CAAA,WAAA,CAAa4O,GACb,cAAgB,CAAA,IAAA,CAChB,eAAiB,CAAA,KAAA,CACjB,MAAOhI,CACP,CAAA,UAAA,CAAYS,CACZ,CAAA,MAAA,CAAQ,CACN,GAAKlI,CAAAA,CAAAA,CAAuB,cAAe,CAAA,KAAA,CAAO,CAAC,CAAA,CAAE,GACrD,CAAA,MAAA,CAAQA,EAAuB,cAAe,CAAA,KAAA,CAAO,CAAC,CAAA,CAAE,MAC1D,CACA,CAAA,KAAA,CAAOE,CAAYW,CAAAA,EAAyB,CAC9C,CAAC,CAAA,CAEKE,EAA4BwI,CAAAA,CAAAA,CAG5BzI,GAAN,cAAiC0I,CAAc,CAC7C,WAAA,CAAYzC,EAAwC,CAClD,KAAA,CAAM/F,EAA0B+F,CAAAA,CAAO,EACzC,CACF,EC1BA,IAAM1G,EAAuB,CAAA,eAAA,CACvBqP,EAA2B,CAAA,wEAAA,CAE3BlP,EAAsBgP,CAAAA,eAAAA,CAAgBpI,EAAsBe,CAAqC,CAAA,CAAE,KAAM,CAAA,CAC7G,KAAM9H,EACN,CAAA,WAAA,CAAaqP,EACb,CAAA,cAAA,CAAgB,KAChB,eAAiB,CAAA,IAAA,CACjB,KAAOjI,CAAAA,CAAAA,CACP,WAAYS,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKlI,EAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,IACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,MACzD,CACA,CAAA,KAAA,CAAOE,CAAYG,CAAAA,EAAoB,CACzC,CAAC,EAEKE,EAAuBgJ,CAAAA,CAAAA,CAGvBjJ,EAAN,CAAA,cAA4BkJ,CAAc,CACxC,WAAA,CAAYzC,CAAmC,CAAA,CAC7C,MAAMvG,EAAqBuG,CAAAA,CAAO,EACpC,CACF,MCxBM9F,EAA4B,CAAA,oBAAA,CAC5B0O,EACJ,CAAA,qJAAA,CAEIvO,GAA2BoO,eAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAA,CAAE,MAAM,CAClH,IAAA,CAAMlH,EACN,CAAA,WAAA,CAAa0O,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,KACjB,KAAOlI,CAAAA,CAAAA,CACP,UAAYS,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAKlI,CAAuB,CAAA,IAAA,CAAK,KAAM,CAAC,CAAA,CAAE,GAC1C,CAAA,MAAA,CAAQA,EAAuB,IAAK,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MAC/C,CACA,CAAA,KAAA,CAAOE,CAAYe,CAAAA,EAAyB,CAC9C,CAAC,CAAA,CAEKE,EAA4BoI,CAAAA,CAAAA,CAG5BrI,GAAN,cAAiCsI,CAAc,CAC7C,WAAA,CAAYzC,CAAwC,CAAA,CAClD,KAAM3F,CAAAA,EAAAA,CAA0B2F,CAAO,EACzC,CACF,ECzBM1F,IAAAA,EAAAA,CAAoB,aACpBuO,EACJ,CAAA,8GAAA,CAEIpO,EAAmBgO,CAAAA,eAAAA,CAAgBpI,CAAsBe,CAAAA,CAAqC,CAAE,CAAA,KAAA,CAAM,CAC1G,IAAM9G,CAAAA,EAAAA,CACN,WAAauO,CAAAA,EAAAA,CACb,eAAgB,IAChB,CAAA,eAAA,CAAiB,IACjB,CAAA,KAAA,CAAOnI,EACP,UAAYS,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,GAAKlI,CAAAA,CAAAA,CAAuB,IAAK,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,GAAA,CAC1C,MAAQA,CAAAA,CAAAA,CAAuB,KAAK,IAAM,CAAA,CAAC,CAAE,CAAA,MAC/C,EACA,KAAOE,CAAAA,CAAAA,CAAYmB,EAAiB,CACtC,CAAC,CAEKE,CAAAA,EAAAA,CAAoBgI,CAGpBjI,CAAAA,EAAAA,CAAN,cAAyBkI,CAAc,CACrC,WAAYzC,CAAAA,CAAAA,CAAgC,CAC1C,KAAMvF,CAAAA,EAAAA,CAAkBuF,CAAO,EACjC,CACF,ECzBA,IAAMtF,EAA4B,CAAA,oBAAA,CAC5BoO,GACJ,0QAGIjO,CAAAA,EAAAA,CAA2B4N,eAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAE,CAAA,KAAA,CAAM,CAClH,IAAA,CAAM1G,GACN,WAAaoO,CAAAA,EAAAA,CACb,cAAgB,CAAA,KAAA,CAChB,gBAAiB,IACjB,CAAA,KAAA,CAAOpI,CACP,CAAA,UAAA,CAAYS,EACZ,MAAQ,CAAA,CACN,GAAKlI,CAAAA,CAAAA,CAAuB,KAAK,IAAM,CAAA,CAAC,CAAE,CAAA,GAAA,CAC1C,OAAQA,CAAuB,CAAA,IAAA,CAAK,IAAM,CAAA,CAAC,CAAE,CAAA,MAC/C,CACA,CAAA,KAAA,CAAOE,EAAYuB,EAAyB,CAC9C,CAAC,CAAA,CAEKE,GAA4B4H,CAG5B7H,CAAAA,EAAAA,CAAN,cAAiC8H,CAAc,CAC7C,WAAYzC,CAAAA,CAAAA,CAAwC,CAClD,KAAA,CAAMnF,GAA0BmF,CAAO,EACzC,CACF,EC/BA,IAAMlF,GAAgC,wBAChCiO,CAAAA,EAAAA,CACJ,0KAGI9N,CAAAA,EAAAA,CAA+BwN,gBAAgBpI,CAAsBW,CAAAA,CAA6B,CAAE,CAAA,KAAA,CAAM,CAC9G,IAAA,CAAMlG,EACN,CAAA,WAAA,CAAaiO,GACb,cAAgB,CAAA,KAAA,CAChB,eAAiB,CAAA,IAAA,CACjB,MAAOrI,CACP,CAAA,UAAA,CAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAK1H,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,GAAA,CACpD,MAAQA,CAAAA,CAAAA,CAAuB,eAAe,IAAM,CAAA,CAAC,CAAE,CAAA,MACzD,EACA,KAAOE,CAAAA,CAAAA,CAAY2B,EAA6B,CAClD,CAAC,CAEKE,CAAAA,EAAAA,CAAgCwH,CAGhCzH,CAAAA,EAAAA,CAAN,cAAqC0H,CAAc,CACjD,WAAA,CAAYzC,EAA4C,CACtD,KAAA,CAAM/E,EAA8B+E,CAAAA,CAAO,EAC7C,CACF,ECrBA,IAAM9E,EAA6B,CAAA,qBAAA,CAC7B8N,GAAiC,uEAEjC3N,CAAAA,EAAAA,CAA4BoN,eAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAE,CAAA,KAAA,CAAM,CACnH,IAAA,CAAMlG,GACN,WAAa8N,CAAAA,EAAAA,CACb,cAAgB,CAAA,KAAA,CAChB,gBAAiB,IACjB,CAAA,KAAA,CAAOtI,CACP,CAAA,UAAA,CAAYS,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKlI,EAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,IACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,MACzD,CACA,CAAA,KAAA,CAAOE,EAAY+B,EAA0B,CAC/C,CAAC,CAAA,CAEKE,GAA6BoH,CAG7BrH,CAAAA,EAAAA,CAAN,cAAkCsH,CAAc,CAC9C,WAAYzC,CAAAA,CAAAA,CAAyC,CACnD,KAAA,CAAM3E,GAA2B2E,CAAO,EAC1C,CACF,MC7BM1E,EAAqB,CAAA,aAAA,CACrB2N,EACJ,CAAA,gMAAA,CAGIxN,GAAoBgN,eAAgBpI,CAAAA,CAAAA,CAAsBW,CAA6B,CAAA,CAAE,MAAM,CACnG,IAAA,CAAM1F,EACN,CAAA,WAAA,CAAa2N,GACb,cAAgB,CAAA,KAAA,CAChB,eAAiB,CAAA,IAAA,CACjB,MAAOvI,CACP,CAAA,UAAA,CAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAK1H,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,GAAA,CACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MACzD,CACA,CAAA,KAAA,CAAOE,CAAYmC,CAAAA,EAAkB,CACvC,CAAC,CAAA,CAEKE,EAAqBgH,CAAAA,CAAAA,CAGrBjH,GAAN,cAA0BkH,CAAc,CACtC,WAAA,CAAYzC,EAAiC,CAC3C,KAAA,CAAMvE,EAAmBuE,CAAAA,CAAO,EAClC,CACF,ECrBA,IAAMtE,EAAe,CAAA,OAAA,CACfwN,GAAmB,gEAEnBrN,CAAAA,EAAAA,CAAc4M,eAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAA,CAAE,KAAM,CAAA,CACrG,KAAM1F,EACN,CAAA,WAAA,CAAawN,EACb,CAAA,cAAA,CAAgB,KAChB,eAAiB,CAAA,IAAA,CACjB,KAAOxI,CAAAA,CAAAA,CACP,WAAYS,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKlI,EAAuB,IAAK,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,IAC1C,MAAQA,CAAAA,CAAAA,CAAuB,IAAK,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,MAC/C,CACA,CAAA,KAAA,CAAOE,EAAYuC,EAAY,CACjC,CAAC,CAAA,CAEKE,EAAe4G,CAAAA,CAAAA,CAGf7G,EAAN,CAAA,cAAoB8G,CAAc,CAChC,WAAA,CAAYzC,CAA2B,CAAA,CACrC,MAAMnE,EAAamE,CAAAA,CAAO,EAC5B,CACF,MC7BMlD,EAA2B,CAAA,mBAAA,CAC3BqM,EAA+B,CAAA,2FAAA,CAE/BlM,GAA0BwL,eAAgBpI,CAAAA,CAAAA,CAAsBW,CAA6B,CAAA,CAAE,MAAM,CACzG,IAAA,CAAMlE,EACN,CAAA,WAAA,CAAaqM,GACb,cAAgB,CAAA,KAAA,CAChB,eAAiB,CAAA,IAAA,CACjB,KAAOzI,CAAAA,CAAAA,CACP,UAAYC,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAK1H,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,GACpD,CAAA,MAAA,CAAQA,EAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MACzD,CACA,CAAA,KAAA,CAAOE,CAAY2D,CAAAA,EAAwB,CAC7C,CAAC,CAAA,CAEKE,EAA2BwF,CAAAA,CAAAA,CAG3BzF,GAAN,cAAgC0F,CAAc,CAC5C,WAAA,CAAYzC,EAAuC,CACjD,KAAA,CAAM/C,EAAyB+C,CAAAA,CAAO,EACxC,CACF,ECxBMlE,IAAAA,EAAAA,CAA2B,oBAC3BsN,EAA+B,CAAA,2FAAA,CAE/BnN,EAA0BwM,CAAAA,eAAAA,CAAgBpI,EAAsBW,CAA6B,CAAA,CAAE,KAAM,CAAA,CACzG,KAAMlF,EACN,CAAA,WAAA,CAAasN,EACb,CAAA,cAAA,CAAgB,MAChB,eAAiB,CAAA,IAAA,CACjB,KAAO1I,CAAAA,CAAAA,CACP,WAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAK1H,EAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,GACpD,CAAA,MAAA,CAAQA,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,MACzD,CAAA,CACA,MAAOE,CAAY2C,CAAAA,EAAwB,CAC7C,CAAC,EAEKE,EAA2BwG,CAAAA,CAAAA,CAG3BzG,EAAN,CAAA,cAAgC0G,CAAc,CAC5C,WAAA,CAAYzC,CAAuC,CAAA,CACjD,MAAM/D,EAAyB+D,CAAAA,CAAO,EACxC,CACF,MCxBMtD,EAAgC,CAAA,wBAAA,CAChC2M,EACJ,CAAA,8JAAA,CAGIxM,EAA+B4L,CAAAA,eAAAA,CAAgBpI,CAAsBW,CAAAA,CAA6B,EAAE,KAAM,CAAA,CAC9G,IAAMtE,CAAAA,EAAAA,CACN,YAAa2M,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,KACjB,KAAO3I,CAAAA,CAAAA,CACP,UAAYC,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAK1H,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,GACpD,CAAA,MAAA,CAAQA,EAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MACzD,CACA,CAAA,KAAA,CAAOE,CAAYuD,CAAAA,EAA6B,CAClD,CAAC,CAEKE,CAAAA,EAAAA,CAAgC4F,EAGhC7F,EAAN,CAAA,cAAqC8F,CAAc,CACjD,YAAYzC,CAA4C,CAAA,CACtD,KAAMnD,CAAAA,EAAAA,CAA8BmD,CAAO,EAC7C,CACF,EC1BM9D,IAAAA,EAAAA,CAAqB,cACrBmN,EACJ,CAAA,8JAAA,CAGIhN,EAAoBoM,CAAAA,eAAAA,CAAgBpI,EAAsBW,CAA6B,CAAA,CAAE,KAAM,CAAA,CACnG,KAAM9E,EACN,CAAA,WAAA,CAAamN,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,IACjB,CAAA,KAAA,CAAO3I,EACP,UAAYC,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,IAAK1H,CAAuB,CAAA,cAAA,CAAe,IAAM,CAAA,CAAC,EAAE,GACpD,CAAA,MAAA,CAAQA,CAAuB,CAAA,cAAA,CAAe,IAAM,CAAA,CAAC,CAAE,CAAA,MACzD,EACA,KAAOE,CAAAA,CAAAA,CAAY+C,EAAkB,CACvC,CAAC,CAEKE,CAAAA,EAAAA,CAAqBoG,CAGrBrG,CAAAA,EAAAA,CAAN,cAA0BsG,CAAc,CACtC,WAAYzC,CAAAA,CAAAA,CAAiC,CAC3C,KAAA,CAAM3D,EAAmB2D,CAAAA,CAAO,EAClC,CACF,EC1BA,IAAM1D,EAAgB,CAAA,QAAA,CAChBgN,GACJ,8JAGI7M,CAAAA,EAAAA,CAAegM,eAAgBpI,CAAAA,CAAAA,CAAsBW,CAA6B,CAAE,CAAA,KAAA,CAAM,CAC9F,IAAA,CAAM1E,GACN,WAAagN,CAAAA,EAAAA,CACb,cAAgB,CAAA,KAAA,CAChB,gBAAiB,IACjB,CAAA,KAAA,CAAO5I,CACP,CAAA,UAAA,CAAYC,EACZ,MAAQ,CAAA,CACN,GAAK1H,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,IACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,MACzD,CACA,CAAA,KAAA,CAAOE,EAAYmD,EAAa,CAClC,CAAC,CAAA,CAEKE,GAAgBgG,CAGhBjG,CAAAA,EAAAA,CAAN,cAAqBkG,CAAc,CACjC,WAAYzC,CAAAA,CAAAA,CAA4B,CACtC,KAAA,CAAMvD,GAAcuD,CAAO,EAC7B,CACF,EC1BA,IAAM1C,EAAuB,CAAA,eAAA,CACvBiM,EACJ,CAAA,kIAAA,CAEI9L,GAAsBgL,eAAgBpI,CAAAA,CAAAA,CAAsBW,CAA6B,CAAA,CAAE,MAAM,CACrG,IAAA,CAAM1D,EACN,CAAA,WAAA,CAAaiM,GACb,cAAgB,CAAA,GAAA,CAChB,eAAiB,CAAA,GAAA,CACjB,MAAO7I,CACP,CAAA,UAAA,CAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAK1H,CAAAA,CAAAA,CAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAE,CAAA,GAAA,CAC/C,MAAQA,CAAAA,CAAAA,CAAuB,QAAQ,GAAQ,CAAA,CAAC,CAAE,CAAA,MACpD,CACA,CAAA,KAAA,CAAOE,CAAYmE,CAAAA,EAAoB,CACzC,CAAC,CAAA,CAEKE,EAAuBgF,CAAAA,CAAAA,CAGvBjF,GAAN,cAA4BkF,CAAc,CACxC,WAAA,CAAYzC,EAAmC,CAC7C,KAAA,CAAMvC,EAAqBuC,CAAAA,CAAO,EACpC,CACF,ECzBA,IAAM9C,EAAY,CAAA,IAAA,CACZsM,GACJ,6IAEInM,CAAAA,EAAAA,CAAWoL,eAAgBpI,CAAAA,CAAAA,CAAsBW,CAA6B,CAAE,CAAA,KAAA,CAAM,CAC1F,IAAA,CAAM9D,EACN,CAAA,WAAA,CAAasM,EACb,CAAA,cAAA,CAAgB,IAChB,eAAiB,CAAA,GAAA,CACjB,KAAO9I,CAAAA,CAAAA,CACP,WAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAK1H,EAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAA,CAAE,IAC/C,MAAQA,CAAAA,CAAAA,CAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAE,CAAA,MACpD,CACA,CAAA,KAAA,CAAOE,EAAY+D,EAAS,CAC9B,CAAC,CAAA,CAEKE,GAAYoF,CAGZrF,CAAAA,EAAAA,CAAN,cAAiBsF,CAAc,CAC7B,WAAA,CAAYzC,CAAwB,CAAA,CAClC,MAAM3C,EAAU2C,CAAAA,CAAO,EACzB,CACF,MC1BM9B,EAAuB,CAAA,eAAA,CACvBuL,EACJ,CAAA,qGAAA,CAEIpL,GAAsBoK,eAAgBpI,CAAAA,CAAAA,CAAsBW,CAA6B,CAAA,CAAE,MAAM,CACrG,IAAA,CAAM9C,EACN,CAAA,WAAA,CAAauL,GACb,cAAgB,CAAA,GAAA,CAChB,eAAiB,CAAA,GAAA,CACjB,MAAO/I,CACP,CAAA,UAAA,CAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAK1H,CAAuB,CAAA,OAAA,CAAQ,IAAQ,CAAC,CAAA,CAAE,GAC/C,CAAA,MAAA,CAAQA,EAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAA,CAAE,MACpD,CACF,CAAC,CAEKmF,CAAAA,EAAAA,CAAuBoE,EAGvBrE,EAAN,CAAA,cAA4BsE,CAAc,CACxC,YAAYzC,CAAmC,CAAA,CAC7C,KAAM3B,CAAAA,EAAAA,CAAqB2B,CAAO,EACpC,CACF,ECxBM1B,IAAAA,EAAAA,CAAY,IACZoL,CAAAA,EAAAA,CACJ,qGAEIjL,CAAAA,EAAAA,CAAWgK,gBAAgBpI,CAAsBW,CAAAA,CAA6B,CAAE,CAAA,KAAA,CAAM,CAC1F,IAAM1C,CAAAA,EAAAA,CACN,WAAaoL,CAAAA,EAAAA,CACb,eAAgB,GAChB,CAAA,eAAA,CAAiB,GACjB,CAAA,KAAA,CAAOhJ,EACP,UAAYC,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,IAAK1H,CAAuB,CAAA,OAAA,CAAQ,GAAQ,CAAA,CAAC,EAAE,GAC/C,CAAA,MAAA,CAAQA,CAAuB,CAAA,OAAA,CAAQ,IAAQ,CAAC,CAAA,CAAE,MACpD,CACF,CAAC,CAAA,CAEKuF,EAAYgE,CAAAA,CAAAA,CAGZjE,GAAN,cAAiBkE,CAAc,CAC7B,WAAA,CAAYzC,EAAwB,CAClC,KAAA,CAAMvB,EAAUuB,CAAAA,CAAO,EACzB,CACF,ECxBA,IAAMlC,EAAgB,CAAA,SAAA,CAChB6L,GACJ,yJAEI1L,CAAAA,EAAAA,CAAewK,eAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAE,CAAA,KAAA,CAAM,CACtG,IAAA,CAAMtD,GACN,WAAa6L,CAAAA,EAAAA,CACb,cAAgB,CAAA,GAAA,CAChB,eAAiB,CAAA,GAAA,CACjB,KAAOjJ,CAAAA,CAAAA,CACP,WAAYS,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKlI,EAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAA,CAAE,IAC/C,MAAQA,CAAAA,CAAAA,CAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAE,CAAA,MACpD,CACF,CAAC,EAEK+E,EAAgBwE,CAAAA,CAAAA,CAGhBzE,EAAN,CAAA,cAAqB0E,CAAc,CACjC,WAAA,CAAYzC,CAA4B,CAAA,CACtC,MAAM/B,EAAc+B,CAAAA,CAAO,EAC7B,CACF,ECxBMtC,IAAAA,EAAAA,CAA0B,oBAC1BkM,CAAAA,EAAAA,CACJ,0JAEI/L,EAAyB4K,CAAAA,eAAAA,CAAgBpI,CAAsBe,CAAAA,CAAqC,EAAE,KAAM,CAAA,CAChH,IAAM1D,CAAAA,EAAAA,CACN,YAAakM,EACb,CAAA,cAAA,CAAgB,GAChB,CAAA,eAAA,CAAiB,IACjB,KAAOlJ,CAAAA,CAAAA,CACP,UAAYS,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAKlI,CAAuB,CAAA,OAAA,CAAQ,IAAQ,CAAC,CAAA,CAAE,GAC/C,CAAA,MAAA,CAAQA,CAAuB,CAAA,OAAA,CAAQ,GAAQ,CAAA,CAAC,EAAE,MACpD,CACF,CAAC,CAAA,CAEK2E,GAA0B4E,CAG1B7E,CAAAA,EAAAA,CAAN,cAA+B8E,CAAc,CAC3C,WAAYzC,CAAAA,CAAAA,CAAsC,CAChD,KAAA,CAAMnC,GAAwBmC,CAAO,EACvC,CACF,ECnBA,IAAMtB,GAA4B,oBAC5BmL,CAAAA,EAAAA,CACJ,4IAEIhL,CAAAA,EAAAA,CAA2B4J,gBAAgBpI,CAAsBW,CAAAA,CAA6B,CAAE,CAAA,KAAA,CAAM,CAC1G,IAAA,CAAMtC,EACN,CAAA,WAAA,CAAamL,GACb,cAAgB,CAAA,GAAA,CAChB,eAAiB,CAAA,GAAA,CACjB,MAAOnJ,CACP,CAAA,UAAA,CAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAK1H,CAAAA,CAAAA,CAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAE,CAAA,GAAA,CAC/C,MAAQA,CAAAA,CAAAA,CAAuB,QAAQ,GAAQ,CAAA,CAAC,CAAE,CAAA,MACpD,CACF,CAAC,CAAA,CAEK2F,EAA4B4D,CAAAA,CAAAA,CAG5B7D,GAAN,cAAiC8D,CAAc,CAC7C,WAAA,CAAYzC,CAAwC,CAAA,CAClD,KAAMnB,CAAAA,EAAAA,CAA0BmB,CAAO,EACzC,CACF,ECxBMlB,IAAAA,EAAAA,CAAiB,UACjBgL,EACJ,CAAA,4IAAA,CAEI7K,EAAgBwJ,CAAAA,eAAAA,CAAgBpI,EAAsBW,CAA6B,CAAA,CAAE,KAAM,CAAA,CAC/F,KAAMlC,EACN,CAAA,WAAA,CAAagL,EACb,CAAA,cAAA,CAAgB,IAChB,eAAiB,CAAA,GAAA,CACjB,KAAOpJ,CAAAA,CAAAA,CACP,WAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAK1H,CAAuB,CAAA,OAAA,CAAQ,GAAQ,CAAA,CAAC,EAAE,GAC/C,CAAA,MAAA,CAAQA,CAAuB,CAAA,OAAA,CAAQ,IAAQ,CAAC,CAAA,CAAE,MACpD,CACF,CAAC,CAEK+F,CAAAA,EAAAA,CAAiBwD,CAGjBzD,CAAAA,EAAAA,CAAN,cAAsB0D,CAAc,CAClC,WAAYzC,CAAAA,CAAAA,CAA6B,CACvC,KAAMf,CAAAA,EAAAA,CAAee,CAAO,EAC9B,CACF,EChCM+J,IAAAA,CAAAA,CAAyE,CAC7EC,4BACAC,CAAAA,6BACF,CAEMC,CAAAA,CAAAA,CAAqCxS,IAAE,IAAK,CAAA,CAACsS,4BAA8BC,CAAAA,6BAA6B,CAAC,ECRzGE,IAAAA,EAAAA,CAA8BzS,GAAE,CAAA,MAAA,CAAO,CAC3C,MAAQA,CAAAA,GAAAA,CAAE,OAAQ,CAAA,MAAM,EACxB,KAAOA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAChB,KAAMA,GAAE,CAAA,KAAA,CACNA,GAAE,CAAA,MAAA,CAAO,CACP,KAAA,CAAOA,GAAE,CAAA,MAAA,GACT,MAAQA,CAAAA,GAAAA,CAAE,OAAQ,CAAA,WAAW,EAC7B,SAAWA,CAAAA,GAAAA,CAAE,KAAMA,CAAAA,GAAAA,CAAE,QAAQ,CAAA,CAAE,EAAGA,CAAAA,GAAAA,CAAE,QAAS,CAAA,MAAA,EAAQ,CACvD,CAAC,CACH,CAAA,CACA,KAAOA,CAAAA,GAAAA,CAAE,OAAO,CACd,aAAA,CAAeA,GAAE,CAAA,MAAA,GAAS,WAAY,EAAA,CACtC,YAAcA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,WAAY,EACvC,CAAC,CACH,CAAC,ECdK0S,IAAAA,EAAAA,CAA8B1S,IACjC,MAAO,EAAA,CACP,GAAI,CAAA,CAAC,EACL,EAAGA,CAAAA,GAAAA,CAAE,KAAMA,CAAAA,GAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAC,EAAE,GAAI,CAAA,CAAC,CAAC,CAAA,CACpC,GAAGA,GAAE,CAAA,KAAA,CAAMA,GAAE,CAAA,MAAA,EAAS,CAAA,GAAA,EAAM,CAAA,WAAA,EAAa,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,EACjD,EAAGA,CAAAA,GAAAA,CAAE,KAAMA,CAAAA,GAAAA,CAAE,MAAMA,GAAE,CAAA,MAAA,EAAS,CAAA,GAAA,GAAM,WAAY,EAAC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAAA,CAAE,GAAI,CAAA,CAAC,CAAC,CAG9D2S,CAAAA,EAAAA,CAAyB3S,GAAE,CAAA,MAAA,CAAO,CACtC,KAAOA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,GACzB,KAAO0S,CAAAA,EAAAA,CACP,eAAiB1S,CAAAA,GAAAA,CAAE,KAAK,CAAC,OAAA,CAAS,QAAQ,CAAC,EAAE,QAAS,EAAA,CACtD,UAAYA,CAAAA,GAAAA,CAAE,QAAS,CAAA,GAAA,EAAM,CAAA,GAAA,CAAI,CAAC,CAAE,CAAA,QAAA,EACtC,CAAC,ECmBD,IAAM4S,EAA4B5S,GAAE,CAAA,MAAA,CAAO,CACzC,SAAA,CAAWA,IAAE,MAAO,EAAA,CACpB,MAAQA,CAAAA,GAAAA,CAAE,QACV,CAAA,OAAA,CAASA,GAAE,CAAA,MAAA,EAAS,CAAA,GAAA,EAAM,CAAA,QAAA,GAC1B,gBAAkBA,CAAAA,GAAAA,CAAE,MAAO,EAAA,CAAE,KAAM,CAAA,QAAA,EACrC,CAAC,EAGK6S,CAAN,CAAA,KAA+E,CAS7E,WAAA,CAAY7H,EAAuC1C,CAAwC,CAAA,CAR3F,IAAS,CAAA,OAAA,CAAU,KASjB,IAAMI,CAAAA,CAAgBkK,CAA0B,CAAA,KAAA,CAAMtK,CAAO,CAC7D,CAAA,IAAA,CAAK,WAAc0C,CAAAA,CAAAA,CACnB,KAAK,SAAYtC,CAAAA,CAAAA,CAAc,SAC/B,CAAA,IAAA,CAAK,MAASA,CAAAA,CAAAA,CAAc,MAC5B,CAAA,IAAA,CAAK,QAAUuC,uBAAwBvC,CAAAA,CAAAA,CAAc,OAAW/G,EAAAA,CAAAA,CAAO,OAAO,CAC9E,CAAA,IAAA,CAAK,gBAAmBsJ,CAAAA,uBAAAA,CAAwBvC,EAAc,gBAAoB,EAAA,CAAA,EAAG,IAAK,CAAA,OAAO,aAAa,EAChH,CAEA,iBAA6B,EAAA,CAC3B,OAAO,IAAK,CAAA,OACd,CAEA,iBAAA,EAAiC,CAC/B,OAAO,CACL,aAAe,CAAA,CAAA,OAAA,EAAU,KAAK,MAAM,CAAA,CAAA,CACpC,cAAgB,CAAA,kBAClB,CACF,CAEA,gBAA+B,EAAA,CAC7B,OAAO,CACL,KAAA,CAAO,IAAK,CAAA,WAAA,CAAY,IAC1B,CACF,CAQA,aAAcwC,CAAAA,CAAAA,CAAyE,CAErF,IAAMC,CAAAA,CAAiBC,CAA6B,EAAA,CAClD,IAAMC,CAAQ,CAAA,kBAAA,CACRC,CAAwC,CAAA,CAC5C,EAAG,IACH,CAAA,CAAA,CAAG,GACH,CAAA,CAAA,CAAG,IACH,EAAI,CAAA,CACN,CAEIC,CAAAA,CAAAA,CACAC,EAAU,CACd,CAAA,KAAA,CAAQD,CAAQF,CAAAA,CAAAA,CAAM,IAAKD,CAAAA,CAAQ,CAAO,IAAA,IAAA,EAAM,CAC9C,IAAMnL,CAAAA,CAAQ,QAASsL,CAAAA,CAAAA,CAAM,CAAC,CAAC,CAAA,CACzBE,CAAOF,CAAAA,CAAAA,CAAM,CAAC,CACpBC,CAAAA,CAAAA,EAAWvL,CAAQqL,CAAAA,CAAAA,CAAUG,CAAI,EACnC,CAEA,OAAOD,CACT,EAEIE,CAAuB,CAAA,CAAA,CACvBC,CAAqB,CAAA,CAAA,CACnBC,EAAc,CAChBV,CAAAA,CAAAA,CAAAA,CAAgB,4BAA4B,CAAA,GAC9CQ,EAAuBP,CAAcD,CAAAA,CAAAA,CAAgB,4BAA4B,CAAC,CAEhFA,CAAAA,CAAAA,CAAAA,CAAgB,0BAA0B,CAAA,GAC5CS,EAAqBR,CAAcD,CAAAA,CAAAA,CAAgB,0BAA0B,CAAC,GAIhF,IAAMW,CAAAA,CAAU,IAAK,CAAA,GAAA,CAAIH,EAAsBC,CAAkB,CAAA,CACjE,OAAO,CAAE,YAAAC,CAAa,CAAA,OAAA,CAAAC,CAAQ,CAChC,CAEA,aAAciH,CAAAA,CAAAA,CAAyC,CACrD,OAAOA,EAAS,QAAS,CAAA,MAAA,CAAO,CAAC1K,CAAAA,CAAK6D,IAAY7D,CAAM6D,CAAAA,CAAAA,CAAQ,MAAQ,CAAA,CAAC,CAC3E,CAEA,qBAAsBA,CAAAA,CAAAA,CAIpB,CACA,IAAMC,CAAAA,CAAcyG,EAAuB,CAAA,SAAA,CAAU1G,CAAO,CAC5D,CAAA,GAAI,CAACC,CAAAA,CAAY,QACf,MAAM,IAAIC,wBAAyB,CAAA,CAAE,KAAM,uBAAyB,CAAA,KAAA,CAAOD,CAAY,CAAA,KAAM,CAAC,CAGhG,CAAA,IAAME,CAAgBF,CAAAA,CAAAA,CAAY,KAE5B3D,CAAY6D,CAAAA,CAAAA,CAAc,KAE1BC,CAAAA,CAAAA,CAAU,CACd,cAAgBD,CAAAA,CAAAA,CAAc,eAC9B,CAAA,UAAA,CAAYA,CAAc,CAAA,UAC5B,CACME,CAAAA,CAAAA,CAASC,QAAS,CAAA,KAAA,CAAMC,sBAAuBH,CAAAA,CAAO,CAAC,CAEzD0G,CAAAA,CAAAA,CACAC,CACJ,CAAA,OAAI,OAAO5G,CAAc,CAAA,KAAA,EAAU,QACjC4G,CAAAA,CAAAA,CAAkBV,6BAEd,OAAOlG,CAAAA,CAAc,KAAM,CAAA,CAAC,GAAM,QACpC4G,CAAAA,CAAAA,CAAkBV,4BAElBU,CAAAA,CAAAA,CAAkBT,8BAIlBS,CAAoBV,GAAAA,4BAAAA,CAClB,OAAOlG,CAAAA,CAAc,OAAU,QACjC2G,CAAAA,CAAAA,CAAoB,CAClB,QAAA,CAAUC,CACV,CAAA,QAAA,CAAU,CAAC5G,CAAAA,CAAc,KAAK,CAChC,CAAA,CAEA2G,CAAoB,CAAA,CAClB,SAAUC,CACV,CAAA,QAAA,CAAU5G,CAAc,CAAA,KAC1B,EAGE,OAAOA,CAAAA,CAAc,KAAM,CAAA,CAAC,GAAM,QACpC2G,CAAAA,CAAAA,CAAoB,CAClB,QAAA,CAAUC,EACV,QAAU,CAAA,CAAC5G,CAAc,CAAA,KAAiB,CAC5C,CAEA2G,CAAAA,CAAAA,CAAoB,CAClB,QAAA,CAAUC,EACV,QAAU5G,CAAAA,CAAAA,CAAc,KAC1B,CAAA,CAIG,CACL,SAAA,CAAA7D,CACA,CAAA,MAAA,CAAA+D,EACA,iBAAAyG,CAAAA,CACF,CACF,CAGA,gBAAgBzG,CAAoBwG,CAAAA,CAAAA,CAA8C,CAChF,IAAMtF,EAAgB,IAAK,CAAA,WAAA,CAAY,MAAO,CAAA,MAAA,CAAO,UAAUlB,CAAM,CAAA,CACrE,GAAI,CAACkB,EAAc,OACjB,CAAA,MAAM,IAAIC,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,IAAK,CAAA,WAAA,CAAY,IAAI,CAC1D,CAAA,CAAA,CAAA,KAAA,CAAOD,CAAc,CAAA,KACvB,CAAC,CAAA,CAGH,IAAME,CAAAA,CAAeF,EAAc,IACnC,CAAA,OAAA,MAAA,CAAO,IAAKE,CAAAA,CAA0B,EAAE,OAASrF,CAAAA,CAAAA,EAAQ,CACvD,GAAI,CAAC,IAAK,CAAA,WAAA,CAAY,MAAO,CAAA,GAAA,CAAIA,CAAG,CAClC,CAAA,MAAM,IAAIoF,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,IAAK,CAAA,WAAA,CAAY,IAAI,CAC1D,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,yBAAyBpF,CAAG,CAAA;AAAA,8BACvB,EAAA,MAAA,CAAO,KAAK,IAAK,CAAA,WAAA,CAAY,OAAO,GAAG,CAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC9E,CAAC,CAEL,CAAC,CAAA,CAEyB,OAAO,IAAKqF,CAAAA,CAAY,CAAE,CAAA,MAAA,CAAO,CAACtF,CAAAA,CAAKC,IAAQ,CAEvE,IAAMwF,EADM,IAAK,CAAA,WAAA,CAAY,OAAO,GAAIxF,CAAAA,CAAG,EACtB,KACfyF,CAAAA,CAAAA,CAAaJ,EAAarF,CAAG,CAAA,CACnC,OAAAD,CAAIyF,CAAAA,CAAQ,EAAIC,CACT1F,CAAAA,CACT,CAAG,CAAA,EAAgB,CAGrB,CAEA,0BAA2B0K,CAAAA,CAAAA,CAA6C,CACtE,IAAMG,CAAAA,CAAkBC,mBAAoB,CAAA,SAAA,CAAUJ,CAAQ,CAC9D,CAAA,GAAI,CAACG,CAAgB,CAAA,OAAA,CACnB,MAAM,IAAIE,6BAAAA,CAA8B,CAAE,IAAM,CAAA,4BAAA,CAA8B,KAAOF,CAAAA,CAAAA,CAAgB,KAAM,CAAC,EAS9G,OAAO,CACL,MAFqBA,CAAgB,CAAA,IAAA,CAEf,QACxB,CACF,CAGM,oBAAoB3G,CAAqBwG,CAAAA,CAAAA,CAAoD,QAAAnE,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CACjG,OAAO,IAAI,OAAA,CAASC,GAAY,CAC9BA,CAAAA,CAAQ,IAAK,CAAA,gBAAgB,EAC/B,CAAC,CACH,CAGM,CAAA,CAAA,uBAAA,CAAwBtC,EAAqBwG,CAAwD,CAAA,CAAA,OAAAnE,EAAA,IACzG,CAAA,IAAA,CAAA,WAAA,CAAA,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAQ,CAAA,IAAA,CAAK,mBAAmB,EAClC,CAAC,CACH,CAAA,CAAA,CAEM,oBAAqBtC,CAAAA,CAAAA,CAAoBwG,CAAsD,CAAA,CAAA,OAAAnE,EAAA,IACnG,CAAA,IAAA,CAAA,WAAA,CAAA,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAQnO,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAA,GACH,IAAK,CAAA,gBAAA,IACL,IAAK,CAAA,eAAA,CAAgB6L,EAAQwG,CAAQ,CAAA,CAAA,CACrC,KAAK,0BAA2BA,CAAAA,CAAQ,CAC5C,CAAA,EACH,CAAC,CACH,GAEA,8BAA+B/D,CAAAA,CAAAA,CAAsC,CACnE,IAAI/N,CAAAA,CACEgO,EAAOyD,EAA4B,CAAA,SAAA,CAAU1D,CAAQ,CAC3D,CAAA,GAAIC,EAAK,OAAS,CAAA,CAChB,IAAME,CAAiBF,CAAAA,CAAAA,CAAK,KAC5BhO,CAAiB,CAAA,OAAOkO,CAAe,CAAA,IAAA,CAAK,CAAC,CAAA,CAAE,WAAc,QAAWkE,CAAAA,sBAAAA,CAAyBC,sBACjG,IAAMC,CAAAA,CAAapE,EAAe,IAAK,CAAA,GAAA,CAAKqE,CACtC,EAAA,OAAOA,CAAK,CAAA,SAAA,EAAc,SACrB,CACL,KAAA,CAAOA,EAAK,KACZ,CAAA,SAAA,CAAWA,EAAK,SAClB,CAAA,CAEO,CACL,KAAA,CAAOA,CAAK,CAAA,KAAA,CACZ,UAAWA,CAAK,CAAA,SAClB,CAEH,CAED,CAAA,OAAO,CACL,cAAgBvS,CAAAA,CAAAA,CAChB,WAAYsS,CACZ,CAAA,KAAA,CAAO,CACL,WAAapE,CAAAA,CAAAA,CAAe,MAAM,YACpC,CACF,CACF,CAEA,MAAM,IAAID,kBAAAA,CAAmB,CAAE,IAAA,CAAM,8BAA+B,KAAOD,CAAAA,CAAAA,CAAK,KAAM,CAAC,CACzF,CACF,MC7RMxH,EAA+B,CAAA,wBAAA,CAC/BgM,GAAmC,mFAEnC7L,CAAAA,EAAAA,CAA8B8L,qBAAqBjB,CAAkC,CAAA,CAAE,KAAM,CAAA,CACjG,IAAMhL,CAAAA,EAAAA,CACN,YAAagM,EACb,CAAA,UAAA,CAAYnB,EACZ,cAAgB,CAAA,IAAA,CAChB,gBAAiB,IACjB,CAAA,MAAA,CAAQ,CACN,GAAK7Q,CAAAA,CAAAA,CAA4B,MAAO,CAAA,GAAA,CACxC,OAAQA,CAA4B,CAAA,IAAA,GAAO,MAC7C,CACF,CAAC,CAAA,CAEKkG,EAAgCkL,CAAAA,CAAAA,CAGhCnL,GAAN,cAAoCoL,CAAmB,CACrD,WAAYvK,CAAAA,CAAAA,CAA4C,CACtD,KAAMX,CAAAA,EAAAA,CAA6BW,CAAO,EAC5C,CACF,ECtBMV,IAAAA,EAAAA,CAAgC,yBAChC8L,EAAoC,CAAA,+DAAA,CAEpC3L,EAA+B0L,CAAAA,oBAAAA,CAAqBjB,CAAkC,CAAA,CAAE,MAAM,CAClG,IAAA,CAAM5K,GACN,WAAa8L,CAAAA,EAAAA,CACb,WAAYrB,CACZ,CAAA,cAAA,CAAgB,KAChB,eAAiB,CAAA,IAAA,CACjB,OAAQ,CACN,GAAA,CAAK7Q,EAA4B,UAAW,CAAA,IAAI,EAAE,GAClD,CAAA,MAAA,CAAQA,CAA4B,CAAA,UAAA,CAAW,IAAI,CAAA,CAAE,MACvD,CACF,CAAC,EAEKsG,EAAiC8K,CAAAA,CAAAA,CAGjC/K,GAAN,cAAqCgL,CAAmB,CACtD,WAAYvK,CAAAA,CAAAA,CAA6C,CACvD,KAAMP,CAAAA,EAAAA,CAA8BO,CAAO,EAC7C,CACF,ECtBMN,IAAAA,EAAAA,CAAgC,yBAChC2L,EAAoC,CAAA,qEAAA,CAEpCxL,GAA+BsL,oBAAqBjB,CAAAA,CAAkC,EAAE,KAAM,CAAA,CAClG,KAAMxK,EACN,CAAA,WAAA,CAAa2L,GACb,UAAYtB,CAAAA,CAAAA,CACZ,eAAgB,IAChB,CAAA,eAAA,CAAiB,KACjB,MAAQ,CAAA,CACN,GAAK7Q,CAAAA,CAAAA,CAA4B,UAAW,CAAA,IAAI,EAAE,GAClD,CAAA,MAAA,CAAQA,EAA4B,UAAW,CAAA,IAAI,EAAE,MACvD,CACF,CAAC,CAAA,CAEK0G,EAAiC0K,CAAAA,CAAAA,CAGjC3K,GAAN,cAAqC4K,CAAmB,CACtD,WAAYvK,CAAAA,CAAAA,CAA6C,CACvD,KAAMH,CAAAA,EAAAA,CAA8BG,CAAO,EAC7C,CACF","file":"index.mjs","sourcesContent":["import { CHAT_CONFIG, MultiStringConfigItem, RangeConfigItem, SelectBooleanConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\n\nconst temperature = RangeConfigItem({\n  param: \"temperature\",\n  title: CHAT_CONFIG.TEMPERATURE.title,\n  description: CHAT_CONFIG.TEMPERATURE.description,\n  min: 0,\n  max: 2,\n  step: 0.01,\n  default: 1,\n});\n\nconst maxTokens = (maxOutputTokens: number) =>\n  RangeConfigItem({\n    param: \"max_completion_tokens\",\n    title: CHAT_CONFIG.MAX_TOKENS.title,\n    description: CHAT_CONFIG.MAX_TOKENS.description,\n    min: 0,\n    max: maxOutputTokens,\n    step: 1,\n    default: 0,\n  });\n\nconst stop = (maxSequences: number) =>\n  MultiStringConfigItem({\n    param: \"stop\",\n    title: CHAT_CONFIG.STOP(maxSequences).title,\n    description: CHAT_CONFIG.STOP(maxSequences).description,\n    max: maxSequences,\n  });\n\nconst topP = RangeConfigItem({\n  param: \"top_p\",\n  title: CHAT_CONFIG.TOP_P.title,\n  description: CHAT_CONFIG.TOP_P.description,\n  min: 0,\n  max: 1,\n  step: 0.01,\n  default: 1,\n});\n\nconst frequencyPenalty = RangeConfigItem({\n  param: \"frequency_penalty\",\n  title: CHAT_CONFIG.FREQUENCY_PENALTY.title,\n  description: CHAT_CONFIG.FREQUENCY_PENALTY.description,\n  min: -2,\n  max: 2,\n  step: 0.01,\n  default: 0,\n});\n\nconst presencePenalty = RangeConfigItem({\n  param: \"presence_penalty\",\n  title: CHAT_CONFIG.PRESENCE_PENALTY.title,\n  description: CHAT_CONFIG.PRESENCE_PENALTY.description,\n  min: -2,\n  max: 2,\n  step: 0.01,\n  default: 0,\n});\n\nconst seed = RangeConfigItem({\n  param: \"seed\",\n  title: CHAT_CONFIG.SEED.title,\n  description: CHAT_CONFIG.SEED.description,\n  min: 0,\n  max: 1000000,\n  step: 1,\n  default: 0,\n});\n\nconst logProbs = SelectBooleanConfigItem({\n  param: \"logprobs\",\n  title: CHAT_CONFIG.LOG_PROBS.title,\n  description: CHAT_CONFIG.LOG_PROBS.description,\n  default: false,\n});\n\nconst topLogProbs = RangeConfigItem({\n  param: \"top_logprobs\",\n  title: CHAT_CONFIG.TOP_LOG_PROBS.title,\n  description: CHAT_CONFIG.TOP_LOG_PROBS.description,\n  min: 0,\n  max: 20,\n  step: 1,\n  default: 0,\n});\n\nconst toolChoice = SelectStringConfigItem({\n  param: \"tool_choice\",\n  title: \"Tool choice\",\n  description:\n    \"Controls which (if any) tool is called by the model. 'none' means the model will not call a function. 'auto' means the model can pick between generating a message or calling a tool.\",\n  default: \"auto\",\n  choices: [\"auto\", \"required\", \"none\"],\n});\n\nexport { frequencyPenalty, logProbs, maxTokens, presencePenalty, seed, stop, temperature, toolChoice, topLogProbs, topP };\n","import { z } from \"zod\";\n\nimport {\n  frequencyPenalty,\n  logProbs,\n  maxTokens,\n  presencePenalty,\n  seed,\n  stop,\n  temperature,\n  toolChoice,\n  topLogProbs,\n  topP,\n} from \"./common.config.chat-model.openai\";\n\nconst ChatModelBaseConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  z.object({\n    temperature: temperature.schema,\n    maxTokens: maxTokens(maxOutputTokens).schema,\n    stop: stop(maxSequences).schema,\n    topP: topP.schema,\n    frequencyPenalty: frequencyPenalty.schema,\n    presencePenalty: presencePenalty.schema,\n    seed: seed.schema.transform((value) => (value === 0 ? undefined : value)),\n    logProbs: logProbs.schema,\n    topLogProbs: topLogProbs.schema,\n    toolChoice: toolChoice.schema,\n  });\n\nconst ChatModelBaseConfigDef = (maxOutputTokens: number, maxSequences: number) =>\n  ({\n    temperature: temperature.def,\n    maxTokens: maxTokens(maxOutputTokens).def,\n    stop: stop(maxSequences).def,\n    topP: topP.def,\n    frequencyPenalty: frequencyPenalty.def,\n    presencePenalty: presencePenalty.def,\n    seed: seed.def,\n    logProbs: logProbs.def,\n    topLogProbs: topLogProbs.def,\n    toolChoice: toolChoice.def,\n  }) as const;\n\nexport { ChatModelBaseConfigDef, ChatModelBaseConfigSchema };\n","import { CHAT_CONFIG, RangeConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\n\nimport { ChatModelResponseSchemaConfigDef, ChatModelResponseSchemaConfigSchema } from \"./response-schema.config.chat-model.openai\";\n\n// o1 models only support temperature = 1.0\nconst temperature = RangeConfigItem({\n  param: \"temperature\",\n  title: CHAT_CONFIG.TEMPERATURE.title,\n  description: CHAT_CONFIG.TEMPERATURE.description,\n  min: 1,\n  max: 1,\n  step: 0.01,\n  default: 1,\n});\n\nconst reasoningEffort = SelectStringConfigItem({\n  param: \"reasoning_effort\",\n  title: \"Reasoning Effort\",\n  description:\n    \"Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.\",\n  default: \"medium\",\n  choices: [\"low\", \"medium\", \"high\"],\n});\nconst ChatModelOSeriesConfigDef = (maxOutputTokens: number, maxSequences: number) => ({\n  ...ChatModelResponseSchemaConfigDef(maxOutputTokens, maxSequences),\n  temperature: temperature.def,\n  reasoningEffort: reasoningEffort.def,\n});\n\nconst ChatModelOSeriesConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  ChatModelResponseSchemaConfigSchema(maxOutputTokens, maxSequences).extend({\n    temperature: temperature.schema,\n    reasoningEffort: reasoningEffort.schema,\n  });\n\nexport { ChatModelOSeriesConfigDef, ChatModelOSeriesConfigSchema };\n","import { CHAT_CONFIG, ObjectSchemaConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\nimport { ResponseSchema } from \"@adaline/types\";\n\nimport { ChatModelBaseConfigDef, ChatModelBaseConfigSchema } from \"./base.config.chat-model.openai\";\n\nconst responseSchema = ObjectSchemaConfigItem({\n  param: \"response_schema\",\n  title: CHAT_CONFIG.RESPONSE_SCHEMA.title,\n  description: CHAT_CONFIG.RESPONSE_SCHEMA.description,\n  objectSchema: ResponseSchema,\n});\n\nconst responseFormat = SelectStringConfigItem({\n  param: \"response_format\",\n  title: CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.title,\n  description: CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.description,\n  default: \"text\",\n  choices: [\"text\", \"json_object\", \"json_schema\"],\n});\n\nconst ChatModelResponseSchemaConfigDef = (maxOutputTokens: number, maxSequences: number) => ({\n  ...ChatModelBaseConfigDef(maxOutputTokens, maxSequences),\n  responseFormat: responseFormat.def,\n  responseSchema: responseSchema.def,\n});\n\nconst ChatModelResponseSchemaConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  ChatModelBaseConfigSchema(maxOutputTokens, maxSequences).extend({\n    responseFormat: responseFormat.schema,\n    responseSchema: responseSchema.schema,\n  });\n\nexport { ChatModelResponseSchemaConfigDef, ChatModelResponseSchemaConfigSchema };\n","import { CHAT_CONFIG, SelectStringConfigItem } from \"@adaline/provider\";\n\nimport { ChatModelBaseConfigDef, ChatModelBaseConfigSchema } from \"./base.config.chat-model.openai\";\n\nconst responseFormat = SelectStringConfigItem({\n  param: \"response_format\",\n  title: CHAT_CONFIG.RESPONSE_FORMAT.title,\n  description: CHAT_CONFIG.RESPONSE_FORMAT.description,\n  default: \"text\",\n  choices: [\"text\", \"json_object\"],\n});\n\nconst ChatModelResponseFormatConfigDef = (maxOutputTokens: number, maxSequences: number) => ({\n  ...ChatModelBaseConfigDef(maxOutputTokens, maxSequences),\n  responseFormat: responseFormat.def,\n});\n\nconst ChatModelResponseFormatConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  ChatModelBaseConfigSchema(maxOutputTokens, maxSequences).extend({\n    responseFormat: responseFormat.schema,\n  });\n\nexport { ChatModelResponseFormatConfigDef, ChatModelResponseFormatConfigSchema };\n","import { RangeConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\n\nconst encodingFormat = SelectStringConfigItem({\n  param: \"encoding_format\",\n  title: \"Encoding format\",\n  description: \"Select the encoding format for the word embedding.\",\n  default: \"float\",\n  choices: [\"float\", \"base64\"],\n});\n\nconst dimensions = (maxDimensions: number) =>\n  RangeConfigItem({\n    param: \"dimensions\",\n    title: \"Dimensions\",\n    description: \"Select the number of dimensions for the word embedding.\",\n    min: 1,\n    max: maxDimensions,\n    step: 1,\n    default: maxDimensions,\n  });\n\nexport { encodingFormat, dimensions };\n","import { z } from \"zod\";\n\nimport { encodingFormat } from \"./common.config.embedding-model.openai\";\n\nconst EmbeddingModelBaseConfigSchema = () =>\n  z.object({\n    encodingFormat: encodingFormat.schema,\n  });\n\nconst EmbeddingModelBaseConfigDef = () =>\n  ({\n    encodingFormat: encodingFormat.def,\n  }) as const;\n\nexport { EmbeddingModelBaseConfigDef, EmbeddingModelBaseConfigSchema };\n","import { EmbeddingModelBaseConfigDef, EmbeddingModelBaseConfigSchema } from \"./base.config.embedding-model.openai\";\nimport { dimensions } from \"./common.config.embedding-model.openai\";\n\nconst EmbeddingModelDimensionsConfigSchema = (maxDimensions: number) =>\n  EmbeddingModelBaseConfigSchema().extend({\n    dimensions: dimensions(maxDimensions).schema,\n  });\n\nconst EmbeddingModelDimensionsConfigDef = (maxDimensions: number) =>\n  ({\n    ...EmbeddingModelBaseConfigDef(),\n    dimensions: dimensions(maxDimensions).def,\n  }) as const;\n\nexport { EmbeddingModelDimensionsConfigDef, EmbeddingModelDimensionsConfigSchema };\n","import {\n  ChatModelBaseConfigDef,\n  ChatModelBaseConfigSchema,\n  ChatModelOSeriesConfigDef,\n  ChatModelOSeriesConfigSchema,\n  ChatModelResponseFormatConfigDef,\n  ChatModelResponseFormatConfigSchema,\n  ChatModelResponseSchemaConfigDef,\n  ChatModelResponseSchemaConfigSchema,\n} from \"./chat-model\";\nimport {\n  EmbeddingModelBaseConfigDef,\n  EmbeddingModelBaseConfigSchema,\n  EmbeddingModelDimensionsConfigDef,\n  EmbeddingModelDimensionsConfigSchema,\n} from \"./embedding-model\";\n\nconst OpenAIChatModelConfigs = {\n  base: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelBaseConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelBaseConfigSchema(maxOutputTokens, maxSequences),\n  }),\n  responseFormat: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelResponseFormatConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelResponseFormatConfigSchema(maxOutputTokens, maxSequences),\n  }),\n  responseSchema: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelResponseSchemaConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelResponseSchemaConfigSchema(maxOutputTokens, maxSequences),\n  }),\n  oSeries: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelOSeriesConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelOSeriesConfigSchema(maxOutputTokens, maxSequences),\n  }),\n} as const;\n\nconst OpenAIEmbeddingModelConfigs = {\n  base: () => ({\n    def: EmbeddingModelBaseConfigDef(),\n    schema: EmbeddingModelBaseConfigSchema(),\n  }),\n  dimensions: (maxDimensions: number) => ({\n    def: EmbeddingModelDimensionsConfigDef(maxDimensions),\n    schema: EmbeddingModelDimensionsConfigSchema(maxDimensions),\n  }),\n} as const;\n\nexport { OpenAIChatModelConfigs, OpenAIEmbeddingModelConfigs };\n","{\n  \"gpt-3.5-turbo-0125\": {\n    \"modelName\": \"gpt-3.5-turbo-0125\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-3.5-turbo-1106\": {\n    \"modelName\": \"gpt-3.5-turbo-1106\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-3.5-turbo\": {\n    \"modelName\": \"gpt-3.5-turbo\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-0125-preview\": {\n    \"modelName\": \"gpt-4-0125-preview\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 30,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-0613\": {\n    \"modelName\": \"gpt-4-0613\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 30,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-1106-preview\": {\n    \"modelName\": \"gpt-4-1106-preview\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 30,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-turbo-2024-04-09\": {\n    \"modelName\": \"gpt-4-turbo-2024-04-09\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 10,\n            \"outputPricePerMillion\": 30\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-turbo-preview\": {\n    \"modelName\": \"gpt-4-turbo-preview\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 10,\n            \"outputPricePerMillion\": 30\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-turbo\": {\n    \"modelName\": \"gpt-4-turbo\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 10,\n            \"outputPricePerMillion\": 30\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4\": {\n    \"modelName\": \"gpt-4\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 30,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4o-2024-05-13\": {\n    \"modelName\": \"gpt-4o-2024-05-13\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 5,\n            \"outputPricePerMillion\": 20\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4o-2024-08-06\": {\n    \"modelName\": \"gpt-4o-2024-08-06\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 2.5,\n            \"outputPricePerMillion\": 10\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4o-mini-2024-07-18\": {\n    \"modelName\": \"gpt-4o-mini-2024-07-18\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.6,\n            \"outputPricePerMillion\": 2.4\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4o-mini\": {\n    \"modelName\": \"gpt-4o-mini\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.6,\n            \"outputPricePerMillion\": 2.4\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4o\": {\n    \"modelName\": \"gpt-4o\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 5,\n            \"outputPricePerMillion\": 20\n          }\n        }\n      }\n    ]\n  },\n  \"o1-2024-12-17\": {\n    \"modelName\": \"o1-2024-12-17\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 15,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"o1\": {\n    \"modelName\": \"o1\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 15,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"o3-mini-2025-01-31\": {\n    \"modelName\": \"o3-mini-2025-01-31\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.1,\n            \"outputPricePerMillion\": 4.4\n          }\n        }\n      }\n    ]\n  },\n  \"o3-mini\": {\n    \"modelName\": \"o3-mini\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.1,\n            \"outputPricePerMillion\": 4.4\n          }\n        }\n      }\n    ]\n  },\n  \"o3-2025-04-16\": {\n    \"modelName\": \"o3-2025-04-16\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 10.0,\n            \"outputPricePerMillion\": 40.0\n          }\n        }\n      }\n    ]\n  },\n  \"o3\": {\n    \"modelName\": \"o3\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 10.0,\n            \"outputPricePerMillion\": 40.0\n          }\n        }\n      }\n    ]\n  },\n  \"o4-mini-2025-04-16\": {\n    \"modelName\": \"o4-mini-2025-04-16\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.1,\n            \"outputPricePerMillion\": 4.4\n          }\n        }\n      }\n    ]\n  },\n  \"o4-mini\": {\n    \"modelName\": \"o4-mini\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.1,\n            \"outputPricePerMillion\": 4.4\n          }\n        }\n      }\n    ]\n  }\n}","import { z } from \"zod\";\n\nimport { ChatModelSchemaType, ChatModelV1, EmbeddingModelSchemaType, EmbeddingModelV1, ProviderError, ProviderV1 } from \"@adaline/provider\";\n\nimport * as Models from \"../models\";\n\nconst ProviderLiteral = \"openai\";\nclass OpenAI<C extends Models.BaseChatModelOptionsType, E extends Models.BaseEmbeddingModelOptionsType> implements ProviderV1<C, E> {\n  readonly version = \"v1\" as const;\n  readonly name = ProviderLiteral;\n  static readonly baseUrl = \"https://api.openai.com/v1\";\n\n  private readonly chatModelFactories: Record<\n    string,\n    {\n      model: { new (options: any): ChatModelV1 };\n      modelOptions: z.ZodType<any>;\n      modelSchema: ChatModelSchemaType;\n    }\n  > = {\n    [Models.GPT_3_5_TurboLiteral]: {\n      model: Models.GPT_3_5_Turbo,\n      modelOptions: Models.GPT_3_5_TurboOptions,\n      modelSchema: Models.GPT_3_5_TurboSchema,\n    },\n    [Models.GPT_3_5_Turbo_0125Literal]: {\n      model: Models.GPT_3_5_Turbo_0125,\n      modelOptions: Models.GPT_3_5_Turbo_0125Options,\n      modelSchema: Models.GPT_3_5_Turbo_0125Schema,\n    },\n    [Models.GPT_3_5_Turbo_1106Literal]: {\n      model: Models.GPT_3_5_Turbo_1106,\n      modelOptions: Models.GPT_3_5_Turbo_1106Options,\n      modelSchema: Models.GPT_3_5_Turbo_1106Schema,\n    },\n    [Models.GPT_4_0125_PreviewLiteral]: {\n      model: Models.GPT_4_0125_Preview,\n      modelOptions: Models.GPT_4_0125_PreviewOptions,\n      modelSchema: Models.GPT_4_0125_PreviewSchema,\n    },\n    [Models.GPT_4_0613Literal]: {\n      model: Models.GPT_4_0613,\n      modelOptions: Models.GPT_4_0613Options,\n      modelSchema: Models.GPT_4_0613Schema,\n    },\n    [Models.GPT_4_1106_PreviewLiteral]: {\n      model: Models.GPT_4_1106_Preview,\n      modelOptions: Models.GPT_4_1106_PreviewOptions,\n      modelSchema: Models.GPT_4_1106_PreviewSchema,\n    },\n    [Models.GPT_4_Turbo_2024_04_09Literal]: {\n      model: Models.GPT_4_Turbo_2024_04_09,\n      modelOptions: Models.GPT_4_Turbo_2024_04_09Options,\n      modelSchema: Models.GPT_4_Turbo_2024_04_09Schema,\n    },\n    [Models.GPT_4_Turbo_PreviewLiteral]: {\n      model: Models.GPT_4_Turbo_Preview,\n      modelOptions: Models.GPT_4_Turbo_PreviewOptions,\n      modelSchema: Models.GPT_4_Turbo_PreviewSchema,\n    },\n    [Models.GPT_4_TurboLiteral]: {\n      model: Models.GPT_4_Turbo,\n      modelOptions: Models.GPT_4_TurboOptions,\n      modelSchema: Models.GPT_4_TurboSchema,\n    },\n    [Models.GPT_4Literal]: {\n      model: Models.GPT_4,\n      modelOptions: Models.GPT_4Options,\n      modelSchema: Models.GPT_4Schema,\n    },\n    [Models.GPT_4o_2024_08_06Literal]: {\n      model: Models.GPT_4o_2024_08_06,\n      modelOptions: Models.GPT_4o_2024_08_06Options,\n      modelSchema: Models.GPT_4o_2024_08_06Schema,\n    },\n    [Models.GPT_4o_MiniLiteral]: {\n      model: Models.GPT_4o_Mini,\n      modelOptions: Models.GPT_4o_MiniOptions,\n      modelSchema: Models.GPT_4o_MiniSchema,\n    },\n    [Models.GPT_4oLiteral]: {\n      model: Models.GPT_4o,\n      modelOptions: Models.GPT_4oOptions,\n      modelSchema: Models.GPT_4oSchema,\n    },\n    [Models.GPT_4o_Mini_2024_07_18Literal]: {\n      model: Models.GPT_4o_Mini_2024_07_18,\n      modelOptions: Models.GPT_4o_Mini_2024_07_18Options,\n      modelSchema: Models.GPT_4o_Mini_2024_07_18Schema,\n    },\n    [Models.GPT_4o_2024_05_13Literal]: {\n      model: Models.GPT_4o_2024_05_13,\n      modelOptions: Models.GPT_4o_2024_05_13Options,\n      modelSchema: Models.GPT_4o_2024_05_13Schema,\n    },\n    [Models.O1Literal]: {\n      model: Models.O1,\n      modelOptions: Models.O1Options,\n      modelSchema: Models.O1Schema,\n    },\n    [Models.O1_2024_12_17Literal]: {\n      model: Models.O1_2024_12_17,\n      modelOptions: Models.O1_2024_12_17Options,\n      modelSchema: Models.O1_2024_12_17Schema,\n    },\n    [Models.O3Mini2025_01_31Literal]: {\n      model: Models.O3Mini2025_01_31,\n      modelOptions: Models.O3Mini2025_01_31Options,\n      modelSchema: Models.O3Mini2025_01_31Schema,\n    },\n    [Models.O3MiniLiteral]: {\n      model: Models.O3Mini,\n      modelOptions: Models.O3MiniOptions,\n      modelSchema: Models.O3MiniSchema,\n    },\n    [Models.O3_2025_04_16Literal]: {\n      model: Models.O3_2025_04_16,\n      modelOptions: Models.O3_2025_04_16Options,\n      modelSchema: Models.O3_2025_04_16Schema,\n    },\n    [Models.O3Literal]: {\n      model: Models.O3,\n      modelOptions: Models.O3Options,\n      modelSchema: Models.O3Schema,\n    },\n    [Models.O4_Mini_2025_04_16Literal]: {\n      model: Models.O4_Mini_2025_04_16,\n      modelOptions: Models.O4_Mini_2025_04_16Options,\n      modelSchema: Models.O4_Mini_2025_04_16Schema,\n    },\n    [Models.O4_MiniLiteral]: {\n      model: Models.O4_Mini,\n      modelOptions: Models.O4_MiniOptions,\n      modelSchema: Models.O4_MiniSchema,\n    },\n  };\n\n  private readonly embeddingModelFactories: Record<\n    string,\n    {\n      model: { new (options: any): EmbeddingModelV1 };\n      modelOptions: z.ZodType<any>;\n      modelSchema: EmbeddingModelSchemaType;\n    }\n  > = {\n    [Models.Text_Embedding_Ada002Literal]: {\n      model: Models.Text_Embedding_Ada002,\n      modelOptions: Models.Text_Embedding_Ada002_Options,\n      modelSchema: Models.Text_Embedding_Ada002Schema,\n    },\n    [Models.Text_Embedding_3_SmallLiteral]: {\n      model: Models.Text_Embedding_3_Small,\n      modelOptions: Models.Text_Embedding_3_Small_Options,\n      modelSchema: Models.Text_Embedding_3_SmallSchema,\n    },\n    [Models.Text_Embedding_3_LargeLiteral]: {\n      model: Models.Text_Embedding_3_Large,\n      modelOptions: Models.Text_Embedding_3_Large_Options,\n      modelSchema: Models.Text_Embedding_3_LargeSchema,\n    },\n  };\n\n  chatModelLiterals(): string[] {\n    return Object.keys(this.chatModelFactories);\n  }\n\n  chatModelSchemas(): Record<string, ChatModelSchemaType> {\n    return Object.keys(this.chatModelFactories).reduce(\n      (acc, key) => {\n        acc[key] = this.chatModelFactories[key].modelSchema;\n        return acc;\n      },\n      {} as Record<string, ChatModelSchemaType>\n    );\n  }\n\n  chatModel(options: C): ChatModelV1 {\n    const modelName = options.modelName;\n    if (!(modelName in this.chatModelFactories)) {\n      throw new ProviderError({\n        info: `OpenAI chat model: ${modelName} not found`,\n        cause: new Error(`OpenAI chat model: ${modelName} not found, available chat models: \n          [${this.chatModelLiterals().join(\", \")}]`),\n      });\n    }\n\n    const model = this.chatModelFactories[modelName].model;\n    const parsedOptions = this.chatModelFactories[modelName].modelOptions.parse(options);\n    return new model(parsedOptions);\n  }\n\n  embeddingModelLiterals(): string[] {\n    return Object.keys(this.embeddingModelFactories);\n  }\n\n  embeddingModelSchemas(): Record<string, EmbeddingModelSchemaType> {\n    return Object.keys(this.embeddingModelFactories).reduce(\n      (acc, key) => {\n        acc[key] = this.embeddingModelFactories[key].modelSchema;\n        return acc;\n      },\n      {} as Record<string, EmbeddingModelSchemaType>\n    );\n  }\n\n  embeddingModel(options: E): EmbeddingModelV1 {\n    const modelName = options.modelName;\n    if (!(modelName in this.embeddingModelFactories)) {\n      throw new ProviderError({\n        info: `OpenAI embedding model: ${modelName} not found`,\n        cause: new Error(`OpenAI embedding model: ${modelName} not found, available embedding models: \n          [${this.embeddingModelLiterals().join(\", \")}]`),\n      });\n    }\n\n    const model = this.embeddingModelFactories[modelName].model;\n    const parsedOptions = this.embeddingModelFactories[modelName].modelOptions.parse(options);\n    return new model(parsedOptions);\n  }\n}\n\nexport { OpenAI, ProviderLiteral };\n","import { z } from \"zod\";\n\nimport { AssistantRoleLiteral, SystemRoleLiteral, ToolRoleLiteral, UserRoleLiteral } from \"@adaline/types\";\n\nconst OpenAIChatModelRoles = z.enum([SystemRoleLiteral, UserRoleLiteral, AssistantRoleLiteral, ToolRoleLiteral]);\n\nconst OpenAIChatModelRolesMap = {\n  system: SystemRoleLiteral,\n  user: UserRoleLiteral,\n  assistant: AssistantRoleLiteral,\n  tool: ToolRoleLiteral,\n} as const;\n\nexport { OpenAIChatModelRoles, OpenAIChatModelRolesMap };\n","import { z } from \"zod\";\n\nimport { ChatModelSchemaType } from \"@adaline/provider\";\nimport { ImageModalityLiteral, TextModalityLiteral, ToolCallModalityLiteral, ToolResponseModalityLiteral } from \"@adaline/types\";\n\nconst OpenAIChatModelModalities: ChatModelSchemaType[\"modalities\"] = [\n  TextModalityLiteral,\n  ImageModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n];\n\nconst OpenAIChatModelModalitiesEnum = z.enum([\n  TextModalityLiteral,\n  ImageModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n]);\n\nconst OpenAIChatModelTextModalities: ChatModelSchemaType[\"modalities\"] = [TextModalityLiteral];\n\nconst OpenAIChatModelTextModalitiesEnum = z.enum([TextModalityLiteral]);\n\nconst OpenAIChatModelTextToolModalities: ChatModelSchemaType[\"modalities\"] = [\n  TextModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n];\n\nconst OpenAIChatModelTextToolModalitiesEnum = z.enum([TextModalityLiteral, ToolCallModalityLiteral, ToolResponseModalityLiteral]);\n\nexport {\n  OpenAIChatModelModalitiesEnum,\n  OpenAIChatModelModalities,\n  OpenAIChatModelTextModalitiesEnum,\n  OpenAIChatModelTextModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n  OpenAIChatModelTextToolModalities,\n};\n","import { z } from \"zod\";\n\nconst OpenAIBaseLogProb = z.object({\n  token: z.string(),\n  logprob: z.number(),\n  bytes: z.array(z.number()).nullable(),\n});\n\nconst OpenAILogProb = z\n  .object({\n    content: z\n      .array(\n        OpenAIBaseLogProb.extend({\n          top_logprobs: z.array(OpenAIBaseLogProb),\n        })\n      )\n      .nullable()\n      .optional(),\n    refusal: z\n      .array(\n        OpenAIBaseLogProb.extend({\n          top_logprobs: z.array(OpenAIBaseLogProb),\n        })\n      )\n      .nullable()\n      .optional(),\n  })\n  .nullable();\n\nconst OpenAIToolCallsCompleteChatResponse = z.array(\n  z.object({\n    id: z.string().min(1),\n    type: z.enum([\"function\"]),\n    function: z.object({\n      name: z.string(),\n      arguments: z.string(),\n    }),\n  })\n);\n\nconst OpenAICompleteChatResponse = z.object({\n  id: z.string(),\n  object: z.literal(\"chat.completion\"),\n  created: z.number(),\n  model: z.string(),\n  system_fingerprint: z.string().nullable(),\n  choices: z.array(\n    z.object({\n      index: z.number(),\n      message: z.object({\n        role: z.string(),\n        content: z.string().nullable().optional(),\n        tool_calls: OpenAIToolCallsCompleteChatResponse.optional(),\n        refusal: z.string().nullable().optional(),\n      }),\n      logprobs: OpenAILogProb.optional(),\n      finish_reason: z.string(),\n    })\n  ),\n  usage: z.object({\n    prompt_tokens: z.number(),\n    completion_tokens: z.number(),\n    total_tokens: z.number(),\n  }),\n});\ntype OpenAICompleteChatResponseType = z.infer<typeof OpenAICompleteChatResponse>;\n\nconst OpenAIToolCallsStreamChatResponse = z.array(\n  z.object({\n    index: z.number().int(),\n    id: z.string().min(1).optional(),\n    type: z.enum([\"function\"]).optional(),\n    function: z\n      .object({\n        name: z.string().min(1).optional(),\n        arguments: z.string().optional(),\n      })\n      .optional(),\n  })\n);\n\nconst OpenAIStreamChatResponse = z.object({\n  id: z.string(),\n  object: z.string(),\n  created: z.number(),\n  model: z.string(),\n  system_fingerprint: z.string().nullable().optional(),\n  choices: z.array(\n    z.object({\n      index: z.number(),\n      delta: z\n        .object({\n          content: z.string().nullable().optional(),\n          tool_calls: OpenAIToolCallsStreamChatResponse.optional(),\n          refusal: z.string().nullable().optional(),\n        })\n        .or(z.object({})),\n      logprobs: OpenAILogProb.optional(),\n      finish_reason: z.string().nullable(),\n    })\n  ),\n  usage: z\n    .object({\n      prompt_tokens: z.number(),\n      completion_tokens: z.number(),\n      total_tokens: z.number(),\n    })\n    .nullable()\n    .optional(),\n});\ntype OpenAIStreamChatResponseType = z.infer<typeof OpenAIStreamChatResponse>;\n\nexport {\n  OpenAICompleteChatResponse,\n  OpenAIStreamChatResponse,\n  OpenAIToolCallsCompleteChatResponse,\n  OpenAIToolCallsStreamChatResponse,\n  type OpenAICompleteChatResponseType,\n  type OpenAIStreamChatResponseType,\n};\n","import { z } from \"zod\";\n\nconst OpenAIChatRequestTool = z.object({\n  type: z.literal(\"function\"),\n  function: z.object({\n    name: z.string().min(1),\n    description: z.string().min(1).optional(),\n    strict: z.boolean().optional(),\n    parameters: z.any(),\n  }),\n});\ntype OpenAIChatRequestToolType = z.infer<typeof OpenAIChatRequestTool>;\n\nconst OpenAIChatRequestToolChoiceEnum = z.enum([\"none\", \"auto\", \"required\"]);\ntype OpenAIChatRequestToolChoiceEnumType = z.infer<typeof OpenAIChatRequestToolChoiceEnum>;\n\nconst OpenAIChatRequestToolChoiceFunction = z.object({\n  type: z.literal(\"function\"),\n  function: z.object({\n    name: z.string().min(1),\n  }),\n});\ntype OpenAIChatRequestToolChoiceFunctionType = z.infer<typeof OpenAIChatRequestToolChoiceFunction>;\n\nconst OpenAIChatRequestResponseFormat = z\n  .object({\n    type: z.enum([\"text\", \"json_object\"]),\n  })\n  .or(\n    z.object({\n      type: z.literal(\"json_schema\"),\n      json_schema: z.object({\n        name: z.string().min(1),\n        description: z.string().min(1).optional(),\n        strict: z.boolean().optional(),\n        schema: z.any(),\n      }),\n    })\n  );\ntype OpenAIChatRequestResponseFormatType = z.infer<typeof OpenAIChatRequestResponseFormat>;\n\nconst OpenAIChatRequestTextContent = z.object({\n  text: z.string().min(1),\n  type: z.literal(\"text\"),\n});\ntype OpenAIChatRequestTextContentType = z.infer<typeof OpenAIChatRequestTextContent>;\n\nconst OpenAIChatRequestImageContent = z.object({\n  type: z.literal(\"image_url\"),\n  image_url: z.object({\n    url: z.string().url().min(1),\n    detail: z.enum([\"low\", \"high\", \"auto\"]).optional(),\n  }),\n});\ntype OpenAIChatRequestImageContentType = z.infer<typeof OpenAIChatRequestImageContent>;\n\nconst OpenAIChatRequestToolCallContent = z.object({\n  id: z.string().min(1),\n  type: z.literal(\"function\"),\n  function: z.object({\n    name: z.string().min(1),\n    arguments: z.string().min(1),\n  }),\n});\ntype OpenAIChatRequestToolCallContentType = z.infer<typeof OpenAIChatRequestToolCallContent>;\n\nconst OpenAIChatRequestSystemMessage = z.object({\n  role: z.literal(\"system\"),\n  content: z.string().min(1).or(z.array(OpenAIChatRequestTextContent).min(1)),\n});\ntype OpenAIChatRequestSystemMessageType = z.infer<typeof OpenAIChatRequestSystemMessage>;\n\nconst OpenAIChatRequestUserMessage = z.object({\n  role: z.literal(\"user\"),\n  content: z\n    .string()\n    .min(1)\n    .or(z.array(z.union([OpenAIChatRequestTextContent, OpenAIChatRequestImageContent])).min(1)),\n});\ntype OpenAIChatRequestUserMessageType = z.infer<typeof OpenAIChatRequestUserMessage>;\n\nconst OpenAIChatRequestAssistantMessage = z.object({\n  role: z.literal(\"assistant\"),\n  content: z.string().min(1).or(z.array(OpenAIChatRequestTextContent).min(1)).optional(),\n  tool_calls: z.array(OpenAIChatRequestToolCallContent).min(1).optional(),\n});\ntype OpenAIChatRequestAssistantMessageType = z.infer<typeof OpenAIChatRequestAssistantMessage>;\n\nconst OpenAIChatRequestToolMessage = z.object({\n  role: z.literal(\"tool\"),\n  tool_call_id: z.string().min(1),\n  content: z.string().min(1),\n});\ntype OpenAIChatRequestToolMessageType = z.infer<typeof OpenAIChatRequestToolMessage>;\n\nconst OpenAIChatRequestMessage = z.union([\n  OpenAIChatRequestSystemMessage,\n  OpenAIChatRequestUserMessage,\n  OpenAIChatRequestAssistantMessage,\n  OpenAIChatRequestToolMessage,\n]);\ntype OpenAIChatRequestMessageType = z.infer<typeof OpenAIChatRequestMessage>;\n\nconst OpenAIChatRequest = z.object({\n  model: z.string().min(1).optional(),\n  messages: z.array(OpenAIChatRequestMessage).min(1),\n  frequency_penalty: z.number().min(-2).max(2).nullable().optional(),\n  logprobs: z.boolean().nullable().optional(),\n  top_logprobs: z.number().min(0).max(20).nullable().optional(),\n  max_completion_tokens: z.number().min(0).nullable().optional(),\n  presence_penalty: z.number().min(-2).max(2).nullable().optional(),\n  response_format: OpenAIChatRequestResponseFormat.optional(),\n  seed: z.number().nullable().optional(),\n  stop: z.string().or(z.array(z.string()).max(4)).nullable().optional(),\n  temperature: z.number().min(0).max(2).nullable().optional(),\n  top_p: z.number().min(0).max(1).nullable().optional(),\n  tools: z.array(OpenAIChatRequestTool).optional(),\n  tool_choice: OpenAIChatRequestToolChoiceEnum.or(OpenAIChatRequestToolChoiceFunction).optional(),\n});\ntype OpenAIChatRequestType = z.infer<typeof OpenAIChatRequest>;\n\nexport {\n  OpenAIChatRequest,\n  OpenAIChatRequestAssistantMessage,\n  OpenAIChatRequestImageContent,\n  OpenAIChatRequestMessage,\n  OpenAIChatRequestResponseFormat,\n  OpenAIChatRequestSystemMessage,\n  OpenAIChatRequestTextContent,\n  OpenAIChatRequestTool,\n  OpenAIChatRequestToolCallContent,\n  OpenAIChatRequestToolChoiceEnum,\n  OpenAIChatRequestToolChoiceFunction,\n  OpenAIChatRequestToolMessage,\n  OpenAIChatRequestUserMessage,\n  type OpenAIChatRequestAssistantMessageType,\n  type OpenAIChatRequestImageContentType,\n  type OpenAIChatRequestMessageType,\n  type OpenAIChatRequestResponseFormatType,\n  type OpenAIChatRequestSystemMessageType,\n  type OpenAIChatRequestTextContentType,\n  type OpenAIChatRequestToolCallContentType,\n  type OpenAIChatRequestToolChoiceEnumType,\n  type OpenAIChatRequestToolChoiceFunctionType,\n  type OpenAIChatRequestToolMessageType,\n  type OpenAIChatRequestToolType,\n  type OpenAIChatRequestType,\n  type OpenAIChatRequestUserMessageType,\n};\n","import { z } from \"zod\";\n\nimport {\n  ChatModelSchemaType,\n  ChatModelV1,\n  getMimeTypeFromBase64,\n  HeadersType,\n  InvalidConfigError,\n  InvalidMessagesError,\n  InvalidModelRequestError,\n  InvalidToolsError,\n  ModelResponseError,\n  ParamsType,\n  removeUndefinedEntries,\n  SelectStringConfigItemDefType,\n  UrlType,\n  urlWithoutTrailingSlash,\n} from \"@adaline/provider\";\nimport {\n  AssistantRoleLiteral,\n  Base64ImageContentTypeLiteral,\n  Base64ImageContentValueType,\n  ChatLogProbsType,\n  ChatModelPriceType,\n  ChatResponseType,\n  ChatUsageType,\n  Config,\n  ConfigType,\n  ContentType,\n  createPartialTextMessage,\n  createPartialToolCallMessage,\n  createTextContent,\n  createToolCallContent,\n  ImageModalityLiteral,\n  Message,\n  MessageType,\n  PartialChatResponseType,\n  SystemRoleLiteral,\n  TextModalityLiteral,\n  Tool,\n  ToolCallContentType,\n  ToolCallModalityLiteral,\n  ToolResponseContentType,\n  ToolResponseModalityLiteral,\n  ToolRoleLiteral,\n  ToolType,\n  UrlImageContentTypeLiteral,\n  UserRoleLiteral,\n} from \"@adaline/types\";\n\nimport pricingData from \"../pricing.json\";\nimport { OpenAI } from \"./../../provider/provider.openai\";\nimport {\n  OpenAIChatRequest,\n  OpenAIChatRequestImageContentType,\n  OpenAIChatRequestTextContentType,\n  OpenAIChatRequestToolType,\n  OpenAIChatRequestType,\n  OpenAICompleteChatResponse,\n  OpenAICompleteChatResponseType,\n  OpenAIStreamChatResponse,\n  OpenAIStreamChatResponseType,\n} from \"./types\";\n\nconst BaseChatModelOptions = z.object({\n  modelName: z.string(),\n  apiKey: z.string(),\n  baseUrl: z.string().url().optional(),\n  completeChatUrl: z.string().url().optional(),\n  streamChatUrl: z.string().url().optional(),\n  organization: z.string().optional(),\n});\ntype BaseChatModelOptionsType = z.infer<typeof BaseChatModelOptions>;\n\nclass BaseChatModel implements ChatModelV1<ChatModelSchemaType> {\n  readonly version = \"v1\" as const;\n  modelSchema: ChatModelSchemaType;\n  modelName: string;\n\n  private readonly apiKey: string;\n  private readonly baseUrl: string;\n  private readonly streamChatUrl: string;\n  private readonly completeChatUrl: string;\n  private readonly organization: string | undefined;\n\n  constructor(modelSchema: ChatModelSchemaType, options: BaseChatModelOptionsType) {\n    const parsedOptions = BaseChatModelOptions.parse(options);\n    this.modelSchema = modelSchema;\n    this.modelName = parsedOptions.modelName;\n    this.apiKey = parsedOptions.apiKey;\n    this.baseUrl = urlWithoutTrailingSlash(parsedOptions.baseUrl || OpenAI.baseUrl);\n    this.streamChatUrl = urlWithoutTrailingSlash(parsedOptions.streamChatUrl || `${this.baseUrl}/chat/completions`);\n    this.completeChatUrl = urlWithoutTrailingSlash(parsedOptions.completeChatUrl || `${this.baseUrl}/chat/completions`);\n    this.organization = parsedOptions.organization;\n  }\n\n  getDefaultBaseUrl(): UrlType {\n    return this.baseUrl;\n  }\n\n  getDefaultHeaders(): HeadersType {\n    return {\n      Authorization: `Bearer ${this.apiKey}`,\n      \"Content-Type\": \"application/json\",\n      ...(this.organization ? { \"OpenAI-Organization\": this.organization } : {}),\n    };\n  }\n\n  getDefaultParams(): ParamsType {\n    return {\n      model: this.modelName,\n    };\n  }\n\n  // x-ratelimit-limit-requests\tThe maximum number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-limit-tokens\tThe maximum number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-requests The remaining number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-tokens\tThe remaining number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-reset-requests\tThe time until the rate limit (based on requests) resets to its initial state.\n  // x-ratelimit-reset-tokens\tThe time until the rate limit (based on tokens) resets to its initial state.\n  getRetryDelay(responseHeaders: HeadersType): { shouldRetry: boolean; delayMs: number } {\n    // parse duration from header value of format \"6m0s\" or \"21s\" or \"41ms\" or \"2s81ms\" or \"5h50m30ms\" and such\n    const parseDuration = (duration: string): number => {\n      const regex = /(\\d+)(h|m|s|ms)/g;\n      const timeUnits: { [unit: string]: number } = {\n        h: 3600000, // 1 hour = 60 * 60 * 1000 ms\n        m: 60000, // 1 minute = 60 * 1000 ms\n        s: 1000, // 1 second = 1000 ms\n        ms: 1, // milliseconds\n      };\n\n      let match;\n      let totalMs = 0;\n      while ((match = regex.exec(duration)) !== null) {\n        const value = parseInt(match[1]);\n        const unit = match[2];\n        totalMs += value * timeUnits[unit];\n      }\n\n      return totalMs;\n    };\n\n    let resetRequestsDelayMs = 0;\n    let resetTokensDelayMs = 0;\n    const shouldRetry = true;\n    if (responseHeaders[\"x-ratelimit-reset-requests\"]) {\n      resetRequestsDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-requests\"]);\n    }\n    if (responseHeaders[\"x-ratelimit-reset-tokens\"]) {\n      resetTokensDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-tokens\"]);\n    }\n\n    // if rate limited by requests, then it's reset must be the higher of two and visa versa\n    const delayMs = Math.max(resetRequestsDelayMs, resetTokensDelayMs);\n    return { shouldRetry, delayMs };\n  }\n\n  getTokenCount(messages: MessageType[]): number {\n    return messages.reduce((acc, message) => {\n      return acc + message.content.map((content) => (content.modality === \"text\" ? content.value : \"\")).join(\" \").length;\n    }, 0);\n  }\n\n  transformModelRequest(request: OpenAIChatRequestType): {\n    modelName: string | undefined;\n    config: ConfigType;\n    messages: MessageType[];\n    tools: ToolType[] | undefined;\n  } {\n    const safeRequest = OpenAIChatRequest.safeParse(request);\n    if (!safeRequest.success) {\n      throw new InvalidModelRequestError({ info: \"Invalid model request\", cause: safeRequest.error });\n    }\n\n    const parsedRequest = safeRequest.data;\n\n    const modelName = parsedRequest.model;\n\n    if (parsedRequest.tool_choice && (!parsedRequest.tools || parsedRequest.tools.length === 0)) {\n      throw new InvalidModelRequestError({\n        info: `Invalid model request for model : '${this.modelName}'`,\n        cause: new Error(\"'tools' are required when 'tool_choice' is specified\"),\n      });\n    }\n\n    const _config: ConfigType = {};\n    if (parsedRequest.response_format) {\n      _config.responseFormat = parsedRequest.response_format.type;\n      if (parsedRequest.response_format.type === \"json_schema\") {\n        _config.responseSchema = {\n          name: parsedRequest.response_format.json_schema.name,\n          description: parsedRequest.response_format.json_schema.description || \"\",\n          strict: parsedRequest.response_format.json_schema.strict,\n          schema: parsedRequest.response_format.json_schema.schema,\n        };\n      }\n    }\n\n    if (parsedRequest.tool_choice) {\n      if (typeof parsedRequest.tool_choice === \"string\") {\n        _config.toolChoice = parsedRequest.tool_choice;\n      } else {\n        _config.toolChoice = parsedRequest.tool_choice.function.name;\n      }\n    }\n\n    _config.seed = parsedRequest.seed;\n    _config.maxTokens = parsedRequest.max_completion_tokens;\n    _config.temperature = parsedRequest.temperature;\n    _config.topP = parsedRequest.top_p;\n    _config.presencePenalty = parsedRequest.presence_penalty;\n    _config.frequencyPenalty = parsedRequest.frequency_penalty;\n    _config.stop = parsedRequest.stop;\n    _config.logProbs = parsedRequest.logprobs;\n    _config.topLogProbs = parsedRequest.top_logprobs;\n\n    const config = Config().parse(removeUndefinedEntries(_config));\n\n    const messages: MessageType[] = [];\n    const toolCallMap: { [id: string]: ToolCallContentType } = {};\n    parsedRequest.messages.forEach((message) => {\n      const role = message.role;\n      switch (role) {\n        case \"system\":\n          {\n            const content = message.content as string | OpenAIChatRequestTextContentType[];\n            if (typeof content === \"string\") {\n              messages.push({\n                role: role,\n                content: [{ modality: TextModalityLiteral, value: content }],\n              });\n            } else {\n              const _content = content.map((c) => {\n                return { modality: TextModalityLiteral, value: c.text };\n              });\n              messages.push({ role: role, content: _content });\n            }\n          }\n          break;\n\n        case \"user\":\n          {\n            const content = message.content as string | (OpenAIChatRequestTextContentType | OpenAIChatRequestImageContentType)[];\n            if (typeof content === \"string\") {\n              messages.push({\n                role: role,\n                content: [{ modality: TextModalityLiteral, value: content }],\n              });\n            } else {\n              const _content = content.map((c) => {\n                if (c.type === \"text\") {\n                  return { modality: TextModalityLiteral, value: c.text };\n                } else {\n                  if (c.image_url.url.startsWith(\"data:\")) {\n                    return {\n                      modality: ImageModalityLiteral,\n                      detail: c.image_url.detail || \"auto\",\n                      value: {\n                        type: Base64ImageContentTypeLiteral,\n                        base64: c.image_url.url,\n                        mediaType: getMimeTypeFromBase64(c.image_url.url) as Base64ImageContentValueType[\"mediaType\"],\n                      },\n                    };\n                  } else {\n                    return {\n                      modality: ImageModalityLiteral,\n                      detail: c.image_url.detail || \"auto\",\n                      value: { type: UrlImageContentTypeLiteral, url: c.image_url.url },\n                    };\n                  }\n                }\n              });\n              messages.push({ role: role, content: _content });\n            }\n          }\n          break;\n\n        case \"assistant\":\n          {\n            const assistantContent: ContentType[] = [];\n\n            if (!message.content && !message.tool_calls) {\n              throw new InvalidModelRequestError({\n                info: `Invalid model request for model : '${this.modelName}'`,\n                cause: new Error(\"one of'content' or 'tool_calls' must be provided\"),\n              });\n            }\n\n            if (message.content) {\n              const content = message.content as string | OpenAIChatRequestTextContentType[];\n              if (typeof content === \"string\") {\n                assistantContent.push({ modality: TextModalityLiteral, value: content });\n              } else {\n                content.forEach((c) => {\n                  assistantContent.push({ modality: TextModalityLiteral, value: c.text });\n                });\n              }\n            }\n\n            if (message.tool_calls) {\n              const toolCalls = message.tool_calls;\n              toolCalls.forEach((toolCall, index) => {\n                const toolCallContent: ToolCallContentType = {\n                  modality: ToolCallModalityLiteral,\n                  id: toolCall.id,\n                  index: index,\n                  name: toolCall.function.name,\n                  arguments: toolCall.function.arguments,\n                };\n                assistantContent.push(toolCallContent);\n                toolCallMap[toolCallContent.id] = toolCallContent;\n              });\n            }\n            messages.push({ role: role, content: assistantContent });\n          }\n          break;\n\n        case \"tool\":\n          {\n            const toolResponse = message;\n            messages.push({\n              role: role,\n              content: [\n                {\n                  modality: ToolResponseModalityLiteral,\n                  id: toolResponse.tool_call_id,\n                  index: toolCallMap[toolResponse.tool_call_id].index,\n                  name: toolCallMap[toolResponse.tool_call_id].name,\n                  data: toolResponse.content,\n                },\n              ],\n            });\n          }\n          break;\n      }\n    });\n\n    const tools: ToolType[] = [];\n    if (parsedRequest.tools) {\n      parsedRequest.tools.forEach((tool: OpenAIChatRequestToolType) => {\n        tools.push({\n          type: \"function\",\n          definition: {\n            schema: {\n              name: tool.function.name,\n              description: tool.function.description || \"\",\n              strict: tool.function.strict,\n              parameters: tool.function.parameters,\n            },\n          },\n        });\n      });\n    }\n\n    return {\n      modelName,\n      config,\n      messages,\n      tools: tools.length > 0 ? tools : undefined,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  transformConfig(config: ConfigType, messages?: MessageType[], tools?: ToolType[]): ParamsType {\n    const _toolChoice = config.toolChoice;\n    delete config.toolChoice; // can have a specific tool name that is not in the model schema, validated at transformation\n\n    const _parsedConfig = this.modelSchema.config.schema.safeParse(config);\n    if (!_parsedConfig.success) {\n      throw new InvalidConfigError({\n        info: `Invalid config for model : '${this.modelName}'`,\n        cause: _parsedConfig.error,\n      });\n    }\n\n    const parsedConfig = _parsedConfig.data as ConfigType;\n    if (_toolChoice !== undefined) {\n      parsedConfig.toolChoice = _toolChoice;\n    }\n\n    Object.keys(parsedConfig).forEach((key) => {\n      if (!(key in this.modelSchema.config.def)) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelName}'`,\n          cause: new Error(`Invalid config key : '${key}', \n            available keys : [${Object.keys(this.modelSchema.config.def).join(\", \")}]`),\n        });\n      }\n    });\n\n    const transformedConfig = Object.keys(parsedConfig).reduce((acc, key) => {\n      const def = this.modelSchema.config.def[key];\n      const paramKey = def.param;\n      const paramValue = (parsedConfig as ConfigType)[key];\n\n      if (paramKey === \"max_completion_tokens\" && def.type === \"range\" && paramValue === 0) {\n        acc[paramKey] = def.max;\n      } else {\n        acc[paramKey] = paramValue;\n      }\n\n      return acc;\n    }, {} as ParamsType);\n\n    if (transformedConfig.top_logprobs && !transformedConfig.logprobs) {\n      throw new InvalidConfigError({\n        info: `Invalid config for model : '${this.modelName}'`,\n        cause: new Error(\"'logprobs' must be 'true' when 'top_logprobs' is specified\"),\n      });\n    }\n\n    if (\"tool_choice\" in transformedConfig && transformedConfig.tool_choice !== undefined) {\n      const toolChoice = transformedConfig.tool_choice as string;\n      if (!tools || (tools && tools.length === 0)) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelName}'`,\n          cause: new Error(\"'tools' are required when 'toolChoice' is specified\"),\n        });\n      } else if (tools && tools.length > 0) {\n        const configToolChoice = this.modelSchema.config.def.toolChoice as SelectStringConfigItemDefType;\n        if (!configToolChoice.choices.includes(toolChoice)) {\n          if (tools.map((tool) => tool.definition.schema.name).includes(toolChoice)) {\n            transformedConfig.tool_choice = { type: \"function\", function: { name: toolChoice } };\n          } else {\n            throw new InvalidConfigError({\n              info: `Invalid config for model : '${this.modelName}'`,\n              cause: new Error(`toolChoice : '${toolChoice}' is not part of provided 'tools' names or \n                one of [${configToolChoice.choices.join(\", \")}]`),\n            });\n          }\n        }\n      }\n    }\n\n    if (\"response_format\" in transformedConfig && transformedConfig.response_format !== undefined) {\n      const responseFormat = transformedConfig.response_format as string;\n      if (responseFormat === \"json_schema\") {\n        if (!(\"response_schema\" in transformedConfig)) {\n          throw new InvalidConfigError({\n            info: `Invalid config for model : '${this.modelName}'`,\n            cause: new Error(\"'responseSchema' is required in config when 'responseFormat' is 'json_schema'\"),\n          });\n        } else {\n          transformedConfig.response_format = {\n            type: \"json_schema\",\n            json_schema: transformedConfig.response_schema,\n          };\n          delete transformedConfig.response_schema;\n        }\n      } else {\n        transformedConfig.response_format = { type: responseFormat };\n      }\n    }\n\n    return transformedConfig;\n  }\n\n  transformMessages(messages: MessageType[]): ParamsType {\n    if (!messages || (messages && messages.length === 0)) {\n      return { messages: [] };\n    }\n\n    const parsedMessages = messages.map((message) => {\n      const parsedMessage = Message().safeParse(message);\n      if (!parsedMessage.success) {\n        throw new InvalidMessagesError({ info: \"Invalid messages\", cause: parsedMessage.error });\n      }\n      return parsedMessage.data;\n    });\n\n    parsedMessages.forEach((message) => {\n      message.content.forEach((content) => {\n        if (!this.modelSchema.modalities.includes(content.modality)) {\n          throw new InvalidMessagesError({\n            info: `Invalid message content for model : '${this.modelName}'`,\n            cause: new Error(`model : '${this.modelName}' does not support modality : '${content.modality}', \n              available modalities : [${this.modelSchema.modalities.join(\", \")}]`),\n          });\n        }\n      });\n    });\n\n    parsedMessages.forEach((message) => {\n      if (!Object.keys(this.modelSchema.roles).includes(message.role)) {\n        throw new InvalidMessagesError({\n          info: `Invalid message content for model : '${this.modelName}'`,\n          cause: new Error(`model : '${this.modelName}' does not support role : '${message.role}', \n            available roles : [${Object.keys(this.modelSchema.roles).join(\", \")}]`),\n        });\n      }\n    });\n\n    const transformedMessages = parsedMessages.map((message) => {\n      switch (message.role) {\n        case SystemRoleLiteral: {\n          const textContent: { type: \"text\"; text: string }[] = [];\n          message.content.forEach((content) => {\n            if (content.modality === TextModalityLiteral) {\n              textContent.push({ type: \"text\", text: content.value });\n            } else {\n              throw new InvalidMessagesError({\n                info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n              });\n            }\n          });\n\n          return {\n            role: this.modelSchema.roles[message.role],\n            content: textContent,\n          };\n        }\n\n        case AssistantRoleLiteral: {\n          const textContent: { type: \"text\"; text: string }[] = [];\n          const toolCalls: { id: string; type: \"function\"; function: { name: string; arguments: string } }[] = [];\n          message.content.forEach((content) => {\n            if (content.modality === TextModalityLiteral) {\n              textContent.push({ type: \"text\", text: content.value });\n            } else if (content.modality === ToolCallModalityLiteral) {\n              toolCalls.push({\n                id: content.id,\n                type: \"function\",\n                function: { name: content.name, arguments: content.arguments },\n              });\n            } else {\n              throw new InvalidMessagesError({\n                info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n              });\n            }\n          });\n\n          return {\n            role: this.modelSchema.roles[message.role],\n            content: textContent,\n            ...(toolCalls.length > 0 ? { tool_calls: toolCalls } : {}),\n          };\n        }\n\n        case UserRoleLiteral: {\n          const textContent: { type: \"text\"; text: string }[] = [];\n          const imageContent: { type: \"image_url\"; image_url: { url: string; detail: string } }[] = [];\n          message.content.forEach((content) => {\n            if (content.modality === TextModalityLiteral) {\n              textContent.push({ type: \"text\", text: content.value });\n            } else if (content.modality === ImageModalityLiteral) {\n              imageContent.push({\n                type: \"image_url\",\n                image_url: {\n                  url: content.value.type === \"url\" ? content.value.url : content.value.base64,\n                  detail: content.detail,\n                },\n              });\n            } else {\n              throw new InvalidMessagesError({\n                info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n              });\n            }\n          });\n\n          const combinedContent = [...textContent, ...imageContent];\n\n          return {\n            role: this.modelSchema.roles[message.role],\n            content: combinedContent,\n          };\n        }\n\n        case ToolRoleLiteral: {\n          if (message.content.length !== 1) {\n            throw new InvalidMessagesError({\n              info: `Invalid message for role : '${message.role}'`,\n              cause: new Error(`role : '${message.role}' must have exactly one content item`),\n            });\n          }\n\n          if (message.content[0].modality !== ToolResponseModalityLiteral) {\n            throw new InvalidMessagesError({\n              info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n              cause: new Error(`role : '${message.role}' must have content with modality : '${ToolResponseModalityLiteral}'`),\n            });\n          }\n\n          const toolResponse = message.content[0] as ToolResponseContentType;\n          return {\n            role: this.modelSchema.roles[message.role],\n            tool_call_id: toolResponse.id,\n            content: toolResponse.data,\n          };\n        }\n\n        default: {\n          throw new InvalidMessagesError({\n            info: `Invalid message 'role' for model : ${this.modelName}`,\n            cause: new Error(`role : '${message.role}' is not supported, \n              available roles : [${Object.keys(this.modelSchema.roles).join(\", \")}]`),\n          });\n        }\n      }\n    });\n\n    return { messages: transformedMessages };\n  }\n\n  transformTools(tools: ToolType[]): ParamsType {\n    if (!this.modelSchema.modalities.includes(ToolCallModalityLiteral)) {\n      throw new InvalidToolsError({\n        info: `Invalid tool 'modality' for model : ${this.modelName}`,\n        cause: new Error(`model : '${this.modelName}' does not support tool modality : '${ToolCallModalityLiteral}'`),\n      });\n    }\n\n    if (!tools || (tools && tools.length === 0)) {\n      return { tools: [] as ToolType[] };\n    }\n\n    const parsedTools = tools.map((tool) => {\n      const parsedTool = Tool().safeParse(tool);\n      if (!parsedTool.success) {\n        throw new InvalidToolsError({ info: \"Invalid tools\", cause: parsedTool.error });\n      }\n      return parsedTool.data;\n    });\n\n    const transformedTools = parsedTools.map((tool) => ({\n      type: \"function\",\n      function: tool.definition.schema,\n    }));\n\n    return { tools: transformedTools };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getCompleteChatUrl(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.completeChatUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getCompleteChatHeaders(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getCompleteChatData(config: ConfigType, messages: MessageType[], tools?: ToolType[]): Promise<ParamsType> {\n    const transformedConfig = this.transformConfig(config, messages, tools);\n    const transformedMessages = this.transformMessages(messages);\n    if (transformedMessages.messages && (transformedMessages.messages as MessageType[]).length === 0) {\n      throw new InvalidMessagesError({\n        info: \"Messages are required\",\n        cause: new Error(\"Messages are required\"),\n      });\n    }\n\n    const transformedTools = tools ? this.transformTools(tools) : {};\n\n    return new Promise((resolve) => {\n      resolve({\n        ...this.getDefaultParams(),\n        ...transformedConfig,\n        ...transformedMessages,\n        ...transformedTools,\n      });\n    });\n  }\n\n  transformCompleteChatResponse(response: any): ChatResponseType {\n    const safe = OpenAICompleteChatResponse.safeParse(response);\n    if (safe.success) {\n      if (safe.data.choices.length === 0) {\n        throw new ModelResponseError({\n          info: \"Invalid response from model\",\n          cause: new Error(`No choices in response : ${JSON.stringify(safe.data)}`),\n        });\n      }\n\n      const parsedResponse: OpenAICompleteChatResponseType = safe.data;\n      const messages: MessageType[] = [\n        {\n          role: AssistantRoleLiteral,\n          content: [],\n        },\n      ];\n      const message = parsedResponse.choices[0].message;\n      if (message.content) {\n        messages[0].content.push(createTextContent(message.content));\n      }\n\n      if (message.refusal) {\n        messages[0].content.push(createTextContent(message.refusal));\n      }\n\n      if (message.tool_calls) {\n        message.tool_calls.forEach((toolCall, index) => {\n          messages[0].content.push(createToolCallContent(index, toolCall.id, toolCall.function.name, toolCall.function.arguments));\n        });\n      }\n\n      const usage: ChatUsageType = {\n        promptTokens: parsedResponse.usage.prompt_tokens,\n        completionTokens: parsedResponse.usage.completion_tokens,\n        totalTokens: parsedResponse.usage.total_tokens,\n      };\n\n      const logProbs: ChatLogProbsType = [];\n      const _logProbs = parsedResponse.choices[0].logprobs;\n      if (_logProbs) {\n        if (_logProbs.content) {\n          logProbs.push(\n            ..._logProbs.content.map((logProb) => ({\n              token: logProb.token,\n              logProb: logProb.logprob,\n              bytes: logProb.bytes,\n              topLogProbs: logProb.top_logprobs.map((topLogProb) => ({\n                token: topLogProb.token,\n                logProb: topLogProb.logprob,\n                bytes: topLogProb.bytes,\n              })),\n            }))\n          );\n        }\n        if (_logProbs.refusal) {\n          logProbs.push(\n            ..._logProbs.refusal.map((logProb) => ({\n              token: logProb.token,\n              logProb: logProb.logprob,\n              bytes: logProb.bytes,\n              topLogProbs: logProb.top_logprobs.map((topLogProb) => ({\n                token: topLogProb.token,\n                logProb: topLogProb.logprob,\n                bytes: topLogProb.bytes,\n              })),\n            }))\n          );\n        }\n      }\n\n      return {\n        messages: messages,\n        usage: usage,\n        logProbs: logProbs,\n      };\n    }\n\n    throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getStreamChatUrl(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.streamChatUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getStreamChatHeaders(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getStreamChatData(config: ConfigType, messages: MessageType[], tools?: ToolType[]): Promise<ParamsType> {\n    const transformedConfig = this.transformConfig(config, messages, tools);\n    const transformedMessages = this.transformMessages(messages);\n    if (transformedMessages.messages && (transformedMessages.messages as MessageType[]).length === 0) {\n      throw new InvalidMessagesError({\n        info: \"Messages are required\",\n        cause: new Error(\"Messages are required\"),\n      });\n    }\n\n    const transformedTools = tools ? this.transformTools(tools) : {};\n\n    return new Promise((resolve) => {\n      resolve({\n        stream: true,\n        stream_options: { include_usage: true },\n        ...this.getDefaultParams(),\n        ...transformedConfig,\n        ...transformedMessages,\n        ...transformedTools,\n      });\n    });\n  }\n\n  async *transformStreamChatResponseChunk(\n    chunk: string,\n    buffer: string\n  ): AsyncGenerator<{ partialResponse: PartialChatResponseType; buffer: string }> {\n    const data = buffer + chunk;\n    let lines: string[] = [];\n    let newBuffer = \"\";\n\n    // Split data into complete lines and new buffer\n    let currentIndex = 0;\n    while (currentIndex < data.length) {\n      const newlineIndex = data.indexOf(\"\\n\", currentIndex);\n      if (newlineIndex === -1) {\n        newBuffer = data.substring(currentIndex);\n        break;\n      } else {\n        const line = data.substring(currentIndex, newlineIndex).trim();\n        if (line) {\n          lines.push(line);\n        }\n        currentIndex = newlineIndex + 1;\n      }\n    }\n\n    // Process each complete line\n    for (const line of lines) {\n      if (line === \"data: [DONE]\") {\n        return; // End of stream\n      }\n\n      if (line.startsWith(\"data: \")) {\n        const jsonStr = line.substring(\"data: \".length);\n        try {\n          const structuredLine = JSON.parse(jsonStr);\n          const safe = OpenAIStreamChatResponse.safeParse(structuredLine);\n          if (safe.success) {\n            const partialResponse: PartialChatResponseType = { partialMessages: [] };\n            const parsedResponse: OpenAIStreamChatResponseType = safe.data;\n            // Process message content\n            if (parsedResponse.choices.length > 0) {\n              const message = parsedResponse.choices[0].delta;\n              if (message !== undefined && Object.keys(message).length !== 0) {\n                if (\"content\" in message && message.content !== null) {\n                  partialResponse.partialMessages.push(createPartialTextMessage(AssistantRoleLiteral, message.content as string));\n                } else if (\"refusal\" in message && message.refusal !== null) {\n                  partialResponse.partialMessages.push(createPartialTextMessage(AssistantRoleLiteral, message.refusal as string));\n                } else if (\"tool_calls\" in message && message.tool_calls !== undefined) {\n                  const toolCall = message.tool_calls.at(0)!;\n                  partialResponse.partialMessages.push(\n                    createPartialToolCallMessage(\n                      AssistantRoleLiteral,\n                      toolCall.index,\n                      toolCall.id,\n                      toolCall.function?.name,\n                      toolCall.function?.arguments\n                    )\n                  );\n                }\n              }\n            }\n\n            if (parsedResponse.usage) {\n              partialResponse.usage = {\n                promptTokens: parsedResponse.usage.prompt_tokens,\n                completionTokens: parsedResponse.usage.completion_tokens,\n                totalTokens: parsedResponse.usage.total_tokens,\n              };\n            }\n            yield { partialResponse: partialResponse, buffer: newBuffer };\n          } else {\n            throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n          }\n        } catch (error) {\n          throw new ModelResponseError({\n            info: `Malformed JSON received in stream: ${jsonStr}`,\n            cause: error,\n          });\n        }\n      }\n    }\n\n    // Yield the updated buffer after processing all lines\n    yield { partialResponse: { partialMessages: [] }, buffer: newBuffer };\n  }\n  async *transformProxyStreamChatResponseChunk(\n    chunk: string,\n    buffer: string,\n    data?: any,\n    headers?: Record<string, string>,\n    query?: Record<string, string>\n  ): AsyncGenerator<{ partialResponse: PartialChatResponseType; buffer: string }> {\n    // Directly delegate to transformStreamChatResponseChunk\n    yield* this.transformStreamChatResponseChunk(chunk, buffer);\n  }\n  async getProxyStreamChatUrl(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.streamChatUrl);\n    });\n  }\n  async getProxyCompleteChatUrl(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.completeChatUrl);\n    });\n  }\n\n  async getProxyCompleteChatHeaders(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<HeadersType> {\n    if (!headers) {\n      return {};\n    }\n    const sanitizedHeaders: Record<string, string> = { ...headers };\n\n    delete sanitizedHeaders.host;\n    delete sanitizedHeaders[\"content-length\"];\n    return sanitizedHeaders;\n  }\n  async getProxyStreamChatHeaders(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<HeadersType> {\n    // Directly delegate to getProxyCompleteChatHeaders for now\n    return await this.getProxyCompleteChatHeaders(data, headers, query);\n  }\n\n  getModelPricing(): ChatModelPriceType {\n    // Check if the modelName exists in pricingData before accessing it\n    if (!(this.modelName in pricingData)) {\n      throw new ModelResponseError({\n        info: `Invalid model pricing for model : '${this.modelName}'`,\n        cause: new Error(`No pricing configuration found for model \"${this.modelName}\"`),\n      });\n    }\n\n    const entry = pricingData[this.modelName as keyof typeof pricingData];\n    return entry as ChatModelPriceType;\n  }\n}\n\nexport { BaseChatModel, BaseChatModelOptions, type BaseChatModelOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_3_5_Turbo_0125Literal = \"gpt-3.5-turbo-0125\";\nconst GPT_3_5_Turbo_0125Description =\n  \"The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a \\\n  text encoding issue for non-English language function calls. Training data up to Sept 2021.\";\n\nconst GPT_3_5_Turbo_0125Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_3_5_Turbo_0125Literal,\n  description: GPT_3_5_Turbo_0125Description,\n  maxInputTokens: 4092,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n  price: pricingData[GPT_3_5_Turbo_0125Literal],\n});\n\nconst GPT_3_5_Turbo_0125Options = BaseChatModelOptions;\ntype GPT_3_5_Turbo_0125OptionsType = z.infer<typeof GPT_3_5_Turbo_0125Options>;\n\nclass GPT_3_5_Turbo_0125 extends BaseChatModel {\n  constructor(options: GPT_3_5_Turbo_0125OptionsType) {\n    super(GPT_3_5_Turbo_0125Schema, options);\n  }\n}\n\nexport {\n  GPT_3_5_Turbo_0125,\n  GPT_3_5_Turbo_0125Literal,\n  GPT_3_5_Turbo_0125Options,\n  GPT_3_5_Turbo_0125Schema,\n  type GPT_3_5_Turbo_0125OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_3_5_Turbo_1106Literal = \"gpt-3.5-turbo-1106\";\nconst GPT_3_5_Turbo_1106Description =\n  \"The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.\\\n   Returns a maximum of 4,096 output tokens. Training data up to Sept 2021.\";\n\nconst GPT_3_5_Turbo_1106Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_3_5_Turbo_1106Literal,\n  description: GPT_3_5_Turbo_1106Description,\n  maxInputTokens: 4092,\n  maxOutputTokens: 16385,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(16385, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(16385, 4).schema,\n  },\n  price: pricingData[GPT_3_5_Turbo_1106Literal], // Added price definition\n});\n\nconst GPT_3_5_Turbo_1106Options = BaseChatModelOptions;\ntype GPT_3_5_Turbo_1106OptionsType = z.infer<typeof GPT_3_5_Turbo_1106Options>;\n\nclass GPT_3_5_Turbo_1106 extends BaseChatModel {\n  constructor(options: GPT_3_5_Turbo_1106OptionsType) {\n    super(GPT_3_5_Turbo_1106Schema, options);\n  }\n}\n\nexport {\n  GPT_3_5_Turbo_1106,\n  GPT_3_5_Turbo_1106Literal,\n  GPT_3_5_Turbo_1106Options,\n  GPT_3_5_Turbo_1106Schema,\n  type GPT_3_5_Turbo_1106OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_3_5_TurboLiteral = \"gpt-3.5-turbo\";\nconst GPT_3_5_TurboDescription = \"Currently points to gpt-3.5-turbo-0125. Training data up to Sept 2021.\";\n\nconst GPT_3_5_TurboSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_3_5_TurboLiteral,\n  description: GPT_3_5_TurboDescription,\n  maxInputTokens: 4092,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n  price: pricingData[GPT_3_5_TurboLiteral],\n});\n\nconst GPT_3_5_TurboOptions = BaseChatModelOptions;\ntype GPT_3_5_TurboOptionsType = z.infer<typeof GPT_3_5_TurboOptions>;\n\nclass GPT_3_5_Turbo extends BaseChatModel {\n  constructor(options: GPT_3_5_TurboOptionsType) {\n    super(GPT_3_5_TurboSchema, options);\n  }\n}\n\nexport { GPT_3_5_Turbo, GPT_3_5_TurboLiteral, GPT_3_5_TurboOptions, GPT_3_5_TurboSchema, type GPT_3_5_TurboOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\"; // Added import\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_0125_PreviewLiteral = \"gpt-4-0125-preview\";\nconst GPT_4_0125_PreviewDescription =\n  \"The latest GPT-4 model intended to reduce cases of laziness where the model doesnt complete a task. Training data up to Apr 2023.\";\n\nconst GPT_4_0125_PreviewSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_0125_PreviewLiteral,\n  description: GPT_4_0125_PreviewDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n  price: pricingData[GPT_4_0125_PreviewLiteral], // Added price definition\n});\n\nconst GPT_4_0125_PreviewOptions = BaseChatModelOptions;\ntype GPT_4_0125_PreviewOptionsType = z.infer<typeof GPT_4_0125_PreviewOptions>;\n\nclass GPT_4_0125_Preview extends BaseChatModel {\n  constructor(options: GPT_4_0125_PreviewOptionsType) {\n    super(GPT_4_0125_PreviewSchema, options);\n  }\n}\n\nexport {\n  GPT_4_0125_Preview,\n  GPT_4_0125_PreviewLiteral,\n  GPT_4_0125_PreviewOptions,\n  GPT_4_0125_PreviewSchema,\n  type GPT_4_0125_PreviewOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_0613Literal = \"gpt-4-0613\";\nconst GPT_4_0613Description =\n  \"Snapshot of gpt-4 from June 13th 2023 with improved function calling support. Training data up to Sept 2021.\";\n\nconst GPT_4_0613Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_0613Literal,\n  description: GPT_4_0613Description,\n  maxInputTokens: 8192,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n  price: pricingData[GPT_4_0613Literal], // Added price definition\n});\n\nconst GPT_4_0613Options = BaseChatModelOptions;\ntype GPT_4_0613OptionsType = z.infer<typeof GPT_4_0613Options>;\n\nclass GPT_4_0613 extends BaseChatModel {\n  constructor(options: GPT_4_0613OptionsType) {\n    super(GPT_4_0613Schema, options);\n  }\n}\n\nexport { GPT_4_0613, GPT_4_0613Literal, GPT_4_0613Options, GPT_4_0613Schema, type GPT_4_0613OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\"; // Added import\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_1106_PreviewLiteral = \"gpt-4-1106-preview\";\nconst GPT_4_1106_PreviewDescription =\n  \"GPT-4 Turbo model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. \\\n  Returns a maximum of 4,096 output tokens. This preview model is not yet suited for production traffic. Training data up to Apr 2023.\";\n\nconst GPT_4_1106_PreviewSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_1106_PreviewLiteral,\n  description: GPT_4_1106_PreviewDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n  price: pricingData[GPT_4_1106_PreviewLiteral], // Added price definition\n});\n\nconst GPT_4_1106_PreviewOptions = BaseChatModelOptions;\ntype GPT_4_1106_PreviewOptionsType = z.infer<typeof GPT_4_1106_PreviewOptions>;\n\nclass GPT_4_1106_Preview extends BaseChatModel {\n  constructor(options: GPT_4_1106_PreviewOptionsType) {\n    super(GPT_4_1106_PreviewSchema, options);\n  }\n}\n\nexport {\n  GPT_4_1106_Preview,\n  GPT_4_1106_PreviewLiteral,\n  GPT_4_1106_PreviewOptions,\n  GPT_4_1106_PreviewSchema,\n  type GPT_4_1106_PreviewOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4_Turbo_2024_04_09Literal = \"gpt-4-turbo-2024-04-09\";\nconst GPT_4_Turbo_2024_04_09Description =\n  \"GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. gpt-4-turbo currently points to this version. \\\n  Training data up to Dec 2023.\";\n\nconst GPT_4_Turbo_2024_04_09Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4_Turbo_2024_04_09Literal,\n  description: GPT_4_Turbo_2024_04_09Description,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4096,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4096, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4096, 4).schema,\n  },\n  price: pricingData[GPT_4_Turbo_2024_04_09Literal],\n});\n\nconst GPT_4_Turbo_2024_04_09Options = BaseChatModelOptions;\ntype GPT_4_Turbo_2024_04_09OptionsType = z.infer<typeof GPT_4_Turbo_2024_04_09Options>;\n\nclass GPT_4_Turbo_2024_04_09 extends BaseChatModel {\n  constructor(options: GPT_4_Turbo_2024_04_09OptionsType) {\n    super(GPT_4_Turbo_2024_04_09Schema, options);\n  }\n}\n\nexport {\n  GPT_4_Turbo_2024_04_09,\n  GPT_4_Turbo_2024_04_09Literal,\n  GPT_4_Turbo_2024_04_09Options,\n  GPT_4_Turbo_2024_04_09Schema,\n  type GPT_4_Turbo_2024_04_09OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_Turbo_PreviewLiteral = \"gpt-4-turbo-preview\";\nconst GPT_4_Turbo_PreviewDescription = \"Currently points to gpt-4-0125-preview. Training data up to Apr 2023.\";\n\nconst GPT_4_Turbo_PreviewSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_Turbo_PreviewLiteral,\n  description: GPT_4_Turbo_PreviewDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n  price: pricingData[GPT_4_Turbo_PreviewLiteral],\n});\n\nconst GPT_4_Turbo_PreviewOptions = BaseChatModelOptions;\ntype GPT_4_Turbo_PreviewOptionsType = z.infer<typeof GPT_4_Turbo_PreviewOptions>;\n\nclass GPT_4_Turbo_Preview extends BaseChatModel {\n  constructor(options: GPT_4_Turbo_PreviewOptionsType) {\n    super(GPT_4_Turbo_PreviewSchema, options);\n  }\n}\n\nexport {\n  GPT_4_Turbo_Preview,\n  GPT_4_Turbo_PreviewLiteral,\n  GPT_4_Turbo_PreviewOptions,\n  GPT_4_Turbo_PreviewSchema,\n  type GPT_4_Turbo_PreviewOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4_TurboLiteral = \"gpt-4-turbo\";\nconst GPT_4_TurboDescription =\n  \"The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling. \\\n  Currently points to gpt-4-turbo-2024-04-09. Training data up to Dec 2023.\";\n\nconst GPT_4_TurboSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4_TurboLiteral,\n  description: GPT_4_TurboDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n  price: pricingData[GPT_4_TurboLiteral],\n});\n\nconst GPT_4_TurboOptions = BaseChatModelOptions;\ntype GPT_4_TurboOptionsType = z.infer<typeof GPT_4_TurboOptions>;\n\nclass GPT_4_Turbo extends BaseChatModel {\n  constructor(options: GPT_4_TurboOptionsType) {\n    super(GPT_4_TurboSchema, options);\n  }\n}\n\nexport { GPT_4_Turbo, GPT_4_TurboLiteral, GPT_4_TurboOptions, GPT_4_TurboSchema, type GPT_4_TurboOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\"; // Added import\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4Literal = \"gpt-4\";\nconst GPT_4Description = \"Currently points to gpt-4-0613. Training data up to Sept 2021.\";\n\nconst GPT_4Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4Literal,\n  description: GPT_4Description,\n  maxInputTokens: 8192,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n  price: pricingData[GPT_4Literal],\n});\n\nconst GPT_4Options = BaseChatModelOptions;\ntype GPT_4OptionsType = z.infer<typeof GPT_4Options>;\n\nclass GPT_4 extends BaseChatModel {\n  constructor(options: GPT_4OptionsType) {\n    super(GPT_4Schema, options);\n  }\n}\n\nexport { GPT_4, GPT_4Literal, GPT_4Options, GPT_4Schema, type GPT_4OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_2024_05_13Literal = \"gpt-4o-2024-05-13\";\nconst GPT_4o_2024_05_13Description = \"Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.\";\n\nconst GPT_4o_2024_05_13Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_2024_05_13Literal,\n  description: GPT_4o_2024_05_13Description,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n  price: pricingData[GPT_4o_2024_05_13Literal],\n});\n\nconst GPT_4o_2024_05_13Options = BaseChatModelOptions;\ntype GPT_4o_2024_05_13OptionsType = z.infer<typeof GPT_4o_2024_05_13Options>;\n\nclass GPT_4o_2024_05_13 extends BaseChatModel {\n  constructor(options: GPT_4o_2024_05_13OptionsType) {\n    super(GPT_4o_2024_05_13Schema, options);\n  }\n}\n\nexport {\n  GPT_4o_2024_05_13,\n  GPT_4o_2024_05_13Literal,\n  GPT_4o_2024_05_13Options,\n  GPT_4o_2024_05_13Schema,\n  type GPT_4o_2024_05_13OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_2024_08_06Literal = \"gpt-4o-2024-08-06\";\nconst GPT_4o_2024_08_06Description = \"Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.\";\n\nconst GPT_4o_2024_08_06Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_2024_08_06Literal,\n  description: GPT_4o_2024_08_06Description,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n  price: pricingData[GPT_4o_2024_08_06Literal],\n});\n\nconst GPT_4o_2024_08_06Options = BaseChatModelOptions;\ntype GPT_4o_2024_08_06OptionsType = z.infer<typeof GPT_4o_2024_08_06Options>;\n\nclass GPT_4o_2024_08_06 extends BaseChatModel {\n  constructor(options: GPT_4o_2024_08_06OptionsType) {\n    super(GPT_4o_2024_08_06Schema, options);\n  }\n}\n\nexport {\n  GPT_4o_2024_08_06,\n  GPT_4o_2024_08_06Literal,\n  GPT_4o_2024_08_06Options,\n  GPT_4o_2024_08_06Schema,\n  type GPT_4o_2024_08_06OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_Mini_2024_07_18Literal = \"gpt-4o-mini-2024-07-18\";\nconst GPT_4o_MiniDescription =\n  \"Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13. \\\n  Training data up to Oct 2023.\";\n\nconst GPT_4o_Mini_2024_07_18Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_Mini_2024_07_18Literal,\n  description: GPT_4o_MiniDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n  price: pricingData[GPT_4o_Mini_2024_07_18Literal],\n});\n\nconst GPT_4o_Mini_2024_07_18Options = BaseChatModelOptions;\ntype GPT_4o_Mini_2024_07_18OptionsType = z.infer<typeof GPT_4o_Mini_2024_07_18Options>;\n\nclass GPT_4o_Mini_2024_07_18 extends BaseChatModel {\n  constructor(options: GPT_4o_Mini_2024_07_18OptionsType) {\n    super(GPT_4o_Mini_2024_07_18Schema, options);\n  }\n}\n\nexport {\n  GPT_4o_Mini_2024_07_18,\n  GPT_4o_Mini_2024_07_18Literal,\n  GPT_4o_Mini_2024_07_18Options,\n  GPT_4o_Mini_2024_07_18Schema,\n  type GPT_4o_Mini_2024_07_18OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_MiniLiteral = \"gpt-4o-mini\";\nconst GPT_4o_MiniDescription =\n  \"Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13. \\\n  Training data up to Oct 2023.\";\n\nconst GPT_4o_MiniSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_MiniLiteral,\n  description: GPT_4o_MiniDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n  price: pricingData[GPT_4o_MiniLiteral],\n});\n\nconst GPT_4o_MiniOptions = BaseChatModelOptions;\ntype GPT_4o_MiniOptionsType = z.infer<typeof GPT_4o_MiniOptions>;\n\nclass GPT_4o_Mini extends BaseChatModel {\n  constructor(options: GPT_4o_MiniOptionsType) {\n    super(GPT_4o_MiniSchema, options);\n  }\n}\n\nexport { GPT_4o_Mini, GPT_4o_MiniLiteral, GPT_4o_MiniOptions, GPT_4o_MiniSchema, type GPT_4o_MiniOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4oLiteral = \"gpt-4o\";\nconst GPT_4oDescription =\n  \"Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13. \\\n  Training data up to Oct 2023.\";\n\nconst GPT_4oSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4oLiteral,\n  description: GPT_4oDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n  price: pricingData[GPT_4oLiteral],\n});\n\nconst GPT_4oOptions = BaseChatModelOptions;\ntype GPT_4oOptionsType = z.infer<typeof GPT_4oOptions>;\n\nclass GPT_4o extends BaseChatModel {\n  constructor(options: GPT_4oOptionsType) {\n    super(GPT_4oSchema, options);\n  }\n}\n\nexport { GPT_4o, GPT_4oLiteral, GPT_4oOptions, GPT_4oSchema, type GPT_4oOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O1_2024_12_17Literal = \"o1-2024-12-17\";\nconst O1_2024_12_17Description =\n  \"A stable release model for production use, offering robust performance and advanced features. Training data up to December 2024.\";\n\nconst O1_2024_12_17Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O1_2024_12_17Literal,\n  description: O1_2024_12_17Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n  price: pricingData[O1_2024_12_17Literal],\n});\n\nconst O1_2024_12_17Options = BaseChatModelOptions;\ntype O1_2024_12_17OptionsType = z.infer<typeof O1_2024_12_17Options>;\n\nclass O1_2024_12_17 extends BaseChatModel {\n  constructor(options: O1_2024_12_17OptionsType) {\n    super(O1_2024_12_17Schema, options);\n  }\n}\n\nexport { O1_2024_12_17, O1_2024_12_17Literal, O1_2024_12_17Options, O1_2024_12_17Schema, type O1_2024_12_17OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O1Literal = \"o1\";\nconst O1Description =\n  \"Highly capable general-purpose reasoning model with advanced capabilities in language, coding, and reasoning. Training data up to Oct 2023.\";\n\nconst O1Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O1Literal,\n  description: O1Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n  price: pricingData[O1Literal],\n});\n\nconst O1Options = BaseChatModelOptions;\ntype O1OptionsType = z.infer<typeof O1Options>;\n\nclass O1 extends BaseChatModel {\n  constructor(options: O1OptionsType) {\n    super(O1Schema, options);\n  }\n}\n\nexport { O1, O1Literal, O1Options, O1Schema, type O1OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O3_2025_04_16Literal = \"o3-2025-04-16\";\nconst O3_2025_04_16Description =\n  \"A new standard for math, science, coding, and visual reasoning tasks. Training data up to Jun 2024.\";\n\nconst O3_2025_04_16Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O3_2025_04_16Literal,\n  description: O3_2025_04_16Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O3_2025_04_16Options = BaseChatModelOptions;\ntype O3_2025_04_16OptionsType = z.infer<typeof O3_2025_04_16Options>;\n\nclass O3_2025_04_16 extends BaseChatModel {\n  constructor(options: O3_2025_04_16OptionsType) {\n    super(O3_2025_04_16Schema, options);\n  }\n}\n\nexport { O3_2025_04_16, O3_2025_04_16Literal, O3_2025_04_16Options, O3_2025_04_16Schema, type O3_2025_04_16OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O3Literal = \"o3\";\nconst O3Description =\n  \"A new standard for math, science, coding, and visual reasoning tasks. Training data up to Jun 2024.\";\n\nconst O3Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O3Literal,\n  description: O3Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O3Options = BaseChatModelOptions;\ntype O3OptionsType = z.infer<typeof O3Options>;\n\nclass O3 extends BaseChatModel {\n  constructor(options: O3OptionsType) {\n    super(O3Schema, options);\n  }\n}\n\nexport { O3, O3Literal, O3Options, O3Schema, type O3OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelTextToolModalities, OpenAIChatModelTextToolModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O3MiniLiteral = \"o3-mini\";\nconst O3MiniDescription =\n  \"o3-mini is the newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. Training data up to Sep 2023.\";\n\nconst O3MiniSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: O3MiniLiteral,\n  description: O3MiniDescription,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O3MiniOptions = BaseChatModelOptions;\ntype O3MiniOptionsType = z.infer<typeof O3MiniOptions>;\n\nclass O3Mini extends BaseChatModel {\n  constructor(options: O3MiniOptionsType) {\n    super(O3MiniSchema, options);\n  }\n}\n\nexport { O3Mini, O3MiniLiteral, O3MiniOptions, O3MiniSchema, type O3MiniOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelTextToolModalities, OpenAIChatModelTextToolModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O3Mini2025_01_31Literal = \"o3-mini-2025-01-31\";\nconst O3Mini2025_01_31Description =\n  \"o3-mini is the newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. Training data up to Sep 2023.\";\n\nconst O3Mini2025_01_31Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: O3Mini2025_01_31Literal,\n  description: O3Mini2025_01_31Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O3Mini2025_01_31Options = BaseChatModelOptions;\ntype O3Mini2025_01_31OptionsType = z.infer<typeof O3Mini2025_01_31Options>;\n\nclass O3Mini2025_01_31 extends BaseChatModel {\n  constructor(options: O3Mini2025_01_31OptionsType) {\n    super(O3Mini2025_01_31Schema, options);\n  }\n}\n\nexport { O3Mini2025_01_31, O3Mini2025_01_31Literal, O3Mini2025_01_31Options, O3Mini2025_01_31Schema, type O3Mini2025_01_31OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelModalities,\n  OpenAIChatModelModalitiesEnum,\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n} from \"./types\";\n\nconst O4_Mini_2025_04_16Literal = \"o4-mini-2025-04-16\";\nconst O4_Mini_2025_04_16Description =\n  \"Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. Training data up to Jun 2024.\";\n\nconst O4_Mini_2025_04_16Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O4_Mini_2025_04_16Literal,\n  description: O4_Mini_2025_04_16Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O4_Mini_2025_04_16Options = BaseChatModelOptions;\ntype O4_Mini_2025_04_16OptionsType = z.infer<typeof O4_Mini_2025_04_16Options>;\n\nclass O4_Mini_2025_04_16 extends BaseChatModel {\n  constructor(options: O4_Mini_2025_04_16OptionsType) {\n    super(O4_Mini_2025_04_16Schema, options);\n  }\n}\n\nexport { O4_Mini_2025_04_16, O4_Mini_2025_04_16Literal, O4_Mini_2025_04_16Options, O4_Mini_2025_04_16Schema, type O4_Mini_2025_04_16OptionsType };\n\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelModalities,\n  OpenAIChatModelModalitiesEnum,\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n} from \"./types\";\n\nconst O4_MiniLiteral = \"o4-mini\";\nconst O4_MiniDescription =\n  \"Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. Training data up to Jun 2024.\";\n\nconst O4_MiniSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O4_MiniLiteral,\n  description: O4_MiniDescription,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O4_MiniOptions = BaseChatModelOptions;\ntype O4_MiniOptionsType = z.infer<typeof O4_MiniOptions>;\n\nclass O4_Mini extends BaseChatModel {\n  constructor(options: O4_MiniOptionsType) {\n    super(O4_MiniSchema, options);\n  }\n}\n\nexport { O4_Mini, O4_MiniLiteral, O4_MiniOptions, O4_MiniSchema, type O4_MiniOptionsType };\n\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchemaType } from \"@adaline/provider\";\nimport { EmbeddingTextModalityLiteral, EmbeddingTokenModalityLiteral } from \"@adaline/types\";\n\nconst OpenAIEmbeddingModelModalities: EmbeddingModelSchemaType[\"modalities\"] = [\n  EmbeddingTextModalityLiteral,\n  EmbeddingTokenModalityLiteral,\n];\n\nconst OpenAIEmbeddingModelModalitiesEnum = z.enum([EmbeddingTextModalityLiteral, EmbeddingTokenModalityLiteral]);\n\nexport { OpenAIEmbeddingModelModalitiesEnum, OpenAIEmbeddingModelModalities };\n","import { z } from \"zod\";\n\nconst OpenAIGetEmbeddingsResponse = z.object({\n  object: z.literal(\"list\"),\n  model: z.string(),\n  data: z.array(\n    z.object({\n      index: z.number(),\n      object: z.literal(\"embedding\"),\n      embedding: z.array(z.number()).or(z.string().base64()),\n    })\n  ),\n  usage: z.object({\n    prompt_tokens: z.number().nonnegative(),\n    total_tokens: z.number().nonnegative(),\n  }),\n});\n\nexport { OpenAIGetEmbeddingsResponse };\n","import { z } from \"zod\";\n\nconst OpenAIEmbeddingRequestInput = z\n  .string()\n  .min(1)\n  .or(z.array(z.string().min(1)).min(1))\n  .or(z.array(z.number().int().nonnegative()).min(1))\n  .or(z.array(z.array(z.number().int().nonnegative()).min(1)).min(1));\ntype OpenAIEmbeddingRequestInputType = z.infer<typeof OpenAIEmbeddingRequestInput>;\n\nconst OpenAIEmbeddingRequest = z.object({\n  model: z.string().min(1).optional(),\n  input: OpenAIEmbeddingRequestInput,\n  encoding_format: z.enum([\"float\", \"base64\"]).optional(),\n  dimensions: z.number().int().min(1).optional(),\n});\ntype OpenAIEmbeddingRequestType = z.infer<typeof OpenAIEmbeddingRequest>;\n\nexport { OpenAIEmbeddingRequest, OpenAIEmbeddingRequestInput, type OpenAIEmbeddingRequestType, type OpenAIEmbeddingRequestInputType };\n","import { z } from \"zod\";\n\nimport {\n  EmbeddingModelSchemaType,\n  EmbeddingModelV1,\n  HeadersType,\n  InvalidConfigError,\n  InvalidEmbeddingRequestsError,\n  InvalidModelRequestError,\n  ModelResponseError,\n  ParamsType,\n  removeUndefinedEntries,\n  UrlType,\n  urlWithoutTrailingSlash,\n} from \"@adaline/provider\";\n\nimport {\n  Base64EmbeddingLiteral,\n  Base64EmbeddingType,\n  Config,\n  ConfigType,\n  EmbeddingRequests,\n  EmbeddingRequestsType,\n  EmbeddingResponseType,\n  EmbeddingTextModalityLiteral,\n  EmbeddingTokenModalityLiteral,\n  FloatEmbeddingLiteral,\n  FloatEmbeddingType,\n} from \"@adaline/types\";\n\nimport { OpenAIEmbeddingRequest, OpenAIGetEmbeddingsResponse } from \"./types\";\n\nimport { OpenAI } from \"./../../provider/provider.openai\";\n\nconst BaseEmbeddingModelOptions = z.object({\n  modelName: z.string(),\n  apiKey: z.string(),\n  baseUrl: z.string().url().optional(),\n  getEmbeddingsUrl: z.string().url().optional(),\n});\ntype BaseEmbeddingModelOptionsType = z.infer<typeof BaseEmbeddingModelOptions>;\n\nclass BaseEmbeddingModel implements EmbeddingModelV1<EmbeddingModelSchemaType> {\n  readonly version = \"v1\" as const;\n  modelSchema: EmbeddingModelSchemaType;\n  modelName: string;\n\n  private readonly apiKey: string;\n  private readonly baseUrl: string;\n  private readonly getEmbeddingsUrl: string;\n\n  constructor(modelSchema: EmbeddingModelSchemaType, options: BaseEmbeddingModelOptionsType) {\n    const parsedOptions = BaseEmbeddingModelOptions.parse(options);\n    this.modelSchema = modelSchema;\n    this.modelName = parsedOptions.modelName;\n    this.apiKey = parsedOptions.apiKey;\n    this.baseUrl = urlWithoutTrailingSlash(parsedOptions.baseUrl || OpenAI.baseUrl);\n    this.getEmbeddingsUrl = urlWithoutTrailingSlash(parsedOptions.getEmbeddingsUrl || `${this.baseUrl}/embeddings`);\n  }\n\n  getDefaultBaseUrl(): UrlType {\n    return this.baseUrl;\n  }\n\n  getDefaultHeaders(): HeadersType {\n    return {\n      Authorization: `Bearer ${this.apiKey}`,\n      \"Content-Type\": \"application/json\",\n    };\n  }\n\n  getDefaultParams(): ParamsType {\n    return {\n      model: this.modelSchema.name,\n    };\n  }\n\n  // x-ratelimit-limit-requests\tThe maximum number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-limit-tokens\tThe maximum number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-requests The remaining number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-tokens\tThe remaining number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-reset-requests\tThe time until the rate limit (based on requests) resets to its initial state.\n  // x-ratelimit-reset-tokens\tThe time until the rate limit (based on tokens) resets to its initial state.\n  getRetryDelay(responseHeaders: HeadersType): { shouldRetry: boolean; delayMs: number } {\n    // parse duration from header value of format \"6m0s\" or \"21s\" or \"41ms\" or \"2s81ms\" or \"5h50m30ms\" and such\n    const parseDuration = (duration: string): number => {\n      const regex = /(\\d+)(h|m|s|ms)/g;\n      const timeUnits: { [unit: string]: number } = {\n        h: 3600000, // 1 hour = 60 * 60 * 1000 ms\n        m: 60000, // 1 minute = 60 * 1000 ms\n        s: 1000, // 1 second = 1000 ms\n        ms: 1, // milliseconds\n      };\n\n      let match;\n      let totalMs = 0;\n      while ((match = regex.exec(duration)) !== null) {\n        const value = parseInt(match[1]);\n        const unit = match[2];\n        totalMs += value * timeUnits[unit];\n      }\n\n      return totalMs;\n    };\n\n    let resetRequestsDelayMs = 0;\n    let resetTokensDelayMs = 0;\n    const shouldRetry = true;\n    if (responseHeaders[\"x-ratelimit-reset-requests\"]) {\n      resetRequestsDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-requests\"]);\n    }\n    if (responseHeaders[\"x-ratelimit-reset-tokens\"]) {\n      resetTokensDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-tokens\"]);\n    }\n\n    // if rate limited by requests, then it's reset must be the higher of two and visa versa\n    const delayMs = Math.max(resetRequestsDelayMs, resetTokensDelayMs);\n    return { shouldRetry, delayMs };\n  }\n\n  getTokenCount(requests: EmbeddingRequestsType): number {\n    return requests.requests.reduce((acc, request) => acc + request.length, 0);\n  }\n\n  transformModelRequest(request: any): {\n    modelName: string | undefined;\n    config: ConfigType;\n    embeddingRequests: EmbeddingRequestsType;\n  } {\n    const safeRequest = OpenAIEmbeddingRequest.safeParse(request);\n    if (!safeRequest.success) {\n      throw new InvalidModelRequestError({ info: \"Invalid model request\", cause: safeRequest.error });\n    }\n\n    const parsedRequest = safeRequest.data;\n\n    const modelName = parsedRequest.model;\n\n    const _config = {\n      encodingFormat: parsedRequest.encoding_format,\n      dimensions: parsedRequest.dimensions,\n    };\n    const config = Config().parse(removeUndefinedEntries(_config));\n\n    let embeddingRequests: EmbeddingRequestsType;\n    let embeddingFormat: typeof EmbeddingTextModalityLiteral | typeof EmbeddingTokenModalityLiteral;\n    if (typeof parsedRequest.input === \"string\") {\n      embeddingFormat = EmbeddingTextModalityLiteral;\n    } else {\n      if (typeof parsedRequest.input[0] === \"string\") {\n        embeddingFormat = EmbeddingTextModalityLiteral;\n      } else {\n        embeddingFormat = EmbeddingTokenModalityLiteral;\n      }\n    }\n\n    if (embeddingFormat === EmbeddingTextModalityLiteral) {\n      if (typeof parsedRequest.input === \"string\") {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: [parsedRequest.input],\n        };\n      } else {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: parsedRequest.input as string[],\n        };\n      }\n    } else {\n      if (typeof parsedRequest.input[0] === \"number\") {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: [parsedRequest.input as number[]],\n        };\n      } else {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: parsedRequest.input as number[][],\n        };\n      }\n    }\n\n    return {\n      modelName,\n      config,\n      embeddingRequests,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  transformConfig(config: ConfigType, requests?: EmbeddingRequestsType): ParamsType {\n    const _parsedConfig = this.modelSchema.config.schema.safeParse(config);\n    if (!_parsedConfig.success) {\n      throw new InvalidConfigError({\n        info: `Invalid config for model : '${this.modelSchema.name}'`,\n        cause: _parsedConfig.error,\n      });\n    }\n\n    const parsedConfig = _parsedConfig.data as ConfigType;\n    Object.keys(parsedConfig as ConfigType).forEach((key) => {\n      if (!this.modelSchema.config.def[key]) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelSchema.name}'`,\n          cause: new Error(`Invalid config key : '${key}', \n            available keys : [${Object.keys(this.modelSchema.config.def).join(\", \")}]`),\n        });\n      }\n    });\n\n    const transformedConfig = Object.keys(parsedConfig).reduce((acc, key) => {\n      const def = this.modelSchema.config.def[key];\n      const paramKey = def.param;\n      const paramValue = parsedConfig[key];\n      acc[paramKey] = paramValue;\n      return acc;\n    }, {} as ParamsType);\n\n    return transformedConfig;\n  }\n\n  transformEmbeddingRequests(requests: EmbeddingRequestsType): ParamsType {\n    const _parsedRequests = EmbeddingRequests().safeParse(requests);\n    if (!_parsedRequests.success) {\n      throw new InvalidEmbeddingRequestsError({ info: \"Invalid embedding requests\", cause: _parsedRequests.error });\n    }\n\n    // Note from OpenAI API Reference:\n    // The input must not exceed the max input tokens for the model (8192 tokens for text-embedding-ada-002),\n    // cannot be an empty string, and any array must be 2048 dimensions or less.\n    // TODO: add max tokens check in requests based on model schema when token calculation is accurate\n\n    const parsedRequests = _parsedRequests.data as EmbeddingRequestsType;\n    return {\n      input: parsedRequests.requests,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getGetEmbeddingsUrl(config?: ConfigType, requests?: EmbeddingRequestsType): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.getEmbeddingsUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getGetEmbeddingsHeaders(config?: ConfigType, requests?: EmbeddingRequestsType): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getGetEmbeddingsData(config: ConfigType, requests: EmbeddingRequestsType): Promise<ParamsType> {\n    return new Promise((resolve) => {\n      resolve({\n        ...this.getDefaultParams(),\n        ...this.transformConfig(config, requests),\n        ...this.transformEmbeddingRequests(requests),\n      });\n    });\n  }\n\n  transformGetEmbeddingsResponse(response: any): EmbeddingResponseType {\n    let encodingFormat: typeof Base64EmbeddingLiteral | typeof FloatEmbeddingLiteral;\n    const safe = OpenAIGetEmbeddingsResponse.safeParse(response);\n    if (safe.success) {\n      const parsedResponse = safe.data;\n      encodingFormat = typeof parsedResponse.data[0].embedding === \"string\" ? Base64EmbeddingLiteral : FloatEmbeddingLiteral;\n      const embeddings = parsedResponse.data.map((item) => {\n        if (typeof item.embedding === \"string\") {\n          return {\n            index: item.index,\n            embedding: item.embedding,\n          } as Base64EmbeddingType;\n        } else {\n          return {\n            index: item.index,\n            embedding: item.embedding,\n          } as FloatEmbeddingType;\n        }\n      });\n\n      return {\n        encodingFormat: encodingFormat,\n        embeddings: embeddings,\n        usage: {\n          totalTokens: parsedResponse.usage.total_tokens,\n        },\n      } as EmbeddingResponseType;\n    }\n\n    throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n  }\n}\n\nexport { BaseEmbeddingModel, BaseEmbeddingModelOptions, type BaseEmbeddingModelOptionsType };\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIEmbeddingModelConfigs } from \"../../configs\";\nimport { BaseEmbeddingModel, BaseEmbeddingModelOptions } from \"./base-embedding-model.openai\";\nimport { OpenAIEmbeddingModelModalities, OpenAIEmbeddingModelModalitiesEnum } from \"./types\";\n\nconst Text_Embedding_Ada002Literal = \"text-embedding-ada-002\";\nconst Text_Embedding_Ada002Description = \"Most capable 2nd generation embedding model, replacing 16 first generation models\";\n\nconst Text_Embedding_Ada002Schema = EmbeddingModelSchema(OpenAIEmbeddingModelModalitiesEnum).parse({\n  name: Text_Embedding_Ada002Literal,\n  description: Text_Embedding_Ada002Description,\n  modalities: OpenAIEmbeddingModelModalities,\n  maxInputTokens: 8192,\n  maxOutputTokens: 1536,\n  config: {\n    def: OpenAIEmbeddingModelConfigs.base().def,\n    schema: OpenAIEmbeddingModelConfigs.base().schema,\n  },\n});\n\nconst Text_Embedding_Ada002_Options = BaseEmbeddingModelOptions;\ntype Text_Embedding_Ada002_OptionsType = z.infer<typeof Text_Embedding_Ada002_Options>;\n\nclass Text_Embedding_Ada002 extends BaseEmbeddingModel {\n  constructor(options: Text_Embedding_Ada002_OptionsType) {\n    super(Text_Embedding_Ada002Schema, options);\n  }\n}\n\nexport {\n  Text_Embedding_Ada002,\n  Text_Embedding_Ada002_Options,\n  Text_Embedding_Ada002Schema,\n  Text_Embedding_Ada002Literal,\n  type Text_Embedding_Ada002_OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIEmbeddingModelConfigs } from \"../../configs\";\nimport { BaseEmbeddingModel, BaseEmbeddingModelOptions } from \"./base-embedding-model.openai\";\nimport { OpenAIEmbeddingModelModalities, OpenAIEmbeddingModelModalitiesEnum } from \"./types\";\n\nconst Text_Embedding_3_SmallLiteral = \"text-embedding-3-small\";\nconst Text_Embedding_3_SmallDescription = \"Increased performance over 2nd generation ada embedding model\";\n\nconst Text_Embedding_3_SmallSchema = EmbeddingModelSchema(OpenAIEmbeddingModelModalitiesEnum).parse({\n  name: Text_Embedding_3_SmallLiteral,\n  description: Text_Embedding_3_SmallDescription,\n  modalities: OpenAIEmbeddingModelModalities,\n  maxInputTokens: 8192,\n  maxOutputTokens: 1536,\n  config: {\n    def: OpenAIEmbeddingModelConfigs.dimensions(1536).def,\n    schema: OpenAIEmbeddingModelConfigs.dimensions(1536).schema,\n  },\n});\n\nconst Text_Embedding_3_Small_Options = BaseEmbeddingModelOptions;\ntype Text_Embedding_3_Small_OptionsType = z.infer<typeof Text_Embedding_3_Small_Options>;\n\nclass Text_Embedding_3_Small extends BaseEmbeddingModel {\n  constructor(options: Text_Embedding_3_Small_OptionsType) {\n    super(Text_Embedding_3_SmallSchema, options);\n  }\n}\n\nexport {\n  Text_Embedding_3_Small,\n  Text_Embedding_3_Small_Options,\n  Text_Embedding_3_SmallSchema,\n  Text_Embedding_3_SmallLiteral,\n  type Text_Embedding_3_Small_OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIEmbeddingModelConfigs } from \"../../configs\";\nimport { BaseEmbeddingModel, BaseEmbeddingModelOptions } from \"./base-embedding-model.openai\";\nimport { OpenAIEmbeddingModelModalities, OpenAIEmbeddingModelModalitiesEnum } from \"./types\";\n\nconst Text_Embedding_3_LargeLiteral = \"text-embedding-3-large\";\nconst Text_Embedding_3_LargeDescription = \"Most capable embedding model for both english and non-english tasks\";\n\nconst Text_Embedding_3_LargeSchema = EmbeddingModelSchema(OpenAIEmbeddingModelModalitiesEnum).parse({\n  name: Text_Embedding_3_LargeLiteral,\n  description: Text_Embedding_3_LargeDescription,\n  modalities: OpenAIEmbeddingModelModalities,\n  maxInputTokens: 8192,\n  maxOutputTokens: 3072,\n  config: {\n    def: OpenAIEmbeddingModelConfigs.dimensions(3072).def,\n    schema: OpenAIEmbeddingModelConfigs.dimensions(3072).schema,\n  },\n});\n\nconst Text_Embedding_3_Large_Options = BaseEmbeddingModelOptions;\ntype Text_Embedding_3_Large_OptionsType = z.infer<typeof Text_Embedding_3_Large_Options>;\n\nclass Text_Embedding_3_Large extends BaseEmbeddingModel {\n  constructor(options: Text_Embedding_3_Large_OptionsType) {\n    super(Text_Embedding_3_LargeSchema, options);\n  }\n}\n\nexport {\n  Text_Embedding_3_Large,\n  Text_Embedding_3_Large_Options,\n  Text_Embedding_3_LargeSchema,\n  Text_Embedding_3_LargeLiteral,\n  type Text_Embedding_3_Large_OptionsType,\n};\n"]}